<!DOCTYPE html><html lang="en-US"><head>
<meta charset="utf-8">
<meta name="generator" content="ReSpec 35.6.0">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<style>
span.example-title{text-transform:none}
:is(aside,div).example,div.illegal-example{padding:.5em;margin:1em 0;position:relative;clear:both}
div.illegal-example{color:red}
div.illegal-example p{color:#000}
aside.example div.example{border-left-width:.1em;border-color:#999;background:#fff}
</style>
<style>
.issue-label{text-transform:initial}
.warning>p:first-child{margin-top:0}
.warning{padding:.5em;border-left-width:.5em;border-left-style:solid}
span.warning{padding:.1em .5em .15em}
.issue.closed span.issue-number{text-decoration:line-through}
.issue.closed span.issue-number::after{content:" (Closed)";font-size:smaller}
.warning{border-color:#f11;border-color:var(--warning-border,#f11);border-width:.2em;border-style:solid;background:#fbe9e9;background:var(--warning-bg,#fbe9e9);color:#000;color:var(--text,#000)}
.warning-title:before{content:"⚠";font-size:1.3em;float:left;padding-right:.3em;margin-top:-.3em}
li.task-list-item{list-style:none}
input.task-list-item-checkbox{margin:0 .35em .25em -1.6em;vertical-align:middle}
.issue a.respec-gh-label{padding:5px;margin:0 2px 0 2px;font-size:10px;text-transform:none;text-decoration:none;font-weight:700;border-radius:4px;position:relative;bottom:2px;border:none;display:inline-block}
</style>
<style>
dfn{cursor:pointer}
.dfn-panel{position:absolute;z-index:35;min-width:300px;max-width:500px;padding:.5em .75em;margin-top:.6em;font-family:"Helvetica Neue",sans-serif;font-size:small;background:#fff;background:var(--indextable-hover-bg,#fff);color:#000;color:var(--text,#000);box-shadow:0 1em 3em -.4em rgba(0,0,0,.3),0 0 1px 1px rgba(0,0,0,.05);box-shadow:0 1em 3em -.4em var(--tocsidebar-shadow,rgba(0,0,0,.3)),0 0 1px 1px var(--tocsidebar-shadow,rgba(0,0,0,.05));border-radius:2px}
.dfn-panel:not(.docked)>.caret{position:absolute;top:-9px}
.dfn-panel:not(.docked)>.caret::after,.dfn-panel:not(.docked)>.caret::before{content:"";position:absolute;border:10px solid transparent;border-top:0;border-bottom:10px solid #fff;border-bottom-color:var(--indextable-hover-bg,#fff);top:0}
.dfn-panel:not(.docked)>.caret::before{border-bottom:9px solid #a2a9b1;border-bottom-color:var(--indextable-hover-bg,#a2a9b1)}
.dfn-panel *{margin:0}
.dfn-panel b{display:block;color:#000;color:var(--text,#000);margin-top:.25em}
.dfn-panel ul a[href]{color:#333;color:var(--text,#333)}
.dfn-panel>div{display:flex}
.dfn-panel a.self-link{font-weight:700;margin-right:auto}
.dfn-panel .marker{padding:.1em;margin-left:.5em;border-radius:.2em;text-align:center;white-space:nowrap;font-size:90%;color:#040b1c}
.dfn-panel .marker.dfn-exported{background:#d1edfd;box-shadow:0 0 0 .125em #1ca5f940}
.dfn-panel .marker.idl-block{background:#8ccbf2;box-shadow:0 0 0 .125em #0670b161}
.dfn-panel a:not(:hover){text-decoration:none!important;border-bottom:none!important}
.dfn-panel a[href]:hover{border-bottom-width:1px}
.dfn-panel ul{padding:0}
.dfn-panel li{margin-left:1em}
.dfn-panel.docked{position:fixed;left:.5em;top:unset;bottom:2em;margin:0 auto;max-width:calc(100vw - .75em * 2 - .5em - .2em * 2);max-height:30vh;overflow:auto}
</style>
  
  
<title>Web of Things (WoT): Use Cases and Requirements</title>
  
<style type="text/css">

.vfm--fixed[data-v-2836fdb5] {
  position: fixed;
}
.vfm--absolute[data-v-2836fdb5] {
  position: absolute;
}
.vfm--inset[data-v-2836fdb5] {
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
}
.vfm--overlay[data-v-2836fdb5] {
  background-color: rgba(0, 0, 0, 0.5);
}
.vfm--prevent-none[data-v-2836fdb5] {
  pointer-events: none;
}
.vfm--prevent-auto[data-v-2836fdb5] {
  pointer-events: auto;
}
.vfm--outline-none[data-v-2836fdb5]:focus {
  outline: none;
}
.vfm-enter-active[data-v-2836fdb5],
.vfm-leave-active[data-v-2836fdb5] {
  transition: opacity 0.2s;
}
.vfm-enter-from[data-v-2836fdb5],
.vfm-leave-to[data-v-2836fdb5] {
  opacity: 0;
}
.vfm--touch-none[data-v-2836fdb5] {
  touch-action: none;
}
.vfm--select-none[data-v-2836fdb5] {
  -webkit-user-select: none;
     -moz-user-select: none;
      -ms-user-select: none;
          user-select: none;
}
.vfm--resize-tr[data-v-2836fdb5],
.vfm--resize-br[data-v-2836fdb5],
.vfm--resize-bl[data-v-2836fdb5],
.vfm--resize-tl[data-v-2836fdb5] {
  width: 12px;
  height: 12px;
  z-index: 10;
}
.vfm--resize-t[data-v-2836fdb5] {
  top: -6px;
  left: 0;
  width: 100%;
  height: 12px;
  cursor: ns-resize;
}
.vfm--resize-tr[data-v-2836fdb5] {
  top: -6px;
  right: -6px;
  cursor: nesw-resize;
}
.vfm--resize-r[data-v-2836fdb5] {
  top: 0;
  right: -6px;
  width: 12px;
  height: 100%;
  cursor: ew-resize;
}
.vfm--resize-br[data-v-2836fdb5] {
  bottom: -6px;
  right: -6px;
  cursor: nwse-resize;
}
.vfm--resize-b[data-v-2836fdb5] {
  bottom: -6px;
  left: 0;
  width: 100%;
  height: 12px;
  cursor: ns-resize;
}
.vfm--resize-bl[data-v-2836fdb5] {
  bottom: -6px;
  left: -6px;
  cursor: nesw-resize;
}
.vfm--resize-l[data-v-2836fdb5] {
  top: 0;
  left: -6px;
  width: 12px;
  height: 100%;
  cursor: ew-resize;
}
.vfm--resize-tl[data-v-2836fdb5] {
  top: -6px;
  left: -6px;
  cursor: nwse-resize;
}

</style>
<style id="respec-mainstyle">
@keyframes pop{
0%{transform:scale(1,1)}
25%{transform:scale(1.25,1.25);opacity:.75}
100%{transform:scale(1,1)}
}
a.internalDFN{color:inherit;border-bottom:1px solid #99c;text-decoration:none}
a.externalDFN{color:inherit;border-bottom:1px dotted #ccc;text-decoration:none}
a.bibref{text-decoration:none}
.respec-offending-element:target{animation:pop .25s ease-in-out 0s 1}
.respec-offending-element,a[href].respec-offending-element{text-decoration:red wavy underline}
@supports not (text-decoration:red wavy underline){
.respec-offending-element:not(pre){display:inline-block}
.respec-offending-element{background:url(data:image/gif;base64,R0lGODdhBAADAPEAANv///8AAP///wAAACwAAAAABAADAEACBZQjmIAFADs=) bottom repeat-x}
}
#references :target{background:#eaf3ff;animation:pop .4s ease-in-out 0s 1}
cite .bibref{font-style:italic}
a[href].orcid{padding-left:4px;padding-right:4px}
a[href].orcid>svg{margin-bottom:-2px}
ol.tof,ul.tof{list-style:none outside none}
.caption{margin-top:.5em;font-style:italic}
#issue-summary>ul{column-count:2}
#issue-summary li{list-style:none;display:inline-block}
details.respec-tests-details{margin-left:1em;display:inline-block;vertical-align:top}
details.respec-tests-details>*{padding-right:2em}
details.respec-tests-details[open]{z-index:999999;position:absolute;border:thin solid #cad3e2;border-radius:.3em;background-color:#fff;padding-bottom:.5em}
details.respec-tests-details[open]>summary{border-bottom:thin solid #cad3e2;padding-left:1em;margin-bottom:1em;line-height:2em}
details.respec-tests-details>ul{width:100%;margin-top:-.3em}
details.respec-tests-details>li{padding-left:1em}
.self-link:hover{opacity:1;text-decoration:none;background-color:transparent}
aside.example .marker>a.self-link{color:inherit}
.header-wrapper{display:flex;align-items:baseline}
:is(h2,h3,h4,h5,h6):not(#toc>h2,#abstract>h2,#sotd>h2,.head>h2){position:relative;left:-.5em}
:is(h2,h3,h4,h5,h6):not(#toch2)+a.self-link{color:inherit;order:-1;position:relative;left:-1.1em;font-size:1rem;opacity:.5}
:is(h2,h3,h4,h5,h6)+a.self-link::before{content:"§";text-decoration:none;color:var(--heading-text)}
:is(h2,h3)+a.self-link{top:-.2em}
:is(h4,h5,h6)+a.self-link::before{color:#000}
@media (max-width:767px){
dd{margin-left:0}
}
@media print{
.removeOnSave{display:none}
}
</style>
  
  
<style>

    .resize img {
      width: 100%;
      height: auto;
    }
  
</style>

<meta name="color-scheme" content="light">
<style type="text/css">
x-vue-echarts{display:block;width:100%;height:100%;min-width:0}

</style>
<meta name="description" content="The Web of Things is applicable to multiple IoT domains,
      including Smart Home, Industrial, Smart City, Retail, and Health
      applications, where usage of the W3C WoT standards can simplify the
      development of IoT systems that combine devices from multiple vendors
      and ecosystems.
      The WoT Working Group has developed, and continues to develop, several
      specifications to address requirements for
      these domains.">
<style>
.hljs{--base:#fafafa;--mono-1:#383a42;--mono-2:#686b77;--mono-3:#717277;--hue-1:#0b76c5;--hue-2:#336ae3;--hue-3:#a626a4;--hue-4:#42803c;--hue-5:#ca4706;--hue-5-2:#c91243;--hue-6:#986801;--hue-6-2:#9a6a01}
@media (prefers-color-scheme:dark){
.hljs{--base:#282c34;--mono-1:#abb2bf;--mono-2:#818896;--mono-3:#5c6370;--hue-1:#56b6c2;--hue-2:#61aeee;--hue-3:#c678dd;--hue-4:#98c379;--hue-5:#e06c75;--hue-5-2:#be5046;--hue-6:#d19a66;--hue-6-2:#e6c07b}
}
.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;color:var(--mono-1,#383a42);background:#fafafa;background:var(--base,#fafafa)}
.hljs-comment,.hljs-quote{color:#717277;color:var(--mono-3,#717277);font-style:italic}
.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4;color:var(--hue-3,#a626a4)}
.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#ca4706;color:var(--hue-5,#ca4706);font-weight:700}
.hljs-literal{color:#0b76c5;color:var(--hue-1,#0b76c5)}
.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#42803c;color:var(--hue-4,#42803c)}
.hljs-built_in,.hljs-class .hljs-title{color:#9a6a01;color:var(--hue-6-2,#9a6a01)}
.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801;color:var(--hue-6,#986801)}
.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#336ae3;color:var(--hue-2,#336ae3)}
.hljs-emphasis{font-style:italic}
.hljs-strong{font-weight:700}
.hljs-link{text-decoration:underline}
</style>
<style>
var:hover{text-decoration:underline;cursor:pointer}
var.respec-hl{color:var(--color,#000);background-color:var(--bg-color);box-shadow:0 0 0 2px var(--bg-color)}
@media (prefers-color-scheme:dark){
var.respec-hl{filter:saturate(.9) brightness(.9)}
}
var.respec-hl-c1{--bg-color:#f4d200}
var.respec-hl-c2{--bg-color:#ff87a2}
var.respec-hl-c3{--bg-color:#96e885}
var.respec-hl-c4{--bg-color:#3eeed2}
var.respec-hl-c5{--bg-color:#eacfb6}
var.respec-hl-c6{--bg-color:#82ddff}
var.respec-hl-c7{--bg-color:#ffbcf2}
@media print{
var.respec-hl{background:0 0;color:#000;box-shadow:unset}
}
</style>
<style>
var{position:relative;cursor:pointer}
var[data-type]::after,var[data-type]::before{position:absolute;left:50%;top:-6px;opacity:0;transition:opacity .4s;pointer-events:none}
var[data-type]::before{content:"";transform:translateX(-50%);border-width:4px 6px 0 6px;border-style:solid;border-color:transparent;border-top-color:#222}
var[data-type]::after{content:attr(data-type);transform:translateX(-50%) translateY(-100%);background:#222;text-align:center;font-family:"Dank Mono","Fira Code",monospace;font-style:normal;padding:6px;border-radius:3px;color:#daca88;text-indent:0;font-weight:400}
var[data-type]:hover::after,var[data-type]:hover::before{opacity:1}
</style>
<script id="initialUserConfig" type="application/json">{
  "lint": {
    "no-headingless-sections": false
  },
  "specStatus": "ED",
  "noRecTrack": "true",
  "maxTocLevel": 6,
  "processVersion": 2019,
  "shortName": "wot-usecases",
  "copyrightStart": 2020,
  "group": "ig/wot",
  "edDraftURI": "https://w3c.github.io/wot-usecases/",
  "githubAPI": "https://api.github.com/repos/w3c/wot-usecases/",
  "issueBase": "https://www.github.com/w3c/wot-usecases/issues",
  "editors": [
    {
      "name": "Michael McCool",
      "w3cid": "93137",
      "company": "Intel Corp.",
      "companyURL": "https://www.intel.com/"
    },
    {
      "name": "Tomoaki Mizushima",
      "w3cid": "98915",
      "company": "Internet Research Institute, Inc.",
      "companyURL": "https://www.iri.co.jp/"
    }
  ],
  "formerEditors": [
    {
      "name": "Michael Lagally",
      "w3cid": "47166",
      "company": "Oracle Corp.",
      "companyURL": "https://www.oracle.com/"
    },
    {
      "name": "Ryuichi Matsukura",
      "w3cid": "64284",
      "company": "Fujitsu Ltd.",
      "companyURL": "https://www.fujitsu.com/"
    }
  ],
  "otherLinks": [
    {
      "key": "Contributors",
      "data": [
        {
          "value": "In the GitHub repository",
          "href": "https://github.com/w3c/wot-usecases/graphs/contributors"
        }
      ]
    },
    {
      "key": "Repository",
      "data": [
        {
          "value": "We are on GitHub",
          "href": "https://github.com/w3c/wot-usecases/"
        },
        {
          "value": "File a bug",
          "href": "https://github.com/w3c/wot-usecases/issues"
        },
        {
          "value": "Contribute",
          "href": "https://github.com/w3c/wot-usecases/pulls"
        }
      ]
    }
  ],
  "localBiblio": {
    "SWEBOKv4": {
      "title": "Guide to the Software Engineering Body of Knowledge (SWEBOK Guide), Version 4.0",
      "authors": [
        "Hironori Washizaki"
      ],
      "href": "https://www.computer.org/education/bodies-of-knowledge/software-engineering",
      "status": "Published",
      "date": "2024",
      "publisher": "IEEE Computer Society",
      "id": "swebokv4"
    },
    "ISO-6709": {
      "title": "ISO-6709:2008 : Standard representation of geographic point location by coordinates",
      "href": "https://www.iso.org/standard/39242.html",
      "status": "Published",
      "date": "2008-07",
      "publisher": "ISO",
      "id": "iso-6709"
    },
    "Hybridcast": {
      "title": "IPTVFJ STD-0013 Hybridcast Operational Guideline Version 2.8",
      "href": "https://www.iptvforum.jp/en/hybridcast/specification.html",
      "date": "19 September 2020",
      "publisher": "IPTVFJ",
      "id": "hybridcast"
    },
    "HIPAA": {
      "title": "The Health Insurance Portability and Accountability Act of 1996 (HIPAA), Public Law 104-191",
      "href": "https://www.hhs.gov/hipaa/index.html",
      "date": "1996-08-21",
      "publisher": "U.S. Department of Health and Human Services (HHS)",
      "id": "hipaa"
    },
    "GDPR": {
      "title": "General Data Protection Regulation (GDPR), EU Public Law 104-191",
      "version": "OJ L 119, 04.05.2016; cor. OJ L 127, 23.5.2018",
      "date": "2018-05-23",
      "href": "https://gdpr-info.eu/",
      "publisher": "European Union",
      "id": "gdpr"
    },
    "PIPEDA": {
      "title": "Personal Information Protection and Electronic Documents Act (PIPEDA)",
      "href": "https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/",
      "date": "2000-04-13",
      "publisher": "Government of Canada, Office of the Privacy Commissioner",
      "id": "pipeda"
    },
    "NMEA-0183": {
      "title": "NMEA 0183 Interface Standard",
      "publisher": "National Marine Electronics Association",
      "date": "November 2018",
      "href": "https://www.nmea.org/content/STANDARDS/NMEA_0183_Standard",
      "id": "nmea-0183"
    },
    "EDGEX": {
      "title": "EdgeX Foundry",
      "href": "https://www.edgexfoundry.org/"
    },
    "OGC": {
      "title": "Open Geospatial Consortium",
      "href": "https://www.ogc.org/",
      "id": "ogc"
    },
    "OGC-coords": {
      "title": "OGC Abstract Specification Topic 2: Referencing by coordinates",
      "href": "http://docs.opengeospatial.org/as/18-005r4/18-005r4.html",
      "date": "8 February 2019",
      "publisher": "Open Geospatial Consortium",
      "id": "ogc-coords"
    },
    "Brick": {
      "title": "Brick Schema",
      "href": "https://brickschema.org/",
      "publisher": "The Brick Consortium, Inc.",
      "id": "brick"
    },
    "BOT": {
      "authors": [
        "Mads Holten Rasmussen",
        "Pieter Pauwels",
        "Maxime Lefrançois",
        "Georg Ferdinand Schneider"
      ],
      "title": "Building Topology Ontology",
      "href": "https://w3c-lbd-cg.github.io/bot/index.html",
      "publisher": "W3C Linked Building Data Community Group",
      "date": "28 June 2021",
      "id": "bot"
    },
    "iso-19111-2019": {
      "title": "ISOi 19111:2019 - Geographic information — Referencing by coordinates",
      "href": "https://www.iso.org/standard/74039.html",
      "status": "Published",
      "date": "Jan 2019",
      "publisher": "ISO",
      "id": "iso-19111-2019"
    },
    "ICE F2761-09(2013)": {
      "title": "ICE F2761-09(2013)",
      "publisher": "IEC",
      "id": "ice f2761-09(2013)"
    },
    "OpenICE": {
      "title": "OpenICE",
      "href": "https://www.openice.info",
      "id": "openice"
    },
    "MDIRA": {
      "title": "MDIRA",
      "href": "https://secwww.jhuapl.edu/mdira/documents",
      "id": "mdira"
    },
    "MQTT": {
      "title": "MQTT Version 3.1.1 Plus Errata 01",
      "href": "http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/mqtt-v3.1.1.html",
      "authors": [
        "Andrew Banks",
        "Rahul Gupta"
      ],
      "status": "Published",
      "date": "December 2015",
      "publisher": "OASIS Standard",
      "id": "mqtt"
    },
    "OPC UA": {
      "title": "OPC Unified Architecture",
      "href": "https://opcfoundation.org/about/opc-technologies/opc-ua/",
      "publisher": "OPC",
      "id": "opc ua"
    },
    "BACnet": {
      "title": "BACnet",
      "href": "http://www.bacnet.org",
      "publisher": "ASHRAE",
      "id": "bacnet"
    },
    "IEC 61850": {
      "title": "IEC 61850:2022 - Communication networks and systems for power utility automation",
      "date": "4 January 2022",
      "href": "https://webstore.iec.ch/publication/6028",
      "publisher": "IEC TC 57",
      "id": "iec 61850"
    },
    "IEEE 1547": {
      "title": "IEEE 1547-2018 - Interconnection and Interoperability of Distributed Energy Resources with Associated Electric Power Systems Interfaces",
      "date": "15 February 2018",
      "href": "https://standards.ieee.org/standard/1547-2018.html",
      "publisher": "IEEE",
      "id": "ieee 1547"
    },
    "KNX": {
      "title": "KNX",
      "href": "https://www.knx.org/knx-en/for-professionals/index.php",
      "publisher": "KNX",
      "id": "knx"
    },
    "Modbus": {
      "title": "Modbus",
      "href": "https://modbus.org",
      "publisher": "Modbus Organization",
      "id": "modbus"
    },
    "OGC Sensor Things": {
      "title": "OGC Sensor Things API",
      "href": "https://www.ogc.org/standards/sensorthings",
      "date": "4 August 2021",
      "publisher": "Open Geospatial Consortium",
      "id": "ogc sensor things"
    },
    "OneM2M": {
      "title": "OneM2M",
      "href": "https://www.onem2m.org",
      "publisher": "ETSI",
      "id": "onem2m"
    },
    "LWM2M": {
      "title": "Lightweight Machine to Machine Technical Specification: Core",
      "href": "http://openmobilealliance.org/release/LightweightM2M/V1_1-20180710-A/OMA-TS-LightweightM2M_Core-V1_1-20180710-A.pdf",
      "date": "Aug 2018",
      "publisher": "OMA SpecWorks.",
      "id": "lwm2m"
    },
    "OCF": {
      "title": "OCF Core Specification",
      "href": "https://openconnectivity.org/developer/specifications",
      "date": "April 2019",
      "publisher": "Open Connectivity Foundation",
      "id": "ocf"
    },
    "ECLASS": {
      "title": "ECLASS Standard",
      "href": "https://www.eclass.eu/",
      "date": "April 2019",
      "publisher": "ECLASS e.V."
    },
    "SAREF4AGRI": {
      "title": "SAREF4AGRI: an extension of SAREF for the agriculture and food domain",
      "authors": [
        "Maria Poveda-Villalon",
        "Raúl Garcia-Castro",
        "Laura Daniele",
        "Mike de Roode"
      ],
      "date": "30 April 2019",
      "publisher": "ETSI",
      "href": "https://saref.etsi.org/saref4agri/",
      "id": "saref4agri"
    },
    "SAREF4ENER": {
      "title": "SAREF4ENER: an extension of SAREF for the energy domain created in collaboration with Energy@Home and EEBus associations",
      "authors": [
        "Laura Daniele"
      ],
      "date": "4 June 2020",
      "publisher": "ETSI",
      "href": "https://saref.etsi.org/saref4ener/",
      "id": "saref4ener"
    },
    "SAREF4BLDG": {
      "title": "SAREF extension for building",
      "authors": [
        "María Poveda-Villalón",
        "Raúl Garcia-Castro"
      ],
      "date": "13 April 2020",
      "publisher": "ETSI",
      "href": "https://saref.etsi.org/saref4bldg/",
      "id": "saref4bldg"
    },
    "SAREF4SYST": {
      "title": "SAREF4SYST: an extension of SAREF for typology of systems and their inter-connections",
      "authors": [
        "Maxime Lefrançois"
      ],
      "date": "6 June 2019",
      "publisher": "ETSI",
      "href": "https://saref.etsi.org/saref4syst/",
      "id": "saref4syst"
    },
    "wot-geolocation-proposal": {
      "title": "WoT Discovery - Geolocation",
      "status": "Proposal",
      "date": "8 March 2021",
      "authors": [
        "Michael McCool"
      ],
      "href": "https://github.com/w3c/wot-discovery/blob/main/proposals/geolocation.md",
      "id": "wot-geolocation-proposal"
    }
  },
  "publishISODate": "2025-10-22T00:00:00.000Z",
  "generatedSubtitle": "W3C Editor's Draft 22 October 2025"
}</script>
<link rel="stylesheet" href="chrome-extension://dmeppfcidcpcocleneopiblmpnbokhep/assets/browser.css">
<link rel="preconnect" href="https://migaku-public-data.migaku.com" crossorigin="anonymous">
<link rel="preload" href="https://migaku-public-data.migaku.com/fonts/inter/InterVariable.woff2?v=4.0" as="font" type="font/woff" crossorigin="anonymous">
<link rel="preload" href="https://migaku-public-data.migaku.com/fonts/gt-maru/GT-Maru-Black.woff2" as="font" type="font/woff" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.w3.org/StyleSheets/TR/2021/W3C-ED"></head>

<body class="h-entry informative"><div id="MigakuShadowDom" data-mgk-ready="false" data-mgk-lang-selected="" data-mgk-app-open="false"></div><div class="head">
    <p class="logos"><a class="logo" href="https://www.w3.org/"><img crossorigin="" alt="W3C" height="48" src="https://www.w3.org/StyleSheets/TR/2021/logos/W3C" width="72">
  </a></p>
    <h1 id="title" class="title">Web of Things (WoT): Use Cases and Requirements</h1> 
    <p id="w3c-state"><a href="https://www.w3.org/standards/types#ED">W3C Editor's Draft</a> <time class="dt-published" datetime="2025-10-22">22 October 2025</time></p>
    <details open="">
      <summary>More details about this document</summary>
      <dl>
        <dt>This version:</dt><dd>
                <a class="u-url" href="https://w3c.github.io/wot-usecases/">https://w3c.github.io/wot-usecases/</a>
              </dd>
        <dt>Latest published version:</dt><dd>
                <a href="https://www.w3.org/wot-usecases/">https://www.w3.org/wot-usecases/</a>
              </dd>
        <dt>Latest editor's draft:</dt><dd><a href="https://w3c.github.io/wot-usecases/">https://w3c.github.io/wot-usecases/</a></dd>
        <dt>History:</dt><dd>
                    <a href="https://www.w3.org/standards/history/wot-usecases/">https://www.w3.org/standards/history/wot-usecases/</a>
                  </dd>
        
        
        
        
        
        <dt>Editors:</dt><dd class="editor p-author h-card vcard" data-editor-id="93137">
    <span class="p-name fn">Michael McCool</span> (<a class="p-org org h-org" href="https://www.intel.com/">Intel Corp.</a>)
  </dd><dd class="editor p-author h-card vcard" data-editor-id="98915">
    <span class="p-name fn">Tomoaki Mizushima</span> (<a class="p-org org h-org" href="https://www.iri.co.jp/">Internet Research Institute, Inc.</a>)
  </dd>
        <dt>
                Former editors:
              </dt><dd class="editor p-author h-card vcard" data-editor-id="47166">
    <span class="p-name fn">Michael Lagally</span> (<a class="p-org org h-org" href="https://www.oracle.com/">Oracle Corp.</a>)
  </dd><dd class="editor p-author h-card vcard" data-editor-id="64284">
    <span class="p-name fn">Ryuichi Matsukura</span> (<a class="p-org org h-org" href="https://www.fujitsu.com/">Fujitsu Ltd.</a>)
  </dd>
        
        
        
        <dt>Contributors</dt><dd>
    <a href="https://github.com/w3c/wot-usecases/graphs/contributors">In the GitHub repository</a>
  </dd><dt>Repository</dt><dd>
    <a href="https://github.com/w3c/wot-usecases/">We are on GitHub</a>
  </dd><dd>
    <a href="https://github.com/w3c/wot-usecases/issues">File a bug</a>
  </dd><dd>
    <a href="https://github.com/w3c/wot-usecases/pulls">Contribute</a>
  </dd>
      </dl>
    </details>
    
    
    <p class="copyright">
    <a href="https://www.w3.org/policies/#copyright">Copyright</a>
    ©
    2020-2025
    
    <a href="https://www.w3.org/">World Wide Web Consortium</a>.
    <abbr title="World Wide Web Consortium">W3C</abbr><sup>®</sup>
    <a href="https://www.w3.org/policies/#Legal_Disclaimer">liability</a>,
    <a href="https://www.w3.org/policies/#W3C_Trademarks">trademark</a> and
    <a rel="license" href="https://www.w3.org/copyright/software-license-2023/" title="W3C Software and Document Notice and License">permissive document license</a> rules apply.
  </p>
    <hr title="Separator for header">
  </div>
  <section id="abstract" class="introductory"><h2>Abstract</h2>
    <p>
      The Web of Things is applicable to multiple IoT domains,
      including Smart Home, Industrial, Smart City, Retail, and Health
      applications, where usage of the <abbr title="World Wide Web Consortium">W3C</abbr> WoT standards can simplify the
      development of IoT systems that combine devices from multiple vendors
      and ecosystems.
      The WoT Working Group has developed, and continues to develop, several
      specifications to address requirements for
      these domains.
    </p>
    <p>
      This Use Cases and Requirements Document is created
      to collect new IoT/WoT use cases from various domains
      that have been contributed by various stakeholders.
      Use cases can then be used to motivate requirements
      for the standardization work in the <abbr title="World Wide Web Consortium">W3C</abbr> WoT working groups.
	  In addition, general high-level requirements are defined in this
	  document in the form of user stories, each of which connects a 
	  motivation (which is often one or more use cases), a specific
	  stakeholder, and
	  a concrete feature or property that can be supported
	  or defined by a WoT specification.
    </p>
  </section>
  <section id="sotd" class="introductory"><h2>Status of This Document</h2><p><em>This section describes the status of this
      document at the time of its publication. A list of current <abbr title="World Wide Web Consortium">W3C</abbr>
      publications and the latest revision of this technical report can be found
      in the
      <a href="https://www.w3.org/TR/"><abbr title="World Wide Web Consortium">W3C</abbr> standards and drafts index</a>.</em></p>
  <p>
    This document was published by the <a href="https://www.w3.org/groups/ig/wot">Web of Things Interest Group</a> as
    an Editor's Draft. 
  </p><p>Publication as an Editor's Draft does not
  imply endorsement by <abbr title="World Wide Web Consortium">W3C</abbr> and its Members. </p><p>
    This is a draft document and may be updated, replaced, or obsoleted by other
    documents at any time. It is inappropriate to cite this document as other
    than a work in progress.
    
  </p><p>
    
        This document was produced by a group
        operating under the
        <a href="https://www.w3.org/policies/patent-policy/"><abbr title="World Wide Web Consortium">W3C</abbr> Patent
          Policy</a>.
      
    
                <abbr title="World Wide Web Consortium">W3C</abbr> maintains a
                <a rel="disclosure" href="https://www.w3.org/groups/ig/wot/ipr">public list of any patent disclosures</a>
          made in connection with the deliverables of
          the group; that page also includes
          instructions for disclosing a patent. An individual who has actual
          knowledge of a patent that the individual believes contains
          <a href="https://www.w3.org/policies/patent-policy/#def-essential">Essential Claim(s)</a>
          must disclose the information in accordance with
          <a href="https://www.w3.org/policies/patent-policy/#sec-Disclosure">section 6 of the <abbr title="World Wide Web Consortium">W3C</abbr> Patent Policy</a>.
        
  </p><p>
                      This document is governed by the
                      <a id="w3c_process_revision" href="https://www.w3.org/policies/process/20250818/">18 August 2025 <abbr title="World Wide Web Consortium">W3C</abbr> Process Document</a>.
                    </p></section><nav id="toc"><h2 class="introductory" id="table-of-contents">Table of Contents</h2><ol class="toc"><li class="tocline"><a class="tocxref" href="#abstract">Abstract</a></li><li class="tocline"><a class="tocxref" href="#sotd">Status of This Document</a></li><li class="tocline"><a class="tocxref" href="#intro"><bdi class="secno">1. </bdi>Introduction</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#terminology"><bdi class="secno">1.1 </bdi>Terminology</a></li><li class="tocline"><a class="tocxref" href="#domains"><bdi class="secno">1.2 </bdi>Domains</a></li><li class="tocline"><a class="tocxref" href="#stakeholders"><bdi class="secno">1.3 </bdi>Stakeholders and Roles</a></li></ol></li><li class="tocline"><a class="tocxref" href="#requirements"><bdi class="secno">2. </bdi>Requirements</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#sec-user-stories"><bdi class="secno">2.1 </bdi>User Stories</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#US-connection-oriented-protocols"><bdi class="secno">2.1.1 </bdi>Connection Oriented Protocols</a></li><li class="tocline"><a class="tocxref" href="#US-reusable-defaults-per-TD"><bdi class="secno">2.1.2 </bdi>Reusable Defaults per TD</a></li><li class="tocline"><a class="tocxref" href="#td-byte-ordering"><bdi class="secno">2.1.3 </bdi>Byte Ordering for Binary Data Formats</a></li><li class="tocline"><a class="tocxref" href="#td-polling-rate-limit"><bdi class="secno">2.1.4 </bdi>Polling Rate Limit</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-pbt"><bdi class="secno">2.1.5 </bdi>Mitigate WoT Protocol Binding Threat</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-etc"><bdi class="secno">2.1.6 </bdi>Mitigate Exposed Thing Compromise Threat</a></li><li class="tocline"><a class="tocxref" href="#US-sec-access-control"><bdi class="secno">2.1.7 </bdi>Security Access Control</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-dos"><bdi class="secno">2.1.8 </bdi>Mitigate WoT DoS Threat</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-ddos"><bdi class="secno">2.1.9 </bdi>Mitigate WoT DDoS Threat</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-ctda"><bdi class="secno">2.1.10 </bdi>Mitigate Communication Threat - TD Authenticity</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-ctdcp"><bdi class="secno">2.1.11 </bdi>Mitigate Communication Threat - TD Confidentiality and Privacy</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-csuda"><bdi class="secno">2.1.12 </bdi>Mitigate Communication Threat - System User Data Authenticity</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-csudcp"><bdi class="secno">2.1.13 </bdi>Mitigate Communication Threat - System User Data Confidentiality and Privacy</a></li><li class="tocline"><a class="tocxref" href="#US-sec-mitigate-csc"><bdi class="secno">2.1.14 </bdi>Mitigate Communication Threat - Side Channels</a></li><li class="tocline"><a class="tocxref" href="#US-disc-network-scope"><bdi class="secno">2.1.15 </bdi>Discovery Network Scope</a></li><li class="tocline"><a class="tocxref" href="#US-disc-via-third-party-services"><bdi class="secno">2.1.16 </bdi>Discovery via Third Party Services</a></li><li class="tocline"><a class="tocxref" href="#US-disc-via-scripting-api"><bdi class="secno">2.1.17 </bdi>Discovery via Scripting API</a></li><li class="tocline"><a class="tocxref" href="#US-disc-filtering"><bdi class="secno">2.1.18 </bdi>Discovery Filtering</a></li><li class="tocline"><a class="tocxref" href="#US-disc-spatial-queries"><bdi class="secno">2.1.19 </bdi>Discovery Spatial Queries</a></li><li class="tocline"><a class="tocxref" href="#US-disc-subnet-spanning-queries"><bdi class="secno">2.1.20 </bdi>Discovery Subnet Spanning Queries</a></li><li class="tocline"><a class="tocxref" href="#US-disc-scalablity"><bdi class="secno">2.1.21 </bdi>Discovery Scalability</a></li><li class="tocline"><a class="tocxref" href="#US-disc-dynamic-and-static-metadata"><bdi class="secno">2.1.22 </bdi>Discovery Dynamic and Static Metadata</a></li><li class="tocline"><a class="tocxref" href="#US-disc-deletion"><bdi class="secno">2.1.23 </bdi>Discovery Deletion</a></li><li class="tocline"><a class="tocxref" href="#US-disc-access-control"><bdi class="secno">2.1.24 </bdi>Discovery Access Control</a></li><li class="tocline"><a class="tocxref" href="#US-disc-clean-up"><bdi class="secno">2.1.25 </bdi>Discovery Clean Up</a></li><li class="tocline"><a class="tocxref" href="#US-disc-ietf-core"><bdi class="secno">2.1.26 </bdi>Discovery IETF CoRE Alignment</a></li><li class="tocline"><a class="tocxref" href="#US-disc-did"><bdi class="secno">2.1.27 </bdi>Discovery DID Alignment</a></li><li class="tocline"><a class="tocxref" href="#US-disc-extensible-introductions"><bdi class="secno">2.1.28 </bdi>Discovery Extensible Introductions</a></li><li class="tocline"><a class="tocxref" href="#US-disc-confidentiality"><bdi class="secno">2.1.29 </bdi>Discovery Confidentiality</a></li><li class="tocline"><a class="tocxref" href="#US-disc-authentication"><bdi class="secno">2.1.30 </bdi>Discovery Authentication</a></li><li class="tocline"><a class="tocxref" href="#US-disc-authorization"><bdi class="secno">2.1.31 </bdi>Discovery Authorization</a></li><li class="tocline"><a class="tocxref" href="#US-disc-anonymous-authentication"><bdi class="secno">2.1.32 </bdi>Discovery Anonymous Authentication</a></li><li class="tocline"><a class="tocxref" href="#US-disc-lifecycle"><bdi class="secno">2.1.33 </bdi>Discovery Lifecycle</a></li><li class="tocline"><a class="tocxref" href="#US-disc-limit-distribution"><bdi class="secno">2.1.34 </bdi>Discovery Limit Distribution</a></li><li class="tocline"><a class="tocxref" href="#US-disc-no-leaks"><bdi class="secno">2.1.35 </bdi>Discovery No Leaks</a></li><li class="tocline"><a class="tocxref" href="#US-disc-simplicity"><bdi class="secno">2.1.36 </bdi>Discovery Simplicity</a></li><li class="tocline"><a class="tocxref" href="#US-disc-human-authentication"><bdi class="secno">2.1.37 </bdi>Discovery Human Authentication</a></li><li class="tocline"><a class="tocxref" href="#US-disc-user-limitations"><bdi class="secno">2.1.38 </bdi>Discovery User Limitations</a></li><li class="tocline"><a class="tocxref" href="#US-disc-alternatives"><bdi class="secno">2.1.39 </bdi>Discovery Alternatives</a></li></ol></li></ol></li><li class="tocline"><a class="tocxref" href="#sec-vertical-ucs"><bdi class="secno">3. </bdi>Domain Specific Use Cases</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#agriculture"><bdi class="secno">3.1 </bdi>Smart Agriculture</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-greenhouse-horticulture-1"><bdi class="secno">3.1.1 </bdi>Greenhouse Horticulture</a></li><li class="tocline"><a class="tocxref" href="#UC-open-field-agriculture-1"><bdi class="secno">3.1.2 </bdi>Open-field Agriculture</a></li><li class="tocline"><a class="tocxref" href="#UC-irrigation-in-outdoor-environment-1"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li><li class="tocline"><a class="tocxref" href="#UC-automatic-milking-system-for-dairy-farm-1"><bdi class="secno">3.1.4 </bdi>Automatic milking system for dairy farm</a></li><li class="tocline"><a class="tocxref" href="#UC-pest-control-in-open-field-1"><bdi class="secno">3.1.5 </bdi>Pest control in Open-field</a></li><li class="tocline"><a class="tocxref" href="#UC-livestock-health-management-1"><bdi class="secno">3.1.6 </bdi>Livestock Health Management</a></li><li class="tocline"><a class="tocxref" href="#UC-agricultural-machinery-management-1"><bdi class="secno">3.1.7 </bdi>Agricultural Machinery Management</a></li></ol></li><li class="tocline"><a class="tocxref" href="#smart-city"><bdi class="secno">3.2 </bdi>Smart City</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-smartcity-geolocation-1"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li><li class="tocline"><a class="tocxref" href="#UC-smartcity-dashboard-1"><bdi class="secno">3.2.2 </bdi>Smart City Dashboard</a></li><li class="tocline"><a class="tocxref" href="#UC-interactive-public-spaces-1"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li><li class="tocline"><a class="tocxref" href="#UC-meeting-room-event-assistance-1"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li><li class="tocline"><a class="tocxref" href="#UC-cross-domain-discovery-in-a-smart-campus-1"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li><li class="tocline"><a class="tocxref" href="#UC-cultural-spaces-museums-1"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li></ol></li><li class="tocline"><a class="tocxref" href="#smart-buildings"><bdi class="secno">3.3 </bdi>Building Technologies</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-smart-building-1"><bdi class="secno">3.3.1 </bdi>Smart Building</a></li><li class="tocline"><a class="tocxref" href="#UC-connected-building-energy-efficiency-1"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li><li class="tocline"><a class="tocxref" href="#UC-automated-smart-building-management-1"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li><li class="tocline"><a class="tocxref" href="#UC-portable-building-applications-1"><bdi class="secno">3.3.4 </bdi>Portable Building Applications</a></li></ol></li><li class="tocline"><a class="tocxref" href="#manufacturing"><bdi class="secno">3.4 </bdi>Manufacturing</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-production-monitoring-1"><bdi class="secno">3.4.1 </bdi>Production Monitoring</a></li><li class="tocline"><a class="tocxref" href="#UC-cross-protocol-interaction-in-industry-4.0-scenarios-1"><bdi class="secno">3.4.2 </bdi>Cross-protocol Interaction in Industry 4.0 Scenarios</a></li></ol></li><li class="tocline"><a class="tocxref" href="#retail"><bdi class="secno">3.5 </bdi>Retail</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-retail-operations-1"><bdi class="secno">3.5.1 </bdi>Retail Operations</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-indoor-door-sensor-1"><bdi class="secno">3.5.3 </bdi>Retail Indoor Door Sensor</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-indoor-and-outdoor-freezers"><bdi class="secno">3.5.4 </bdi>Retail Indoor and Outdoor Freezers</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-kitchen-refrigerator-1"><bdi class="secno">3.5.5 </bdi>Retail Kitchen Refrigerator</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-restroom-devices-1"><bdi class="secno">3.5.6 </bdi>Retail Restroom Devices</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-lighting-control-1"><bdi class="secno">3.5.7 </bdi>Retail Lighting Control</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-outdoor-canopy-lighting-control-1"><bdi class="secno">3.5.8 </bdi>Retail Outdoor Canopy Lighting Control</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-fountain-drink-ice-machine-1"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li><li class="tocline"><a class="tocxref" href="#UC-retail-camera-device-1"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li></ol></li><li class="tocline"><a class="tocxref" href="#health"><bdi class="secno">3.6 </bdi>Health</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#public-health"><bdi class="secno">3.6.1 </bdi>Public Health</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-smart-city-public-health-monitoring-1"><bdi class="secno">3.6.1.1 </bdi>Smart City Public Health Monitoring</a></li><li class="tocline"><a class="tocxref" href="#UC-interconnected-medical-devices-in-a-hospital-icu-1"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li></ol></li><li class="tocline"><a class="tocxref" href="#private-health"><bdi class="secno">3.6.2 </bdi>Private Health</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-health-notifiers-1"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li></ol></li><li class="tocline"><a class="tocxref" href="#Biomedical"><bdi class="secno">3.6.3 </bdi>Biomedical Devices</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-digital-microscopes-1"><bdi class="secno">3.6.3.1 </bdi>Digital Microscopes</a></li></ol></li></ol></li><li class="tocline"><a class="tocxref" href="#energy"><bdi class="secno">3.7 </bdi>Energy</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-smart-grids-1"><bdi class="secno">3.7.1 </bdi>Smart Grids</a></li></ol></li><li class="tocline"><a class="tocxref" href="#UC-transportation-1"><bdi class="secno">3.8 </bdi>Transportation</a></li><li class="tocline"><a class="tocxref" href="#automotive"><bdi class="secno">3.9 </bdi>Automotive</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-smart-car-configuration-management-1"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li></ol></li><li class="tocline"><a class="tocxref" href="#smart-home"><bdi class="secno">3.10 </bdi>Smart Home</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#audio_video"><bdi class="secno">3.10.1 </bdi>Audio/Video</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-home-wot-devices-synchronize-to-tv-programs-1"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li><li class="tocline"><a class="tocxref" href="#UC-leaving-and-coming-home-1"><bdi class="secno">3.10.1.2 </bdi>Leaving and Coming Home</a></li></ol></li><li class="tocline"><a class="tocxref" href="#education"><bdi class="secno">3.10.2 </bdi>Education</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-education-shared-devices-1"><bdi class="secno">3.10.2.1 </bdi>Education Shared Devices</a></li></ol></li></ol></li></ol></li><li class="tocline"><a class="tocxref" href="#sec-horizontal-ucs"><bdi class="secno">4. </bdi>Use Cases for multiple domains</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-discovery-1"><bdi class="secno">4.1 </bdi>Discovery</a></li><li class="tocline"><a class="tocxref" href="#UC-multi-vendor-system-integration-out-of-the-box-interoperability-1"><bdi class="secno">4.2 </bdi>Multi-Vendor System Integration - Out of the box interoperability</a></li><li class="tocline"><a class="tocxref" href="#UC-virtual-thing-1"><bdi class="secno">4.3 </bdi>Virtual Thing</a></li><li class="tocline"><a class="tocxref" href="#digital-twin"><bdi class="secno">4.4 </bdi>Digital Twin</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-digital-twin-1"><bdi class="secno">4.4.1 </bdi>Digital Twin (1)</a></li><li class="tocline"><a class="tocxref" href="#UC-digital-twin-2"><bdi class="secno">4.4.2 </bdi>Digital Twin (2)</a></li></ol></li><li class="tocline"><a class="tocxref" href="#UC-cross-protocol-interworking-1"><bdi class="secno">4.5 </bdi>Cross Protocol Interworking</a></li><li class="tocline"><a class="tocxref" href="#multimodal"><bdi class="secno">4.6 </bdi>Multimodal System Integration</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-multimodal-recognition-support-1"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li><li class="tocline"><a class="tocxref" href="#UC-enhancement-of-synergistic-interactions-1"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li></ol></li><li class="tocline"><a class="tocxref" href="#accessibility"><bdi class="secno">4.7 </bdi>Accessibility</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li></ol></li><li class="tocline"><a class="tocxref" href="#Security"><bdi class="secno">4.8 </bdi>Security</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-oauth2-flows-1"><bdi class="secno">4.8.1 </bdi>OAuth2 Flows</a></li></ol></li><li class="tocline"><a class="tocxref" href="#lifecycle"><bdi class="secno">4.9 </bdi>Lifecycle</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-device-lifecycle-1"><bdi class="secno">4.9.1 </bdi>Device Lifecycle</a></li></ol></li><li class="tocline"><a class="tocxref" href="#vr-ar"><bdi class="secno">4.10 </bdi>VR/AR</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#UC-ar-virtual-guide-1"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li></ol></li><li class="tocline"><a class="tocxref" href="#UC-edge-computing-1"><bdi class="secno">4.11 </bdi>Edge Computing</a></li></ol></li><li class="tocline"><a class="tocxref" href="#sec-use-case-categories"><bdi class="secno">5. </bdi>Use Case Categories</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#CAT-Security-Public-Service"><bdi class="secno">5.1 </bdi>Security Public Service</a></li><li class="tocline"><a class="tocxref" href="#CAT-Security-Private-Information"><bdi class="secno">5.2 </bdi>Security Private Information</a></li><li class="tocline"><a class="tocxref" href="#CAT-Security-Safety-Critical"><bdi class="secno">5.3 </bdi>Security Safety Critical</a></li><li class="tocline"><a class="tocxref" href="#CAT-Security-Business-Critical"><bdi class="secno">5.4 </bdi>Security Business Critical</a></li><li class="tocline"><a class="tocxref" href="#CAT-TD-Creation-Simplification"><bdi class="secno">5.5 </bdi>TD Creation Simplification</a></li></ol></li><li class="tocline"><a class="tocxref" href="#acknowledgements"><bdi class="secno">A. </bdi>Acknowledgments</a></li><li class="tocline"><a class="tocxref" href="#references"><bdi class="secno">B. </bdi>References</a><ol class="toc"><li class="tocline"><a class="tocxref" href="#informative-references"><bdi class="secno">B.1 </bdi>Informative references</a></li></ol></li></ol></nav>
  <section id="intro"><div class="header-wrapper"><h2 id="x1-introduction"><bdi class="secno">1. </bdi>Introduction</h2><a class="self-link" href="#intro" aria-label="Permalink for Section 1."></a></div>
    
    <p>
      The World Wide Web Consortium (<abbr title="World Wide Web Consortium">W3C</abbr>) has published the Web of Things
      (WoT) Architecture [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-architecture" title="Web of Things (WoT) Architecture">wot-architecture</a></cite>] and
	  Web of Things (WoT) Thing Description (TD) [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-thing-description" title="Web of Things (WoT) Thing Description">wot-thing-description</a></cite>]
	  as official <abbr title="World Wide Web Consortium">W3C</abbr> Recommendations, as well as related specifications such
	  as Web of Things (WoT) Discovery [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-discovery" title="Web of Things (WoT) Discovery">wot-discovery</a></cite>].
	  These specifications enable
      easy integration across Internet of Things platforms and applications,
	  and recent charters have continued to expand their applicability.
    </p>
    <p>
      Since the inception of the group the WoT IG has collected use cases
	  to better understand the features needed to enable
      interoperability of Internet of Things (IoT)
      services on a worldwide basis.  
	  These use cases are collected here.
	  To more clearly define general requirements, they have been augmented with a set of user
	  stories that attempt to document the motivations behind specific

	  features in the specifications.
    </p><p>
      The present document gathers and describes new use cases and requirements (in the form of user stories)
      for future standardization work in the WoT standard.
	  Where possible, we have also documented where the current standards already satisfy the listed
	  user stories.
    </p>

    <p>
      This document contains chapters describing user stories and use cases that were contributed by multiple authors.
	  The intention is that additional user stories and use cases will be added in future revisions of this document
	  as necessary.
    </p>

      <section id="terminology"><div class="header-wrapper"><h3 id="x1-1-terminology"><bdi class="secno">1.1 </bdi>Terminology</h3><a class="self-link" href="#terminology" aria-label="Permalink for Section 1.1"></a></div>
        
        This document uses the terminology from WoT Architecture [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-architecture" title="Web of Things (WoT) Architecture">wot-architecture</a></cite>].
	In addition, the following terms are used with the defined meanings:
	<dl>
	<dt><dfn data-lt="WoT Use Case|Use Case" class="lint-ignore" data-plurals="use cases" id="dfn-wot-use-case" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Use Case</dfn></dt>
		<dd>A documented scenario that achieves a specific set of goals for specific users that the WoT should support.
			The purpose of a Use Case is to put required features and usages of WoT standards in context.
			Ideally,
			use cases identify specific needed functionality or gaps in current standards.</dd>

	<dt><dfn data-lt="WoT Use Case Category|Use Case Category" class="lint-ignore" id="dfn-wot-use-case-category" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Use Case Category</dfn></dt>
		<dd>A set of <a href="#dfn-wot-use-case" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-wot-use-case-1">Use Cases</a> with a common property.
			These are used to group <a href="#dfn-wot-use-case" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-wot-use-case-2">Use Cases</a> so they can be referred to easily when defining requirements,
			i.e., <a href="#dfn-wot-user-story" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-wot-user-story-1">User Stories</a>.</dd>
	<dt><dfn data-lt="WoT Requirement|Requirement" class="lint-ignore" id="dfn-wot-requirement" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Requirement</dfn></dt>
		<dd>A condition or capability needed by a user to solve a problem or achieve an objective;
			a Requirement may also be a condition or capability that must be met or possessed by a system or system component to
			satisfy another formally imposed document,
			such as an external standard [<cite><a class="bibref" data-link-type="biblio" href="#bib-swebokv4" title="Guide to the Software Engineering Body of Knowledge (SWEBOK Guide), Version 4.0">SWEBOKv4</a></cite>].</dd>

	<dt><dfn data-lt="WoT User Story|User Story" class="lint-ignore" data-plurals="user stories" id="dfn-wot-user-story" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">User Story</dfn></dt>
		<dd>Relates a specific feature or set of features (or proposed features) in the WoT specifications with its motivation,
			which may reference a <a href="#dfn-wot-use-case" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-wot-use-case-3">Use Case</a>.
			User stories summarize both functional requirements (the purpose) and technical requirements (the feature),
			and also indicate the stakeholder that requires the feature.
			User stories can be expressed in a sentence of the form:
			"As a STAKEHOLDER I need a FEATURE so that PURPOSE."
			User Stories are not detailed requirements;
			these should be maintained elsewhere,
			for example by the responsible Task Force,
			with the User Story linking to them.</dd>

	</dl>
      </section>

      <section id="domains"><div class="header-wrapper"><h3 id="x1-2-domains"><bdi class="secno">1.2 </bdi>Domains</h3><a class="self-link" href="#domains" aria-label="Permalink for Section 1.2"></a></div>
      
      <p>
        The collection of use cases in this document can be separated into two categories:
      </p><ul>
        <li>Domain-specific (vertical) use cases for a single application domain.</li>

        <li>Horizontal use cases that address multiple domains.</li>
      </ul>
      Domain specific use cases are described in <a href="#sec-vertical-ucs" class="sec-ref"><bdi class="secno">3. </bdi>Domain Specific Use Cases</a>,
      horizontal use cases are described in <a href="#sec-horizontal-ucs" class="sec-ref"><bdi class="secno">4. </bdi>Use Cases for multiple domains</a>
      <p></p>
      </section>
	    
    <section id="stakeholders"><div class="header-wrapper"><h3 id="x1-3-stakeholders-and-roles"><bdi class="secno">1.3 </bdi>Stakeholders and Roles</h3><a class="self-link" href="#stakeholders" aria-label="Permalink for Section 1.3"></a></div>
      
        <p>
	        Whenever possible, stakeholders should be identified using the terms
	        defined in the WoT Security and Privacy Guidelines [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-security" title="Web of Things (WoT) Security and Privacy Guidelines">wot-security</a></cite>].
	        For convenience these terms are listed here, but please refer to that
	        document for full definitions:
	      </p>
	    <dl>
        <dt>
          <dfn data-lt="Stakeholder Device Manufacturer|Device Manufacturer" class="lint-ignore" data-plurals="device manufacturers" id="dfn-stakeholder-device-manufacturer" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Device Manufacturer</dfn>
        </dt>
        <dd>
          An individual, company, or organization that designs and develops networked or IoT devices to be sold to consumers.
        </dd>
        <dt>
          <dfn date-lt="Stakeholder System Provider" class="lint-ignore" id="dfn-system-provider" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">System Provider</dfn>
        </dt>
        <dd>
          An individual, company, or organization that provides systems, such as network systems and IoT systems, to other individuals or organizations.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder System Integrator|System Integrator" class="lint-ignore" id="dfn-stakeholder-system-integrator" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">System Integrator</dfn>
        </dt>
        <dd>
          An individual, company, or organization that specializes in integrating and linking network systems, IoT systems, etc.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder System Installer|System Installer" class="lint-ignore" id="dfn-stakeholder-system-installer" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">System Installer</dfn>
        </dt>
        <dd>
          An individual, company, or organization that sets up and makes available systems and devices.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder System User|System User" class="lint-ignore" data-plurals="system users" id="dfn-stakeholder-system-user" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">System User</dfn>
        </dt>
        <dd>
          A person, company, or organization that uses an application or IoT system.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder System Owner|System Owner" class="lint-ignore" id="dfn-stakeholder-system-owner" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">System Owner</dfn>
        </dt>
        <dd>
          A person, company, or organization that has management responsibility for a network system or IoT system.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder System Maintainer|System Maintainer" class="lint-ignore" id="dfn-stakeholder-system-maintainer" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">System Maintainer</dfn>
        </dt>
        <dd>
          A person, company, or organization that maintains, supports, and operates a network system or IoT system.
        </dd>
      </dl>
      <p>
        The following additional stakeholders and roles were identified
        when the use cases were collected, or are defined in other WoT documents:
      </p>
      <dl>
        <dt>
          <dfn data-lt="Stakeholder Device Owner|Device Owner" class="lint-ignore" data-plurals="device owners" id="dfn-stakeholder-device-owner" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Device Owner</dfn>
        </dt>
        <dd>
          A special case of <a href="#dfn-stakeholder-system-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-owner-1">System Owner</a> when some devices in a system may have different owners, or when the focus is on the ownership of a specific device.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder Device User|Device User" class="lint-ignore" data-plurals="device users" id="dfn-stakeholder-device-user" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Device User</dfn>
        </dt>
        <dd>
          A human interacting with an actual physical user interface of a device, or whose environment may be sensed or modified by a device.
		  May also be used when referring to a data or network service provided by a particular device.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder Cloud Provider|Cloud Provider" class="lint-ignore" data-plurals="cloud providers" id="dfn-stakeholder-cloud-provider" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Cloud Provider</dfn>
        </dt>
        <dd>
          An organization providing remote computing services available over a network.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder Service Provider|Service Provider" class="lint-ignore" data-plurals="service providers" id="dfn-stakeholder-service-provider" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Service Provider</dfn>
        </dt>
        <dd>
          An organization or entity, which may be local or remote, that provides a specific (network) service.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder Gateway Manufacturer|Gateway Manufacturer" class="lint-ignore" id="dfn-stakeholder-gateway-manufacturer" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Gateway Manufacturer</dfn>
        </dt>
        <dd>
          A special case of <a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-1">Device Manufacturer</a> where a device is not an endpoint IoT device,
		  but a device whose focus is on providing network services such as firewalls,
		  address translation, name services, caching, brokers, registries, or directories.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder Identity Provider|Identity Provider" class="lint-ignore" id="dfn-stakeholder-identity-provider" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Identity Provider</dfn>
        </dt>
        <dd>
          A special case of a <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-1">Service Provider</a> that provides a mechanism to identify or authenticate entities and users.
        </dd>
        <dt>
          <dfn data-lt="Stakeholder Directory Service Provider|Directory Service Provider" class="lint-ignore" id="dfn-stakeholder-directory-service-provider" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Directory Service Provider</dfn>
        </dt>
        <dd>
          A special case of a <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-2">Service Provider</a> that provides a directory service,
		  such as the Thing Description Directory (TD Directory) service described in WoT Discovery [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-discovery" title="Web of Things (WoT) Discovery">wot-discovery</a></cite>].
	      </dd>
        <dt>
          <dfn data-lt="Stakeholder TD Consumer|TD Consumer" class="lint-ignore" data-plurals="td consumers" id="dfn-stakeholder-td-consumer" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">TD Consumer</dfn>
        </dt>
        <dd>
          An entity that reads and interprets a WoT Thing Description [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-thing-description" title="Web of Things (WoT) Thing Description">wot-thing-description</a></cite>].
        </dd>
        <dt>
	        <dfn data-lt="Stakeholder TD Server|TD Server" class="lint-ignore" id="dfn-stakeholder-td-server" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">TD Server</dfn>
        </dt>
        <dd>
          An entity that provides a WoT Thing Description [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-thing-description" title="Web of Things (WoT) Thing Description">wot-thing-description</a></cite>].
		  A TD Server may or may not be on the same physical device as the Thing described in the TD it provides.
		  Defined in WoT Discovery [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-discovery" title="Web of Things (WoT) Discovery">wot-discovery</a></cite>].
        </dd>
        <dt>
          <dfn data-lt="Stakeholder TD Directory|TD Directory" class="lint-ignore" id="dfn-stakeholder-td-directory" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">TD Directory</dfn>
        </dt>
        <dd>
          A special case of a <a href="#dfn-stakeholder-directory-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-directory-service-provider-1">Directory Service Provider</a> and a <a href="#dfn-stakeholder-td-server" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-td-server-1">TD Server</a>,
		  defined in WoT Discovery [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-discovery" title="Web of Things (WoT) Discovery">wot-discovery</a></cite>],
		  that provides a searchable registry for Thing Descriptions (TDs).
        </dd>
      </dl>
    </section>
  </section>

  

  <section id="requirements"><div class="header-wrapper"><h2 id="x2-requirements"><bdi class="secno">2. </bdi>Requirements</h2><a class="self-link" href="#requirements" aria-label="Permalink for Section 2."></a></div>
    

    <section id="sec-user-stories"><div class="header-wrapper"><h3 id="x2-1-user-stories"><bdi class="secno">2.1 </bdi>User Stories</h3><a class="self-link" href="#sec-user-stories" aria-label="Permalink for Section 2.1"></a></div>
      
      <p>User stories provide a high-level summary of a requirement in the form of
      a single sentence that describes a stakeholder (Who has the need),
      a technical requirement (What they need; a capability or condition; features),
      and a functional requirement (Why they need it; the purpose or motivation; use cases).
      These are often stated in the form of a sentence: "As a <em>Who</em> I need <em>What</em> so that I can <em>Why</em>."
      For clarity, the following user stories break out each part in a list.
      Each user story will in addition identify one or more Use Case (or Use Case Categories)
      that establishes the motivation for the identified capability.
      Capabilities correspond to sets of features in other technical specifications.
      </p>
      <div class="note" id="issue-container-generatedID"><div role="heading" class="ednote-title marker" id="h-ednote" aria-level="4"><span>Editor's note</span></div><p class="">Define how user stories and features are linked.  We can link back from 
      implemented features to user stories, but want to avoid unstable links e.g. to documents
      maintained in github.  If we have bidirectional links we need some mechanism to keep them
      consistent.</p></div>
      <section id="US-connection-oriented-protocols"><div class="header-wrapper"><h4 id="x2-1-1-connection-oriented-protocols"><bdi class="secno">2.1.1 </bdi>Connection Oriented Protocols</h4><a class="self-link" href="#US-connection-oriented-protocols" aria-label="Permalink for Section 2.1.1"></a></div>
	      
	      <dl><dt>Status:</dt><dd>Work in Progress</dd>
		  <dt>Submitters:</dt><dd>Ege Korkan</dd>
		  <dt>Who (As a...):</dt><dd>Deployer of devices with connection oriented protocols.</dd>
	          <dt>What (I need...):</dt><dd><p>Reusable Connection descriptions in a TD.</p>
		      <dl>
	              <dt>Capability Details:</dt><dd>For protocols that are based on an initial connection and then subsequent messages, 
	                 a Consumer can reuse the initial connection rather than opening a new connection each time.</dd>
		      </dl>
                  </dd><dt>Why (so that...):</dt><dd><p>Better describe connection oriented protocols such as MQTT and WebSockets.</p>
		      <dl>
	              <dt>Motivating Use Case:</dt><dd><a href="#UC-open-field-agriculture-1" data-matched-text="[[[#UC-open-field-agriculture-1]]]" class="sec-ref"><bdi class="secno">3.1.2 </bdi>Open-field Agriculture</a></dd>
		      </dl>
	          </dd>
	      </dl>
	      <p></p>
      </section>
      <section id="US-reusable-defaults-per-TD"><div class="header-wrapper"><h4 id="x2-1-2-reusable-defaults-per-td"><bdi class="secno">2.1.2 </bdi>Reusable Defaults per TD</h4><a class="self-link" href="#US-reusable-defaults-per-TD" aria-label="Permalink for Section 2.1.2"></a></div>
	      
	      <dl><dt>Status:</dt><dd>Work in Progress</dd>
		  <dt>Submitters:</dt><dd>Ege Korkan</dd>
                  <dt>Who (As a...):</dt><dd>Designer/Developer of TDs</dd>
	          <dt>What (I need...):</dt><dd>Reusable Connection descriptions in a TD</dd>
	          <dt>Why (so that...):</dt><dd><p>Simplify TDs in cases without usage of default terms or to avoid redundancy</p>
		     <dl>
	               <dt>Motivating Use Case Category:</dt><dd><p><a href="#CAT-TD-Creation-Simplification" data-matched-text="[[[#CAT-TD-Creation-Simplification]]]" class="sec-ref"><bdi class="secno">5.5 </bdi>TD Creation Simplification</a>.</p>
	               </dd><dt>Details:</dt><dd><p>There are at least three sub-problems that motivate this feature:</p>
	                <ol><li>If the media type is common across forms but is not <code>application/json</code>, it otherwise needs to be repeated in each form.</li>
                            <li>If there are common protocol stack configurations such as different default verbs, baud rates, and endianness, they otherwise need to be repeated in each form.</li>
                            <li>Multiple bases are not otherwise possible, so each form repeats multiple bases. This is relevant (for example) when a TD has both local and public IP addresses.</li>
	                </ol>
		       </dd>
		     </dl>
	       </dd>
	      </dl>
      </section>
      <section id="td-byte-ordering"><div class="header-wrapper"><h4 id="x2-1-3-byte-ordering-for-binary-data-formats"><bdi class="secno">2.1.3 </bdi>Byte Ordering for Binary Data Formats</h4><a class="self-link" href="#td-byte-ordering" aria-label="Permalink for Section 2.1.3"></a></div>
        
        <dl>
	  <dt>Status:</dt><dd>Work in Progress</dd>          
	  <dt>Submitters:</dt>
            <dd>
              Ege Korkan, Michael McCool
            </dd>
          <dt>Who (As a...):</dt>
            <dd>
              <p><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-2">Device manufacturer</a></p>
          <dl><dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-td-consumer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-td-consumer-1">TD Consumer</a>
            </dd></dl></dd>
          <dt>What (I need...)</dt>
            <dd>
              <p>Express the byte ordering of data from my devices in binary protocols (such as Modbus, Profinet, etc)</p>
          <dl><dt>Design:</dt>
            <dd>
              <ul>
		<li><a href="https://w3c.github.io/wot-binding-templates/bindings/protocols/modbus/#form-terms">https://w3c.github.io/wot-binding-templates/bindings/protocols/modbus/#form-terms</a></li>
                <li><a href="https://github.com/w3c/wot-binding-templates/pull/331">feat(modbus): introduce modbus type and byte/word order&nbsp;wot-binding-templates#331</a></li>
              </ul>
            </dd></dl></dd>
          <dt>Why (so that...):</dt>
            <dd>
              <p><a href="#dfn-stakeholder-td-consumer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-td-consumer-2">TD Consumers</a> can communicate with my devices</p>
          <dl>  
	  <dt>Related Issues:</dt>
	  <dd>
	  <ul>
		<li><a href="https://github.com/w3c/wot-usecases/issues/345">Issue 345</a></li>
	  </ul>
	  </dd>
          <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#UC-production-monitoring-1" data-matched-text="[[[#UC-production-monitoring-1]]]" class="sec-ref"><bdi class="secno">3.4.1 </bdi>Production Monitoring</a></li>
                <li><a href="#UC-smart-grids-1" data-matched-text="[[[#UC-smart-grids-1]]]" class="sec-ref"><bdi class="secno">3.7.1 </bdi>Smart Grids</a></li>
                <li><a href="#UC-smart-building-1" data-matched-text="[[[#UC-smart-building-1]]]" class="sec-ref"><bdi class="secno">3.3.1 </bdi>Smart Building</a></li>
            </ul></dd></dl></dd>
        </dl>
      </section>
      <section id="td-polling-rate-limit"><div class="header-wrapper"><h4 id="x2-1-4-polling-rate-limit"><bdi class="secno">2.1.4 </bdi>Polling Rate Limit</h4><a class="self-link" href="#td-polling-rate-limit" aria-label="Permalink for Section 2.1.4"></a></div>
        
          <dl>
	<dt>Status:</dt><dd>Work in Progress</dd>
	<dt>Submitters:</dt>
              <dd>
                Ege Korkan, Michael McCool
              </dd>
            <dt>Who (As a...):</dt>
              <dd>
                <p><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-3">Device manufacturer</a></p> 
            <dl><dt>Other Stakeholders:</dt>
              <dd>
                <a href="#dfn-stakeholder-td-consumer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-td-consumer-3">TD Consumer</a>
              </dd></dl></dd>
            <dt>What (I need...):</dt>
              <dd>
                <p>Express the polling rate limit from devices without event notifications (such as Modbus, Profinet, etc.)</p>
            <dl><dt>Design:</dt>
              <dd>
                <ul>
		  <li><a href="https://w3c.github.io/wot-binding-templates/bindings/protocols/modbus/#form-terms">https://w3c.github.io/wot-binding-templates/bindings/protocols/modbus/#form-terms</a></li>
                </ul>
              </dd></dl></dd>
            <dt>Why (so that...):</dt>
              <dd>
                <p><a href="#dfn-stakeholder-td-consumer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-td-consumer-4">TD Consumers</a> can use an appropriate polling rate</p>
            <dl>
	      <dt>Related Issues:</dt>
	      <dd>
	       <ul>
		<li><a href="https://github.com/w3c/wot-usecases/issues/346">Issue 346</a></li>
	       </ul>
	      </dd>
	      <dt>Motivating Use Cases:</dt>
              <dd>
                <ul>
                  <li><a href="#UC-production-monitoring-1" data-matched-text="[[[#UC-production-monitoring-1]]]" class="sec-ref"><bdi class="secno">3.4.1 </bdi>Production Monitoring</a></li>
                  <li><a href="#UC-smart-grids-1" data-matched-text="[[[#UC-smart-grids-1]]]" class="sec-ref"><bdi class="secno">3.7.1 </bdi>Smart Grids</a></li>
                  <li><a href="#UC-smart-building-1" data-matched-text="[[[#UC-smart-building-1]]]" class="sec-ref"><bdi class="secno">3.3.1 </bdi>Smart Building</a></li>
              </ul></dd></dl></dd>
          </dl>
      </section>
      

          

 
    <section id="US-sec-mitigate-pbt"><div class="header-wrapper"><h4 id="x2-1-5-mitigate-wot-protocol-binding-threat"><bdi class="secno">2.1.5 </bdi>Mitigate WoT Protocol Binding Threat</h4><a class="self-link" href="#US-sec-mitigate-pbt" aria-label="Permalink for Section 2.1.5"></a></div>
      
      <p>Remote attack methods using a WoT protocol binding with the intent to gain
      unauthorized access to WoT assets should be mitigated.</p>
      <dl>
	<dt>Status:</dt><dd>Satisfied</dd>
        <dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-1">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-1">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>Access controls, authentication, and authorization mechanisms.</p>
	  <dl>
            <dt>Capability Details:</dt>
            <dd>
              <p>The network interfaces of WoT devices and services should support appropriate security mechanisms for each protocol.</p>
            </dd>
	    <dt>Realization:</dt>
	<dd>
	      <ul> 
		<li><a href="https://w3c.github.io/wot-thing-description/#sec-security-vocabulary-definition">WoT Thing Description: Security Vocabulary Definitions</a></li>
	      </ul> 
	</dd>           
          </dl>        
	</dd>
        <dt>Why (so that...):</dt>
        <dd>
          <p>Prevent unauthorized malicious access to WoT assets.</p>
	  <dl>
	    <dt>Related Risks:</dt>
	    <dd>
	      <ul>
	        <li><a href="https://w3c.github.io/wot-security/#dfn-wot-protocol-binding-threat">WoT Protocol Binding Threat</a></li>
	      </ul>
	    </dd>
            <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Private-Information" data-matched-text="[[[#CAT-Security-Private-Information]]]" class="sec-ref"><bdi class="secno">5.2 </bdi>Security Private Information</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-sec-mitigate-etc"><div class="header-wrapper"><h4 id="x2-1-6-mitigate-exposed-thing-compromise-threat"><bdi class="secno">2.1.6 </bdi>Mitigate Exposed Thing Compromise Threat</h4><a class="self-link" href="#US-sec-mitigate-etc" aria-label="Permalink for Section 2.1.6"></a></div>
      
      <p>Remote attack methods using the exposed WoT interface described by a WoT Thing Description with the intent to gain
      unauthorized access to WoT assets should be mitigated.</p>
      <dl>
	<dt>Status:</dt><dd>Satisfied</dd>
        <dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-2">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-2">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>Access controls, authentication, and authorization mechanisms.</p>
	  <dl>
            <dt>Capability Details:</dt>
            <dd>
              <p>The network interfaces of WoT devices and services should support appropriate security mechanisms for each protocol.</p>
	    </dd>
	    <dt>Realization:</dt><dd>
	      <ul> 
		<li><a href="https://w3c.github.io/wot-thing-description/#sec-security-vocabulary-definition">WoT Thing Description: Security Vocabulary Definitions</a></li>
	      </ul>  
	    </dd>
          </dl>        
	</dd>
        <dt>Why (so that...):</dt>
        <dd>
          <p>Prevent unauthorized malicious access to WoT assets.</p>
	  <dl>
	    <dt>Related Risks:</dt>
	    <dd> 
	      <ul>
	        <li><a href="https://w3c.github.io/wot-security/#dfn-wot-interface-threat-exposed-thing-compromise">WoT Interface
                       Threat - Exposed Thing Compromise</a></li>
	      </ul>
	    </dd>
            <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Private-Information" data-matched-text="[[[#CAT-Security-Private-Information]]]" class="sec-ref"><bdi class="secno">5.2 </bdi>Security Private Information</a></li>
                <li><a href="#CAT-Security-Safety-Critical" data-matched-text="[[[#CAT-Security-Safety-Critical]]]" class="sec-ref"><bdi class="secno">5.3 </bdi>Security Safety Critical</a></li>
                <li><a href="#CAT-Security-Business-Critical" data-matched-text="[[[#CAT-Security-Business-Critical]]]" class="sec-ref"><bdi class="secno">5.4 </bdi>Security Business Critical</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-sec-access-control"><div class="header-wrapper"><h4 id="x2-1-7-security-access-control"><bdi class="secno">2.1.7 </bdi>Security Access Control</h4><a class="self-link" href="#US-sec-access-control" aria-label="Permalink for Section 2.1.7"></a></div>
      
      <p>Control and manage access to WoT assets to prevent misuse by unauthorized attackers.</p>
      <dl>
        <dt>Status:</dt><dd>Satisfied</dd>
        <dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-3">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-3">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>Ability to restrict access to WoT assets to specific authenticated users, and verify their authority to use specific assets.</p>
	  <dl>
            <dt>Capability Details:</dt>
            <dd>
              <p>The architecture of WoT services, such as directory services and self-description,
	      should allow for authentication and authorization checks before releasing any information.</p>
	    </dd>
	    <dt>Realization:</dt><dd>
	      <ul>
		<li><a href="https://www.w3.org/TR/wot-discovery/#architecture">WoT Discovery: Architecture</a></li>
		<li><a href="https://w3c.github.io/wot-thing-description/#sec-security-vocabulary-definition">WoT Thing Description: Security Vocabulary Definitions</a></li>
	      </ul>
	    </dd>
          </dl>        
	</dd>
        <dt>Why (so that...):</dt>
        <dd>
          <p>Prevent unauthorized malicious use of WoT assets.</p>
	  <dl>
            <dt>Related Risks:</dt>
	    <dd>
	      <ul>
	        <li><a href="https://w3c.github.io/wot-security/#dfn-wot-interface-threat-unauthorized-wot-interface-access">WoT
                        Interface Threat - Unauthorized WoT Interface Access</a></li>
	      </ul>
	    </dd>
            <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Private-Information" data-matched-text="[[[#CAT-Security-Private-Information]]]" class="sec-ref"><bdi class="secno">5.2 </bdi>Security Private Information</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-sec-mitigate-dos"><div class="header-wrapper"><h4 id="x2-1-8-mitigate-wot-dos-threat"><bdi class="secno">2.1.8 </bdi>Mitigate WoT DoS Threat</h4><a class="self-link" href="#US-sec-mitigate-dos" aria-label="Permalink for Section 2.1.8"></a></div>
      
      <p>Prevent Denial-of-Service attacks on WoT services by malicious attackers that prevent legitimate usage by authorized users.</p>
      <dl>
	<dt>Status:</dt><dd>Satisfied</dd>
        <dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-4">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-4">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>The ability to ensure access to WoT services by authorized users even when subjected to malicious network attacks.</p>
          <dl>
            <dt>Capability Details:</dt>
            <dd>
              <p>An attacker may attempt to block access by other users to a WoT service by, for example,
	      sending a device numerous requests to keep it too busy to respond to other authorized users.
	      Devices implementations should implement best practices to mitigate these attacks.</p>
	    </dd>
	    <dt>Realization:</dt>
            <dd><ul>
		<li><a href="https://www.w3.org/TR/wot-discovery/#security-consideration-dos">WoT Discovery: Denial of Service</a></li>
	      </ul>            
          </dd></dl>
        </dd>
        <dt>Why (so that...):</dt>
        <dd>
          <p>WoT services can always be available to authorized users.</p>
          <dl>
	    <dt>Related Risks:</dt>
            <dd>
	      <ul>
                <li><a href="https://w3c.github.io/wot-security/#dfn-wot-dos-threat">WoT DoS Threat</a></li>
	      </ul>            
	    </dd>
            <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Public-Service" data-matched-text="[[[#CAT-Security-Public-Service]]]" class="sec-ref"><bdi class="secno">5.1 </bdi>Security Public Service</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-sec-mitigate-ddos"><div class="header-wrapper"><h4 id="x2-1-9-mitigate-wot-ddos-threat"><bdi class="secno">2.1.9 </bdi>Mitigate WoT DDoS Threat</h4><a class="self-link" href="#US-sec-mitigate-ddos" aria-label="Permalink for Section 2.1.9"></a></div>
      
      <p>Prevent use of WoT services for Distributed Denial-of-Service attacks on other services.</p>
      <dl>
        <dt>Status:</dt><dd>Satisfied</dd>
	<dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-5">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-5">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>Prevent usage of WoT services for distributed denial of service attacks.</p>
	  <dl>
            <dt>Realization:</dt>
            <dd>
              <ul>
		<li><a href="https://www.w3.org/TR/wot-discovery/#security-consideration-amp-ddos">WoT Discovery: Amplification and Distributed Denial of Service</a></li>
	      </ul>
            </dd>
          </dl>	
	</dd>
        <dt>Why (so that...):</dt>
        <dd>
          <p>WoT devices are not used maliciously to prevent access to other services.</p>
          <dl>
            <dt>Related Risks:</dt>
            <dd>
	      <ul>
                <li><a href="https://w3c.github.io/wot-security/#dfn-wot-ddos-threat">WoT DDoS Threat</a></li>
	      </ul>
            </dd>
	    <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Public-Service" data-matched-text="[[[#CAT-Security-Public-Service]]]" class="sec-ref"><bdi class="secno">5.1 </bdi>Security Public Service</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-sec-mitigate-ctda"><div class="header-wrapper"><h4 id="x2-1-10-mitigate-communication-threat-td-authenticity"><bdi class="secno">2.1.10 </bdi>Mitigate Communication Threat - TD Authenticity</h4><a class="self-link" href="#US-sec-mitigate-ctda" aria-label="Permalink for Section 2.1.10"></a></div>
      
      <p>Descriptions of WoT interfaces, for example in TDs, should be accurate and modification by unauthorized third parties should be prevented to avoid spoofing, redirection, and other attacks.</p>
      <dl>
	<dt>Status:</dt><dd>Satisfied</dd>
        <dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-6">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-6">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>The ability to prevent WoT TDs from unauthorized modification.</p>
	  <dl>
	  <dt>Realization:</dt>
            <dd>
              <ul>
		<li><a href="https://www.w3.org/TR/wot-discovery/#security-consideration-lan-self-discovery">WoT Discovery: Self-Discovery on LANs</a></li>
	      </ul>
            </dd>
	  </dl>
	</dd>
        <dt>Why (so that...):</dt>
        <dd>
          <p>Modification of WoT TDs cannot be used for spoofing or redirection attacks.</p>
          <dl>
	    <dt>Related Risks:</dt>
            <dd>
	      <ul>
                <li><a href="https://w3c.github.io/wot-security/#dfn-wot-communication-threat-td-authenticity">WoT
                   Communication Threat - TD Authenticity</a></li>
	      </ul>
            </dd>
	    <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Public-Service" data-matched-text="[[[#CAT-Security-Public-Service]]]" class="sec-ref"><bdi class="secno">5.1 </bdi>Security Public Service</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-sec-mitigate-ctdcp"><div class="header-wrapper"><h4 id="x2-1-11-mitigate-communication-threat-td-confidentiality-and-privacy"><bdi class="secno">2.1.11 </bdi>Mitigate Communication Threat - TD Confidentiality and Privacy</h4><a class="self-link" href="#US-sec-mitigate-ctdcp" aria-label="Permalink for Section 2.1.11"></a></div>
      
      <p>Prevent interception of confidential device metadata by unauthorized third parties to avoid releasing information that might be used to plan attacks or to infer private information.</p>
      <dl>
        <dt>Status:</dt><dd>Satisfied</dd>
	<dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-7">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-7">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>The ability to restrict access to metadata, such as Thing Descriptions, to authorized users only.</p>
	  <dl>
            <dt>Realization:</dt>
            <dd>
              <ul>
		<li><a href="https://www.w3.org/TR/wot-discovery/#architecture">WoT Discovery: Architecture</a></li>
		<li><a href="https://www.w3.org/TR/wot-discovery/#security-consideration-lan-self-discovery">WoT Discovery: Self-Discovery on LANs</a></li>
	      </ul>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...):</dt>
        <dd>
          <p>Unauthorized users cannot use confidential metadata to plan attacks or to infer private information about users, <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-1">Device Owners</a>, or other stakeholders.</p>
          <dl>
	    <dt>Related Risks:</dt>
            <dd>
	      <ul>
                <li><a href="https://w3c.github.io/wot-security/#dfn-wot-communication-threat-td-confidentiality-and-privacy">WoT
                Communication Threat - TD Confidentiality and Privacy</a></li>
	      </ul>
            </dd>
            <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Public-Service" data-matched-text="[[[#CAT-Security-Public-Service]]]" class="sec-ref"><bdi class="secno">5.1 </bdi>Security Public Service</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-sec-mitigate-csuda"><div class="header-wrapper"><h4 id="x2-1-12-mitigate-communication-threat-system-user-data-authenticity"><bdi class="secno">2.1.12 </bdi>Mitigate Communication Threat - System User Data Authenticity</h4><a class="self-link" href="#US-sec-mitigate-csuda" aria-label="Permalink for Section 2.1.12"></a></div>
      
      <p>Data related to <a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-8">system users</a>, such as identity or access rights, should be confirmed before access is granted.</p>
      <dl>
	<dt>Status:</dt><dd>Satisfied</dd>
        <dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-9">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-8">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>The ability to confirm the accuracy (authenticity) of <a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-10">system user</a> data, such as access rights or identity.</p>
          <dl>
            <dt>Capability Details:</dt>
            <dd>
              <p>In some cases, anonymous access to system services may be required.  In this case there should be a mechanism
	      to authenticate access rights only, such as bearer tokens, with user identity confirmed separately.</p>
	    </dd>
            <dt>Realization:</dt>
            <dd>
              <ul>
		<li><a href="https://www.w3.org/TR/wot-discovery/#architecture">WoT Discovery: Architecture</a></li>
		<li><a href="https://w3c.github.io/wot-thing-description/#sec-security-vocabulary-definition">WoT Thing Description: Security Vocabulary Definitions</a></li>
	      </ul>
            </dd>
          </dl>            
	    </dd>
          </dl>
        
        <dt>Why (so that...):</dt>
        <dd>
          <p>Unauthorized access to a system is not made available to unauthenticated attackers posing as authorized <a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-11">system users</a>.</p>
          <dl>
	    <dt>Related Risks:</dt>
            <dd>
	      <ul>
                <li><a href="https://w3c.github.io/wot-security/#dfn-wot-communication-threat-system-user-data-authenticity">WoT
                Communication Threat - System User Data Authenticity</a></li>
	      </ul>
            </dd>            
	    <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Public-Service" data-matched-text="[[[#CAT-Security-Public-Service]]]" class="sec-ref"><bdi class="secno">5.1 </bdi>Security Public Service</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      
    </section>

    <section id="US-sec-mitigate-csudcp"><div class="header-wrapper"><h4 id="x2-1-13-mitigate-communication-threat-system-user-data-confidentiality-and-privacy"><bdi class="secno">2.1.13 </bdi>Mitigate Communication Threat - System User Data Confidentiality and Privacy</h4><a class="self-link" href="#US-sec-mitigate-csudcp" aria-label="Permalink for Section 2.1.13"></a></div>
      
      <p>The identity and other private information of systems users, including whenever possible what services they are accessing, should be kept confidential.</p>
      <dl>
	<dt>Status:</dt><dd>Satisfied</dd>
        <dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-12">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-9">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>The ability to maintain the confidentiality of <a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-13">system user</a> data.</p>
          <dl>
            <dt>Capability Details:</dt>
            <dd>
              <p>The identities of users should not be revealed in general to third parties, and in some cases not even to the device (using, for example, separation of authentication/identity and authorization capabilities).
	      There also should be mechanisms in place to prevent visibility to third parties of which services are being accessed by <a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-14">system users</a>.</p>
	    </dd>
            <dt>Realization:</dt>
            <dd>
              <ul>
		<li><a href="https://www.w3.org/TR/wot-discovery/#architecture">WoT Discovery: Architecture</a></li>
	        <li><a href="https://www.w3.org/TR/wot-discovery/#privacy-considerations">WoT Discovery: Privacy Considerations</a></li>		
		<li><a href="https://w3c.github.io/wot-thing-description/#sec-security-vocabulary-definition">WoT Thing Description: Security Vocabulary Definitions</a></li>
	      </ul>
            </dd>
          </dl>
            </dd>
          </dl>
        
        <dt>Why (so that...):</dt>
        <dd>
          <p>Private information about <a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-15">system users</a> is not revealed to unauthorized third parties.</p>
          <dl>
            <dt>Related Risks:</dt>
            <dd>
	       <ul>
                 <li><a href="https://w3c.github.io/wot-security/#dfn-wot-communication-threat-system-user-data-confidentiality-and-privacy">WoT
                    Communication Threat - System User Data Confidentiality and Privacy</a></li>
	       </ul>
            </dd>
	    <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Public-Service" data-matched-text="[[[#CAT-Security-Public-Service]]]" class="sec-ref"><bdi class="secno">5.1 </bdi>Security Public Service</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      
    </section>

    <section id="US-sec-mitigate-csc"><div class="header-wrapper"><h4 id="x2-1-14-mitigate-communication-threat-side-channels"><bdi class="secno">2.1.14 </bdi>Mitigate Communication Threat - Side Channels</h4><a class="self-link" href="#US-sec-mitigate-csc" aria-label="Permalink for Section 2.1.14"></a></div>
      
      <p>Mitigations to prevent interception and/or modification by unauthorized third parties should be available for all communications, including the transmission of metadata (e.g., TDs).</p>
      <dl>
	<dt>Status:</dt><dd>Satisfied</dd>
        <dt>Submitters:</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Who (As a...):</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-16">System User</a></p>
          <dl>
            <dt>Other Stakeholders:</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-10">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...):</dt>
        <dd>
          <p>The ability to secure communications so it cannot be intercepted or modified by unauthorized third parties</p>
          <dl>
            <dt>Capability Details:</dt>
            <dd>
              <p>This can be supported by encrypted communication channels, a precondition for which is authentication of the authorized participants in the communication.
	      The encrypted communication also needs to ensure the integrity of the communication; it not only should not be possible in general for 
	      an unauthorized party to read communications, they should also not be able to modify communications without detection.</p>
            </dd><dt>Realization:</dt>
            <dd>
              <ul>
		<li><a href="https://www.w3.org/TR/wot-discovery/#architecture">WoT Discovery: Architecture</a></li>
	        <li><a href="https://www.w3.org/TR/wot-discovery/#privacy-considerations">WoT Discovery: Privacy Considerations</a></li>		
		<li><a href="https://w3c.github.io/wot-thing-description/#sec-security-vocabulary-definition">WoT Thing Description: Security Vocabulary Definitions</a></li>
		<li><a href="https://www.w3.org/TR/wot-architecture11/#sec-security-considerations">WoT Architecture: Security Considerations</a></li>	      
	      </ul>
            </dd>
          </dl>
            </dd>
          </dl>
        
        <dt>Why (so that...):</dt>
        <dd>
          <p>An attacker cannot gain access to confidential information or gain access to WoT assets by manipulation of authorized communications</p>
          <dl>
	   <dt>Related Risks:</dt>
           <dd>
	      <ul>
                 <li><a href="https://w3c.github.io/wot-security/#dfn-wot-communication-threat-side-channels">WoT
                 Communication Threat - Side Channels</a></li>
	      </ul>
            </dd>
	    <dt>Motivating Use Cases:</dt>
            <dd>
              <ul>
                <li><a href="#CAT-Security-Public-Service" data-matched-text="[[[#CAT-Security-Public-Service]]]" class="sec-ref"><bdi class="secno">5.1 </bdi>Security Public Service</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      
    </section>



  


    <section id="US-disc-network-scope"><div class="header-wrapper"><h4 id="x2-1-15-discovery-network-scope"><bdi class="secno">2.1.15 </bdi>Discovery Network Scope</h4><a class="self-link" href="#US-disc-network-scope" aria-label="Permalink for Section 2.1.15"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-17">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-11">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support peer-to-peer (self-identifying), local (network segment),
            and global (internet-wide) discovery</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Discovery should include the ability to discover devices at multiple scales.
	      Scales should include both local networks
	      (e.g. on a single subnet, such as on a LAN) and internet-scale discovery
	      (e.g. discovering services made available by a city).
	      Devices and services discovered at different scales should be consolidated through
	      a common discovery abstraction even if different mechanisms are required for
	      implementation.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>IoT services and devices can be located and their descriptions retrieved independently of network location.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-via-third-party-services"><div class="header-wrapper"><h4 id="x2-1-16-discovery-via-third-party-services"><bdi class="secno">2.1.16 </bdi>Discovery via Third Party Services</h4><a class="self-link" href="#US-disc-via-third-party-services" aria-label="Permalink for Section 2.1.16"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-18">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-12">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support discovery via third-party services</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
	            <p>Discovery should include the ability to discover devices via a third-party services, such as directory service.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>To support sleeping devices, brownfield devices (devices whose interfaces can be described by WoT but for which
          explicit, built-in support is not included in their design), small devices (that cannot self-describe for capability reasons),
          cross-network discovery (for scalability and security reasons, small devices may not want to be directly discoverable outside the local
	        network), and to search over collections.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-via-scripting-api"><div class="header-wrapper"><h4 id="x2-1-17-discovery-via-scripting-api"><bdi class="secno">2.1.17 </bdi>Discovery via Scripting API</h4><a class="self-link" href="#US-disc-via-scripting-api" aria-label="Permalink for Section 2.1.17"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Partially satisfied. Not all features supported.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-19">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-13">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Compatibility with discovery support in the WoT Scripting API</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>An API should be provided in the WoT Scripting API so that WoT Discovery functionality
                can be accessed.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>WoT Consumers can find and access WoT TDs for available WoT services dynamically.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>


          
    <section id="US-disc-filtering"><div class="header-wrapper"><h4 id="x2-1-18-discovery-filtering"><bdi class="secno">2.1.18 </bdi>Discovery Filtering</h4><a class="self-link" href="#US-disc-filtering" aria-label="Permalink for Section 2.1.18"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Partially satisfied. Query interface defined but optional.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-20">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-14">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support for various forms of query, including keyword, template, and semantic queries to
            filter results.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>When discovering devices and services, especially at internet scale, it is not feasible to
              access the metadata (Thing Descriptions) for all accessible devices.  Instead a suitable subset needs to
              be selected using suitable criteria.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>discovery can scale to a large number of devices and services.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-spatial-queries"><div class="header-wrapper"><h4 id="x2-1-19-discovery-spatial-queries"><bdi class="secno">2.1.19 </bdi>Discovery Spatial Queries</h4><a class="self-link" href="#US-disc-spatial-queries" aria-label="Permalink for Section 2.1.19"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Proposal only, not in current specification.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-21">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-15">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support spatial and sub-net limited queries.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>One fundamental filtering capability for discovery should include filtering by location,
	            so that only devices nearby physically can be discovered.  Subnet-limited discovery can be a 
	            proxy for this in some circumstances, for instance a Smart Home will generally have all devices
	            on a single subnet and limiting search to this subnet is acceptable to limit searches to that specific
	            home.  However, more generally, larger buildings and institutions may have multiple subnets,
	            and in use cases like a Smart City explicitly limiting searches to specific geographical areas or
	            semantic areas (e.g. a named neighborhood, a specific floor of a building) is needed.
	            In some cases, a search may also be limited to an area that is not in the physical proximity of 
	            the user, for example a user checking the weather in another city before travel, or a city dashboard
              checking pollution conditions neighborhood by neighborhood.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>Internet-scale searches can be limited to a set near or within a specific location (which may or may not be the user's location).</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-subnet-spanning-queries"><div class="header-wrapper"><h4 id="x2-1-20-discovery-subnet-spanning-queries"><bdi class="secno">2.1.20 </bdi>Discovery Subnet Spanning Queries</h4><a class="self-link" href="#US-disc-subnet-spanning-queries" aria-label="Permalink for Section 2.1.20"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-22">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-16">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support queries that can span a subnet or multiple directory services.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>The discovery mechanism should be flexible enough to span and
	            combine discovery results from multiple subnets.  Some mechanisms acceptable on a LAN,
	            e.g. broadcast, are not generally suitable for use on the large-scale internet.  A directory
              service is one way to support this capability.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>discovery of devices independent of the network segmentation is possible.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-scalablity"><div class="header-wrapper"><h4 id="x2-1-21-discovery-scalability"><bdi class="secno">2.1.21 </bdi>Discovery Scalability</h4><a class="self-link" href="#US-disc-scalablity" aria-label="Permalink for Section 2.1.21"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Partially satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-23">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-17">System Integrator</a>,
	            <a href="#dfn-stakeholder-system-maintainer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-maintainer-1">System Maintainer</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Be scalable to large databases of TDs.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Discovery should work for large systems with hundreds, thousands, or even millions of devices and 
	            services.  Several other capabilities are needed to support large scale applications, including
	            the ability to span network segments and filter results by search criteria at the source.  In many
		    cases, such as small requesting devices with limited or metered bandwidth, it is 
	            not acceptable for large systems to send all metadata for all possible devices in the directory to the requester.
            </p></dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>Very large systems of IoT devices and services can be accessed and managed.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>



    <section id="US-disc-dynamic-and-static-metadata"><div class="header-wrapper"><h4 id="x2-1-22-discovery-dynamic-and-static-metadata"><bdi class="secno">2.1.22 </bdi>Discovery Dynamic and Static Metadata</h4><a class="self-link" href="#US-disc-dynamic-and-static-metadata" aria-label="Permalink for Section 2.1.22"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Partially Satisfied; proposal for dynamic/static geolocation data exists.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-24">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-18">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support both dynamic and static metadata (TDs).</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Some metadata is fixed and some changes frequently, for some value of "frequent".  The discovery
	            mechanism should be flexible enough to support updates and notify subscribers of changes when
	            requested.  If the changes are very frequent, there should be some way to indicate to the user
	            that the data should be accessed from the device or service directly rather than through metadata.
	            Some data, such as location, might be either static or dynamic.  This specific form of metadata will
	            also be useful for filtering criteria.  The discovery mechanism should work with a wide range of scales
              for the frequency of updates.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>Data that does not change often can be stored efficiently but that data that does changes can be
	        updated in a timely manner.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-deletion"><div class="header-wrapper"><h4 id="x2-1-23-discovery-deletion"><bdi class="secno">2.1.23 </bdi>Discovery Deletion</h4><a class="self-link" href="#US-disc-deletion" aria-label="Permalink for Section 2.1.23"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-25">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-19">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support explicit deletion of TDs.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>When metadata (TDs) are stored remotely in a discovery system, it should be possible to remove stale or
	            incorrect metadata.  It may also be necessary to support deletion to support privacy goals.
	            Deletion should take place as soon as possible after the request is made, and it should
	            be possible to follow up a discovery action with a deletion action.  Deletion actions should however be
              protected so only authorized owners of the metadata can request its deletion.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>Stale, incorrect, or private metadata can be removed when no longer needed or appropriate.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                  <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                  <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
               </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-access-control"><div class="header-wrapper"><h4 id="x2-1-24-discovery-access-control"><bdi class="secno">2.1.24 </bdi>Discovery Access Control</h4><a class="self-link" href="#US-disc-access-control" aria-label="Permalink for Section 2.1.24"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-26">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-20">System Integrator</a>,
	      <a href="#dfn-stakeholder-system-maintainer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-maintainer-2">System Maintainer</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support access control for metadata.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>When metadata for a device or service is stored in a third party directory service, it may need to be 
	            updated, managed, modified, or deleted.  Such actions should only be performed by authenticated 
	            an authorized entities, such as those that originally created the entry in the directory service.
	            If the metadata is stored on a device, then updates to that information should also be subject to suitable
              access controls, similar to that for firmware updates.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>the integrity of metadata can be maintained</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-clean-up"><div class="header-wrapper"><h4 id="x2-1-25-discovery-clean-up"><bdi class="secno">2.1.25 </bdi>Discovery Clean Up</h4><a class="self-link" href="#US-disc-clean-up" aria-label="Permalink for Section 2.1.25"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-27">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-21">System Integrator</a>,
	            <a href="#dfn-stakeholder-system-maintainer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-maintainer-3">System Maintainer</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Automatically clean up TDs for devices that are no longer accessible or active.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Metadata (TDS) that are stored in third-party directory services should have a limited lifetime
	            and should be automatically deleted if that lifetime is not extended by an authorized entity,
              such as the entity that originally created the metadata record or a delegate.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>Obsolete metadata can be removed, saving space and avoiding attempts to access inactive devices and services.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>



    <section id="US-disc-ietf-core"><div class="header-wrapper"><h4 id="x2-1-26-discovery-ietf-core-alignment"><bdi class="secno">2.1.26 </bdi>Discovery IETF CoRE Alignment</h4><a class="self-link" href="#US-disc-ietf-core" aria-label="Permalink for Section 2.1.26"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-28">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-22">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Align with IETF CoRE Resource Directories and CoRE Link Format.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>It should be possible to use mechanisms defined by the IETF, such as CoRE Resource Directories,
	      to discover WoT resources including Thing Descriptions and Thing Description Directories.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>IETF CoRE and WoT Ecosystem can co-exist and WoT resources can be discovered from IETF CoRE-compliant systems.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-did"><div class="header-wrapper"><h4 id="x2-1-27-discovery-did-alignment"><bdi class="secno">2.1.27 </bdi>Discovery DID Alignment</h4><a class="self-link" href="#US-disc-did" aria-label="Permalink for Section 2.1.27"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-29">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-23">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Align with <abbr title="World Wide Web Consortium">W3C</abbr> DIDs and DID Documents.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Given a DID for a Thing, it should be possible to discover the TD for that Thing
	      by resolving the DID Document and following links contained in it.   Conversely, it should
	      be possible to use DIDs as Thing identifiers.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>DID identifiers for Things can be used to access Thing metadata using DID mechanisms, so
	  the DID and WoT ecosystems can work together.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                  <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
		  
               </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-extensible-introductions"><div class="header-wrapper"><h4 id="x2-1-28-discovery-extensible-introductions"><bdi class="secno">2.1.28 </bdi>Discovery Extensible Introductions</h4><a class="self-link" href="#US-disc-extensible-introductions" aria-label="Permalink for Section 2.1.28"></a></div>
      
        <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-30">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-24">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>WoT TDs should be accessible via a variety of existing discovery mechanisms</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Many existing discovery mechanisms exist and WoT should work with them, as well
	      as being extensible to new discovery mechanisms.  This can be accomplished by using
	      existing non-WoT discovery mechanisms as a "first contact" or "introduction" mechanism
	      resolving into a URL that can then be used to access WoT-specific discovery mechanisms.
	      Existing discovery mechanism supported this way should include but not be limited to 
	      DNS-SD, DNS-SRV, DHCP, QR codes, and Bluetooth beacons.  In general, it should be possible
	      to use any mechanism that returns a URL as an "introduction" mechanism.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>WoT systems can interoperate with existing and new discovery mechanisms, including mechanisms
	  appropriate to different network scales.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>



    <section id="US-disc-confidentiality"><div class="header-wrapper"><h4 id="x2-1-29-discovery-confidentiality"><bdi class="secno">2.1.29 </bdi>Discovery Confidentiality</h4><a class="self-link" href="#US-disc-confidentiality" aria-label="Permalink for Section 2.1.29"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-31">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-25">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support best known methods for confidentiality.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Detailed WoT metadata such as WoT TDs (Thing Descriptions) should not be visible to unauthorized network participants.
	      This can be accomplished by only providing WoT TDs through HTTP-based network APIs with appropriate 
	      encryption, so transmissions can be protected at least as well as existing web APIs.  Note that this applies only to the second
	      stage of WoT discovery, "exploration".  The "introduction" stage is not protected but is also prohibited from directly distributing WoT metadata.
	      </p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>WoT metadata (TDs) can be protected from unauthorized access.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-authentication"><div class="header-wrapper"><h4 id="x2-1-30-discovery-authentication"><bdi class="secno">2.1.30 </bdi>Discovery Authentication</h4><a class="self-link" href="#US-disc-authentication" aria-label="Permalink for Section 2.1.30"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-32">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-26">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support best known methods for authentication.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Detailed WoT metadata such as WoT TDs (Thing Descriptions) should not be provided to unauthenticated requesters.
	      This can be accomplished by only providing WoT TDs through HTTP-based network APIs with appropriate 
	      authentication combined with encryption, so WoT interfaces to access metadata can be protected at least as well as existing web APIs.
	      Note that this applies only to the second stage of WoT discovery, "exploration".
	      The "introduction" stage is not protected but is also prohibited from directly distributing WoT metadata.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>WoT metadata (TDs) is only provided to authenticated requesters.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-authorization"><div class="header-wrapper"><h4 id="x2-1-31-discovery-authorization"><bdi class="secno">2.1.31 </bdi>Discovery Authorization</h4><a class="self-link" href="#US-disc-authorization" aria-label="Permalink for Section 2.1.31"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-33">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-27">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support best known methods for authorization and role management.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>Detailed WoT metadata such as WoT TDs (Thing Descriptions) should not be provided to unauthorized requesters.
	      This can be accomplished by providing WoT TDs through HTTP-based network APIs with appropriate 
	      authorization combined with role management, so WoT interfaces to access metadata can be protected at least as well as existing web APIs.
	      While not required in all cases, to support anonymous access it should also possible to separate authentication and authorization using a separate service.
	      For example, it should be possible to use web tokens as API keys to control access, and the web tokens could be provided
	      by a separate service.   This can also be used to support limited-duration per-user access without having to update each device.
	      Note that this applies only to the second stage of WoT discovery, "exploration".
	      The "introduction" stage is not protected but is also prohibited from directly distributing WoT metadata.</p>
            </dd>
            </dl></dd>
          </dl>
        
        <dt>Why (so that...)</dt>
        <dd>
          <p>WoT metadata (TDs) can be protected from unauthorized access.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      
    </section>



    <section id="US-disc-anonymous-authentication"><div class="header-wrapper"><h4 id="x2-1-32-discovery-anonymous-authentication"><bdi class="secno">2.1.32 </bdi>Discovery Anonymous Authentication</h4><a class="self-link" href="#US-disc-anonymous-authentication" aria-label="Permalink for Section 2.1.32"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-34">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-28">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support authentication and authorization mechanisms that do not reveal user identities.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              <p>In cases where the identity of the requester is not important, an
              anonymous mechanism for authentication should be possible, to protect
              their privacy.  Well-known web technologies, such as bearer tokens, can
              be used for this.  Note that this does not apply to "introductions", but
              only to the second "exploration" stage of WoT Discovery. Some introduction mechanisms
              may not preserve privacy and these should be avoided if privacy is
              critical.  At least one introduction mechanism that does not reveal the
              identity of the requestor will be available.</p>
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>WoT services and metadata can be accessed while preserving privacy.</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-lifecycle"><div class="header-wrapper"><h4 id="x2-1-33-discovery-lifecycle"><bdi class="secno">2.1.33 </bdi>Discovery Lifecycle</h4><a class="self-link" href="#US-disc-lifecycle" aria-label="Permalink for Section 2.1.33"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-35">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-29">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support device and information lifecycle, trust management, and access controls</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              All stages of a device lifecycle should be supported by the discovery process, in 
	      particular it should be possible to onboard devices into a WoT system conveniently and,
	      at the end of their life, delete their metadata.
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>The process of adding and removing devices from a system is as simple as possible while preserving privacy and confidentiality</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-limit-distribution"><div class="header-wrapper"><h4 id="x2-1-34-discovery-limit-distribution"><bdi class="secno">2.1.34 </bdi>Discovery Limit Distribution</h4><a class="self-link" href="#US-disc-limit-distribution" aria-label="Permalink for Section 2.1.34"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-36">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-30">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>To distribute TDs and other metadata only to authenticated and authorized entities.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              Detailed metadata should not be made generally available to unauthorized users; or at 
	      least, there should be the capability to only provide information to authorized users if
	      such restrictions are appropriate.
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>privacy and confidentiality can be maintained</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>
    
    <section id="US-disc-no-leaks"><div class="header-wrapper"><h4 id="x2-1-35-discovery-no-leaks"><bdi class="secno">2.1.35 </bdi>Discovery No Leaks</h4><a class="self-link" href="#US-disc-no-leaks" aria-label="Permalink for Section 2.1.35"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-37">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-31">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Don't leak TDs, other metadata, or queries to unauthorized entities.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              TDs should not be distributed by means other than defined mechanisms that can
	      be protected with authentication.  In addition, queries and other metadata should be 
	      protected as much as possible.
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>privacy and confidentiality can be maintained</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>
    


    <section id="US-disc-simplicity"><div class="header-wrapper"><h4 id="x2-1-36-discovery-simplicity"><bdi class="secno">2.1.36 </bdi>Discovery Simplicity</h4><a class="self-link" href="#US-disc-simplicity" aria-label="Permalink for Section 2.1.36"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Satisfied.  However, there is probably room for improvement.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-38">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-32">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Simple automatic discovery of Things and services with minimum to no human interaction.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              Discovery should be as simple as possible, consistent with other goals, such as privacy and security
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>automated systems can use discovery for system management and implementation is as straightforward as possible</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" data-matched-text="[[[#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1]]]" class="sec-ref"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</a></li>
                <li><a href="#UC-retail-fountain-drink-ice-machine-1" data-matched-text="[[[#UC-retail-fountain-drink-ice-machine-1]]]" class="sec-ref"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-home-wot-devices-synchronize-to-tv-programs-1" data-matched-text="[[[#UC-home-wot-devices-synchronize-to-tv-programs-1]]]" class="sec-ref"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-human-authentication"><div class="header-wrapper"><h4 id="x2-1-37-discovery-human-authentication"><bdi class="secno">2.1.37 </bdi>Discovery Human Authentication</h4><a class="self-link" href="#US-disc-human-authentication" aria-label="Permalink for Section 2.1.37"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Partially Satisfied.  Some supported authentication mechanisms support human-based pairing, but not all, and secure communication is still an issue.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-39">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-33">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Support for human authentication (eg pairing button presses) when appropriate.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              A standard mechanism to "pair" devices using e.g. button presses can be useful.
	      There are some supported authentication mechanisms that support this, e.g. OAuth.
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>New devices can be easily and securely onboarded in a home environment</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>
  

    <section id="US-disc-user-limitations"><div class="header-wrapper"><h4 id="x2-1-38-discovery-user-limitations"><bdi class="secno">2.1.38 </bdi>Discovery User Limitations</h4><a class="self-link" href="#US-disc-user-limitations" aria-label="Permalink for Section 2.1.38"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Partially Satisfied.  There are some authentication methods that do NOT require human input-based pairing.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-40">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-34">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>It should be possible for a user to discover devices even if they have sensory or motor limitations.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              It should be possible to onboard devices without having to push a button on the device.
	      Some authentication mechanisms support this, including OAuth, but it may require an alternative authentication path.
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>Users with sensory or motor limitations can use WoT systems</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-irrigation-in-outdoor-environment-1" data-matched-text="[[[#UC-irrigation-in-outdoor-environment-1]]]" class="sec-ref"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</a></li>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-smartcity-geolocation-1" data-matched-text="[[[#UC-smartcity-geolocation-1]]]" class="sec-ref"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</a></li>
                <li><a href="#UC-meeting-room-event-assistance-1" data-matched-text="[[[#UC-meeting-room-event-assistance-1]]]" class="sec-ref"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-connected-building-energy-efficiency-1" data-matched-text="[[[#UC-connected-building-energy-efficiency-1]]]" class="sec-ref"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</a></li>
                <li><a href="#UC-automated-smart-building-management-1" data-matched-text="[[[#UC-automated-smart-building-management-1]]]" class="sec-ref"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</a></li>
                <li><a href="#UC-retail-camera-device-1" data-matched-text="[[[#UC-retail-camera-device-1]]]" class="sec-ref"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>

    <section id="US-disc-alternatives"><div class="header-wrapper"><h4 id="x2-1-39-discovery-alternatives"><bdi class="secno">2.1.39 </bdi>Discovery Alternatives</h4><a class="self-link" href="#US-disc-alternatives" aria-label="Permalink for Section 2.1.39"></a></div>
      
      <dl>
        <dt>Status:</dt><dd>Partially Satisfied.  There are some authentication methods that do NOT require human input-based pairing.</dd>
        <dt>Submitters</dt><dd>Michael McCool</dd>
        <dt>Who (As a...)</dt>
        <dd>
          <p><a href="#dfn-stakeholder-system-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-user-41">System User</a></p>
          <dl>
            <dt>Other Stakeholders</dt>
            <dd>
              <a href="#dfn-stakeholder-system-integrator" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-system-integrator-35">System Integrator</a>
            </dd>
          </dl>
        </dd>
        <dt>What (I need...)</dt>
        <dd>
          <p>Alternative forms of discovery should be supported to address different accessibility and use case needs.</p>
          <dl>
            <dt>Capability Details</dt>
            <dd>
              The system and devices should be able to support multiple authentication mechanisms so suitable alternatives can be selected
	      appropriate to the situation
            </dd>
          </dl>
        </dd>
        <dt>Why (so that...)</dt>
        <dd>
          <p>the system can accommodate the needs of different users</p>
          <dl>
            <dt>Motivating Use Cases</dt>
            <dd>
              <ul>
                <li><a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a></li>
                <li><a href="#UC-cross-domain-discovery-in-a-smart-campus-1" data-matched-text="[[[#UC-cross-domain-discovery-in-a-smart-campus-1]]]" class="sec-ref"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</a></li>
                <li><a href="#UC-cultural-spaces-museums-1" data-matched-text="[[[#UC-cultural-spaces-museums-1]]]" class="sec-ref"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</a></li>
                <li><a href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" data-matched-text="[[[#UC-interconnected-medical-devices-in-a-hospital-icu-1]]]" class="sec-ref"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</a></li>
                <li><a href="#UC-health-notifiers-1" data-matched-text="[[[#UC-health-notifiers-1]]]" class="sec-ref"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</a></li>
                <li><a href="#UC-smart-car-configuration-management-1" data-matched-text="[[[#UC-smart-car-configuration-management-1]]]" class="sec-ref"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</a></li>
                <li><a href="#UC-discovery-1" data-matched-text="[[[#UC-discovery-1]]]" class="sec-ref"><bdi class="secno">4.1 </bdi>Discovery</a></li>
                <li><a href="#UC-multimodal-recognition-support-1" data-matched-text="[[[#UC-multimodal-recognition-support-1]]]" class="sec-ref"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</a></li>
                <li><a href="#UC-enhancement-of-synergistic-interactions-1" data-matched-text="[[[#UC-enhancement-of-synergistic-interactions-1]]]" class="sec-ref"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</a></li>
                <li><a href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" data-matched-text="[[[#UC-audiovisual-devices-acting-as-smartphone-extensions-1]]]" class="sec-ref"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</a></li>
                <li><a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a></li>
                <li><a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a></li>
		
              </ul>
            </dd>
          </dl>
        </dd>
      </dl>
    </section>
  </section>
</section>
	  
	  

  <section id="sec-vertical-ucs"><div class="header-wrapper"><h2 id="x3-domain-specific-use-cases"><bdi class="secno">3. </bdi>Domain Specific Use Cases</h2><a class="self-link" href="#sec-vertical-ucs" aria-label="Permalink for Section 3."></a></div>
    

    <section id="agriculture"><div class="header-wrapper"><h3 id="x3-1-smart-agriculture"><bdi class="secno">3.1 </bdi>Smart Agriculture</h3><a class="self-link" href="#agriculture" aria-label="Permalink for Section 3.1"></a></div>
      
      <section id="UC-greenhouse-horticulture-1"><div class="header-wrapper"><h4 id="x3-1-1-greenhouse-horticulture"><bdi class="secno">3.1.1 </bdi>Greenhouse Horticulture</h4><a class="self-link" href="#UC-greenhouse-horticulture-1" aria-label="Permalink for Section 3.1.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>
            Ryuichi Matsukura, Takuki Kamiya
          </dd>
          <dt>Target Users</dt>
          <dd>

            Agricultural corporation, Farmer, Manufacturers (Sensor, other facilities), <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-1">Cloud Provider</a>

          </dd>
          <dt>Motivation</dt>
          <dd>

            Greenhouse Horticulture controlled by computers can create an optimal environment for growing plants. This
            enables to improve productivity and ensure stable vegetable production throughout the year, independent of
            the weather. This is the result of research on the growth of plants in the 1980s. For example, in
            tomatoes, switching to hydroponics and optimizing the temperature, humidity and CO2 concentration required
            for photosynthesis resulted in a five times increase in yield. The growth conditions for other vegetables
            also have been investigated, and this control system is applied now.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Sensors (temperature, humidity, brightness, UV brightness, air pressure, and CO2)
            Heating, CO2 generator, open and close sunlight shielding sheet.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Sensors values to clarify the gaps between conditions for maximizing photosynthesis and the current
            environment.
            Following sensors values at one or some points in the greenhouse: temperature, humidity, brightness, and
            CO2.

          </dd>
          <dt>Dependencies</dt>
          <dd>
            WoT Architecture
            <br>
            WoT Thing Description

          </dd>
          <dt>Description</dt>
          <dd>

            Sensors and some facilities like heater, CO2 generator, sheet controllers are connected to the gateway via
            wired or wireless networks. The gateway is connected to the cloud via the Internet. All sensors and
            facilities can be accessed and controlled from the cloud.
            To maximize photosynthesis, the temperature, CO2 concentration, and humidity in the greenhouse are mainly
            controlled. When the sunlight comes in the morning and CO2 concentration inside decreases, the application
            turns on the CO2 generator to keep over 400 ppm, the same as the air outside. The temperature in the
            greenhouse is adjusted by controlling the heater and the sunlight shielding sheet.
            The cloud gathers all sensor data and the status of the facilities. The application makes the best
            configuration for the region of the greenhouse located.

            

          </dd>
          <dt>Gaps</dt>
          <dd>

            In the case of the wireless connection to the sensors, the gateway should keep the latest value of the
            sensors since the wireless connection is sometimes broken. The gateway can create a virtual entity
            corresponding to the sensor and allow the application to access this virtual entity having the actual
            sensor status like sleeping.

          </dd>
          
        </dl>
      </section>
      <section id="UC-open-field-agriculture-1"><div class="header-wrapper"><h4 id="x3-1-2-open-field-agriculture"><bdi class="secno">3.1.2 </bdi>Open-field Agriculture</h4><a class="self-link" href="#UC-open-field-agriculture-1" aria-label="Permalink for Section 3.1.2"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Cristiano Aguzzi

          </dd>
          <dt>Target Users</dt>
          <dd>

            Agricultural corporation, Farmer, Manufacturers (Sensor, other facilities), <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-2">Cloud Provider</a>, Middleware
            provider, Network providers, <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-3">Service Provider</a>.

          </dd>
          <dt>Motivation</dt>
          <dd>
            Water is vital for ensuring food security to the world’s population, and agriculture is the biggest consumer
            amounting for 70% of freshwater. Field irrigation application methods are one of the main causes of water
            wastage. The most common technique, surface irrigation, wastes a high percentage of the water by wetting
            areas where no plants benefit from it. On the other hand, localized irrigation can use water more
            efficiently and effectively, avoiding both under-irrigation and over-irrigation. However, in an attempt to
            avoid under-irrigation, farmers feed more water than is needed resulting not only to productivity losses,
            but also water wastages.

            Therefore, technology should be developed and deployed for sensing water needs and automatically manage
            water supply to crops. However, open field agriculture is characterized by a quite dynamic range of
            requirements. Usually, solutions developed for one particular crop type cannot be reused in other
            cultivations. Moreover, the same field can have different crop types or different sizes/shapes during the
            years, meaning that technology to monitor the state of crop growth should be highly configurable and
            adaptive. Even agriculture and irrigation methods can change and also they are very different depending on
            the size of the field and its clime type.

            Consequently, silos applications are deployed leveraging on IoT technologies to gather data about the crop
            growth state and irrigation needs. The Web of Things may help to create a single platform where
            cost-effective applications could adapt seamlessly between different scenarios, breaking the silos and
            giving value both to the environment and the market.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            <p>Sensors:</p>
            <ul>
              <li>Weather sensors (maybe collected together inside a <a href="https://en.wikipedia.org/wiki/Weather_station">weather station</a>)
                <ul>
                  <li>temperature</li>
                  <li>air humidity</li>
                  <li>air pressure</li>
                  <li>pluviometer</li>
                  <li>global solar radiation</li>
                  <li>anemometer (wind speed)</li>
                  <li> wind direction</li>
                  <li>global solar radiation and photosynthetically active radiation</li>
                  <li> gas/air quality sensor (i.e. CO2)</li>
                </ul>
              </li>
              <li>Soil sensors (usually packed together in soil probes)
                <ul>
                  <li>soil temperature</li>
                  <li>soil moisture/water content</li>
                  <li>soil conductivity (detecting salt levels in the soil)</li>
                  <li> water table sensor</li>
                </ul>
              </li>
              <li>Drone sensors
                <ul>
                  <li>camera</li>
                  <li>temperature sensitive camera</li>
                  <li>multispectral camera</li>
                </ul>
              </li>
            </ul>
            <p>Actuators:</p>
            <ul>
              <li>drones: used for data collection or pesticed/impollination</li>
              <li>sprinklers</li>
              <li>pumps</li>
              <li>central pivot sprinklers</li>
              <li>hose-reel irrigation machine</li>
            </ul>
            <p>Additional devices:</p>
            <ul>
              <li>Solar panels</li>
              <li>Loggers: units that collect data from close sensors. </li>
              <li>Gateways</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>
            Sensor data plays a central role in Smart Agriculture. In particular, it is critical that the information
            sensed is associated with a timestamp. Common algorithms use *time series* to calculate the water needs of a
            crop.

            Furthermore, soil sensors usually are calibrated over a specific soil type (which may differ even in the
            same geographic region). For example, the calibration data for a soil moisture sensor is represented by a
            function that maps sensor output to soil water content. In literature, this function is knowns as a
            *calibration curve*. Commercial sensors are precalibrated with a "standard" curve but on most occasions, it
            fails to accurately measure the water content. Therefore, it can be configured during the installation phase
            (which may happen every time the soil is plowed).

            Finally, a crucial aspect is forecasting. Farmers use this information to actively change their management
            procedures. Services exploit it to suggest irrigation schedule or change device settings to behave
            accordingly to environmental changes.

            To summarize here it is a list of most important expected data from Open field agriculture:

            <ul>
              <li>Calibration curve</li>
              <li>Time series</li>
              <li>Forecast data</li>
              <li>Geolocations: sensor data must be contextualized in geolocation. Also, geolocation is critical in
                massive open fields to localize instrument position.</li>
              <li>Weather data</li>
              <li>Unit of measure: commercial soli sensor may output their value in a different unit of measures (i.e.
                volts or % water in an m^3 of soil)</li>
              <li>Relative values</li>
              <li>Depth position: geolocation is not sufficient to describe the parameters of the soil. Depth is an
                additional context that should be added to an observed value. </li>
              <li>Device owner information</li>
              <li>Battery level and energy consumption</li>
            </ul>

          </dd>
          <dt>Dependencies</dt>
          <dd>

            WoT Architecture, WoT Thing Description

          </dd>
          <dt>Description</dt>
          <dd>
            In open-field agriculture, the IoT solutions leverage on different radio protocols and devices. Usually,
            radio protocols should cover long distances (even kilometers) and be energy efficient. Devices too need to
            be energy saving as they are deployed for months and sometimes even years in harsh environments. A
            sleeping-cycle is one mechanism they use to save energy usually coordinated by *loggers/gateways* or
            preprogrammed. *Loggers* are deployed closed to sensor devices and have more storage space. They serve as
            buffers between sensors and higher services. Often *loggers* and sensors are embedded in the same board,
            otherwise, they are connected using cables or close-ranged radio protocols. On the other hand, *gateways*
            serve as a collection point for data of an entire field or farm. They are much more capable devices and
            usually are more energy-consuming. In some deployment scenarios, they host a full operating system with
            multiple software facilities installed. Otherwise, gateways only serve as relays of data sent from the
            loggers and sensors to cloud services and vice-versa. The cloud services may be partially hosted in edge
            servers to preserve data privacy and responsiveness of the whole IoT solution. Possible cloud services are:
            <ul>
              <li>Weather forecasting/local weather forecasting</li>
              <li>Soil digital twin to simulate and predict water content</li>
              <li>Plant digital twin (growth and water needs prediction)</li>
              <li>Irrigation advice service: combining the previous services and knowing the irrigation system topology
                is possible to advise farms with the best times to irrigate a crop. </li>
              <li>Pesticide and fertilize planning</li>
            </ul>

            The complete deployment topology of an open field agriculture solution is described in the diagram below:
            <br>
            <br>
            <div class="resize"><img src="./images/Agriculture.svg" alt="deployment topology of an open field agriculture solution"></div>
            <br>
            <br>
          </dd>
          <dt>Variants</dt>
          <dd>
            Open-field agriculture varies a lot between geographical location and methods. For example in the <a href="http://swamp-project.org/">SWAMP project</a> there three different pilots with different
            requirement/constraints:
            <ul>
              <li><a href="http://swamp-project.org/cbec/">Italian pilot</a> (Reggio Emilia region):
                <ul>
                  <li>Relative small field size</li>
                  <li>Multiple connectivity solutions available: 4G, LPWAN, and WiFi</li>
                  <li>Variance in crop types, sometimes even inside the same farm</li>
                  <li>Small soil type variance</li>
                  <li>Precise model soil behavior</li>
                  <li>A great influence of the water table</li>
                  <li>Variance in the irrigation system</li>
                  <li>Channel-based water distribution</li>
                  <li>The main goal is to optimize water consumption</li>
                </ul>
              </li>
              <li><a href="http://swamp-project.org/matopiba/">Brazilian pilot</a> (Matopiba and Guaspari location):
                <ul>
                  <li>Huge field size</li>
                  <li>Centra pivot irrigation systems: need to optimize each sprinkler output</li>
                  <li>Soil type variance within the same field</li>
                  <li>A low number of connectivity options: no 4G, only radio communication base on LPWAN</li>
                  <li>Low crop type variance</li>
                  <li>the main goal is to optimize energy consumption</li>
                </ul>
              </li>
              <li><a href="http://swamp-project.org/intercrop/">Spain pilot</a>:
                <ul>
                  <li>Efficient localized irrigation and application of the right amount of water to the crop</li>
                  <li>arid location</li>
                  <li>The goal is to minimize water consumption but maintaining a good field yield.</li>
                </ul>
              </li>
            </ul>
          </dd>
          <dt>Gaps</dt>
          <dd>
            Currently, there is no specification on how to model device status (i.e. connected/disconnected)
            Examples of how to handle a device calibration phase may help developers to use a standardized approach.
            Possibly define standard links types to define the relation between loggers and sensors
            Handle both geographical position and depth information.
            Ontology class for battery and energy consumption
            Model historical and forecast data

          </dd>
          <dt>Existing Standards</dt>
          <dd>
            <ul>
              <li>LPWAN [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc8376" title="Low-Power Wide Area Network (LPWAN) Overview">rfc8376</a></cite>]</li>
              <li><a href="http://www.sdi-12.org/current_specification/SDI-12_version-1_4-Jan-10-2019.pdf">SDI 12</a>
              </li>
              <li>CoAP [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc7252" title="The Constrained Application Protocol (CoAP)">rfc7252</a></cite>]</li>
              <li>MQTT [<cite><a class="bibref" data-link-type="biblio" href="#bib-mqtt" title="MQTT Version 3.1.1 Plus Errata 01">MQTT</a></cite>]</li>
            </ul>
          </dd>
          <dt>Comments</dt>
          <dd>

            This use case is designed using the experience gained in the European-Brazil Horizon 2020 SWAMP project.
            Please follow the
            <a href="http://swamp-project.org/">link</a> for further information. Since SWAMP is heavily oriented to
            optimize water consumption,
            this document just mentioned issues like plant feeding, fertilizing, pollination, yield prediction, crop
            quality measurement, etc.
            Nevertheless, WoT technologies may be employed also in these scenarios.
          </dd>
        </dl>
      </section>
      <section id="UC-irrigation-in-outdoor-environment-1"><div class="header-wrapper"><h4 id="x3-1-3-irrigation-in-outdoor-environment"><bdi class="secno">3.1.3 </bdi>Irrigation in Outdoor Environment</h4><a class="self-link" href="#UC-irrigation-in-outdoor-environment-1" aria-label="Permalink for Section 3.1.3"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            <ul>
              <li>Catherine Roussey
                
              </li>
              <li>Jean-Pierre Chanet
                
              </li>
            </ul>

          </dd>
          <dt>Target Users</dt>
          <dd>

            <ul>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-1">Device Users</a>: farmers</li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-4">Service Provider</a></li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            Depending on the type of crops (e.g. maize), cultivated plots may need specific irrigation processes
            in outdoor environments. Depending on the country there exist some specific pedo-climatic conditions
            and some water consumption restrictions. Thus an irrigation system is installed on the plot. It is used
            on a several days basis (e.g. every 7 days), for each plot. The goal is to optimize the irrigation decision
            based on the crop development stage and the quantity of rain that has already fallen down on the plot.
            For example an important rain may postpone the irrigation decision.
            <br>
            <br>
            This use case aims to evaluate the number of days to delay the irrigation system, in addition to the basis
            irrigation frequency (e.g. 2 delay days means 9 days between two irrigations).

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            <ul>
              <li>6 tensiometers in the plot (soil moisture):
                <ul>
                  <li> 3 tensiometers at 30 cm depth</li>
                  <li> 3 tensiometer at 60 cm depth</li>
                </ul>
              </li>
              <li>1 weather station:
                <ul>
                  <li>thermometer (outdoor temperature)</li>
                  <li>pluviometer (rain quantity)</li>
                </ul>
              </li>
              <li>1 mobile pluviometer (quantity of water provided by the watering system)</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>

            To decide when to water a cultivated plot, we evaluate the crop growth stage, the root zone moisture level
            and the number of delay days:

            <ul>
              <li>To evaluate the <b>Crop growth stage</b>, we need:
                <ul>
                  <li>Min and max temperature per day: the <b>min temperature per day</b> is evaluated on the period
                    [d-1
                    18:00, d 18:00[. The <b>*max temperature per day</b> is evaluated on the period [d 06:00:00, d+1
                    06:00:00[.i</li>
                  <li><b><a href="https://en.wikipedia.org/wiki/Growing_degree-day">Growing degree day</a></b> values
                    uses
                    min and max temperature per day, the sowing day and the type of seed. The Growing degree day is
                    compared to some thresholds to evaluate the crop growth stage</li>
                </ul>
              </li>
              <li>To evaluate the <b>Root zone moisture level</b>, we need:
                <ul>
                  <li>Mean moisture per day per probe: in order to get reliable values, each tensiometer sends several
                    measurements of soil moisture, at fixed hours of the day (usually in the morning), that are
                    aggregated; their mean value is considered</li>
                  <li>For the set of 3 tensiometers localised at the same level of depth, the median value is evaluated
                    from their mean per day moisture measurements. One tensiometer may not provide accurate values (the
                    soil around the probe is too dry and the soil matter is not connected to the probe). The median
                    value
                    of three different tensiometers at the same depth will improve the accuracy of the moisture
                    measurement.</li>
                  <li>Then the sum of the two median values at two different depths is evaluated, to take into account
                    the
                    quantity of water available in the root zone volume. This aggregated value estimates the root zone
                    moisture level. </li>
                  <li>The root zone moisture level is compared to some thresholds (dependent on the crop growth stage)
                    to
                    evaluate if the crop needs water or not at the end of the basis irrigation period.</li>
                </ul>
              </li>
              <li>To determine the <b>number of delay days</b>, we need:
                <ul>
                  <li>The time period between two waterings of the same plot is dependent on the farm and known by the
                    farmer. When a watering is launched, no new watering should be planned during the basic irrigation
                    frequency. The quantity of rain that falls down on the plot may postpone the watering plan. The
                    total
                    quantity of rain per day is compared to some thresholds to determine the number of delay days.</li>
                </ul>
              </li>
            </ul>

            The mobile pluviometer is used to validate that the quantity of water received by the crop actually
            corresponds to the quantity of water provided by the watering system.
            <br>
            <br>
            At the end, the farmer may decide if they follow the irrigation recommendations or not. They could force the
            watering for one of the next days.
            <br>
          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            <ul>
              <li>WoT Architecture: wireless communication in outdoor environments presents some issues: communication
                consumes lots of energy, sensor nodes have limited energy, weather conditions impact communication
                quality</li>
              <li>WoT Thing Description: the affordance should be precise enough to describe the soil at a specific
                depth or the root zone volume or the min temperature per day</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>

            To avoid Property right and consent management issues between farmers and cloud <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-5">Service Providers</a> on these
            computed data, sensors are connected to the farm infrastructure and the services that evaluate aggregated
            data are executed locally on this infrastructure.
            <br>
            <br>
            The weather station may be located outside of the farm.
            <br>
            <br>
            The tensiometers are located inside the farm. The tensiometers and the mobile pluviometer are connected
            using wireless communication to the gateway. The gateway sends the measurements to the farm infrastructure.

          </dd>
          <dt>Variants:</dt>
          <dd>
            The crop growth stage may be observed by the farmer. In this case, they can force this value to update the
            service inputs.

          </dd>
          <dt>Security Considerations</dt>
          <dd>

            The 6 tensiometers and 1 pluviometer are installed on the plot, but only the farmer should be able to change
            their configurations (frequency of communication). Wireless communication should be used but the measurement
            data should only be accessible through the farm network infrastructure.

          </dd>
          <dt>Privacy Considerations</dt>
          <dd>

            Data concerning quantity of water, type of seed, sowing day should be protected.

          </dd>
          <dt>Gaps</dt>
          <dd>

            The main potential issues come from tensiometers located in the plot, as they are known to be cheap and easy
            to use probes but not always reliable. They can face multiple issues: if the soil gets too dry or the probe
            is improperly installed, there may be air between the probe and the soil, therefore preventing the probe
            from providing accurate conductivity measurements.
            <br>
            <br>
            To be sure of the quality of those measurements each tensiometer sends its measurements several times (3 to
            5) per day. The tensiometer may send an inappropriate value due to the bad connection between the soil and
            the probe, that is the reason why three tensiometers are used and the median value is computed. If the
            gateway does not receive the value of one sensor during a whole day, an alert should be sent. To take an
            irrigation decision, at least one measurement per sensor and per day should be provided.
            <br>
            <br>
            The gateway can create a virtual entity corresponding to the sensor and allow the application to access this
            virtual entity having the actual sensor status like sleeping.
            <br>
            <br>
            Sensor nodes deployed in outdoor environments may take into account that their energy supply device
            (battery, solar panel) constrains the lifetime of the device. Thus they should be able to alert that they
            may not be able to provide a service due to lack of energy or they should be able to change their
            configuration and switch communication protocols to save as much energy as possible.
            <br>
            <br>
            Moreover wireless communication can be impacted by weather conditions or any outdoor conditions. For example
            a tractor that comes too close to the sensor node may move the communication device and destroy some
            components. Some kind of network supervision must be achieved (for instance by the gateway) to check node
            availability.

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            <ul>
              <li>Semantic Sensor Network Ontology (SSN/SOSA) [<cite><a class="bibref" data-link-type="biblio" href="#bib-vocab-ssn" title="Semantic Sensor Network Ontology">vocab-ssn</a></cite>]</li>
              <li>SAREF4AGRI ETSI Standard [<cite><a class="bibref" data-link-type="biblio" href="#bib-saref4agri" title="SAREF4AGRI: an extension of SAREF for the agriculture and food domain">SAREF4AGRI</a></cite>]</li>
              <li><a href="https://www.w3.org/TR/prov-o/">PROV-O</a></li>
              <li><a href="https://irstea.github.io/caso/OnToology/ontology/caso.owl/documentation/index-en.html">CASO</a>
              </li>
              <li><a href="http://www.w3id.org/def/irrig">IRRIG</a></li>
            </ul>

            The CASO and IRRIG ontologies extend SSN, PROV-O and SAREF4AGRI to implement an irrigation expert system.
            <br>
            <br>
            A thesaurus climate and forecast that describes the weather properties and associated phenomenon is
            available at <a href="http://vocab.nerc.ac.uk/collection/P07/">http://vocab.nerc.ac.uk/collection/P07/</a>.
            <br>
            <br>
            The weather measurements provided by the agricultural weather station of Agrotechnopole is available at <a href="http://ontology.irstea.fr/weather/snorql/">http://ontology.irstea.fr/weather/snorql/</a>. [5]

          </dd>
          <dt>Comments</dt>
          <dd>

            This use case has been implemented in France, following local conditions and regulations. There exists an
            open manual irrigation decision method called <a href="http://www.irrinov.arvalisinstitutduvegetal.fr/irrinov.asp">IRRINOV®</a> developed by Arvalis [2]
            and INRAE dedicated to France and some specific crops: maize, wheat and cereals, potatoes and beans.
            <br>
            <br>
            IRRINOV® can be automated using wireless sensor networks and semantic web technologies. The considered
            network is of star type: all sensors can communicate with a common gateway, which is connected to the
            Internet. The IRRINOV® implementation was developed in [3]. This work presents an expert system for maize
            using drools. It automates the irrigation decision for maize based on sensor measurements.
            <br>
            <br>
            To measure weather properties, we use the recommendation provided by the French National Weather Institute:
            Météo France[4]. Its web site defines how to evaluate the min and max temperatures per day in <a href="http://www.meteofrance.fr/publications/glossaire/154123-temperature-minimale">http://www.meteofrance.fr/publications/glossaire/154123-temperature-minimale</a>
            (in French, we found no equivalent description in English).

          </dd>
          <dt>References</dt>
          <dd>

            [1] <a href="https://www.inrae.fr/">https://www.inrae.fr/</a>
            <br>
            [2] <a href="https://www.arvalisinstitutduvegetal.fr/">https://www.arvalisinstitutduvegetal.fr/</a>
            <br>
            [3] Q-D. Nguyen, C. ROUSSEY, M. Poveda-Villalón, C. de Vaulx , J-P. Chanet. Development Experience of a
            Context-Aware System for Smart Irrigation Using CASO and IRRIG Ontologies. Applied Science 2020, 10(5),
            1803; <a href="https://doi.org/10.3390/app10051803">https://doi.org/10.3390/app10051803</a>
            <br>
            [4] <a href="http://www.meteofrance.fr/">http://www.meteofrance.fr/</a>
            <br>
            [5] C. ROUSSEY,S. BERNARD, G. ANDRÉ, D. BOFFETY. Weather Data Publication on the LOD using SOSA/SSN2022-11-07
            Ontology. Semantic Web Journal, 2019 <a href="http://www.semantic-web-journal.net/content/weather-data-publication-lod-using-sosassn-ontology-0">http://www.semantic-web-journal.net/content/weather-data-publication-lod-using-sosassn-ontology-0</a>
          </dd>
        </dl>

      </section>
   <section id="UC-automatic-milking-system-for-dairy-farm-1"><div class="header-wrapper"><h4 id="x3-1-4-automatic-milking-system-for-dairy-farm"><bdi class="secno">3.1.4 </bdi>Automatic milking system for dairy farm</h4><a class="self-link" href="#UC-automatic-milking-system-for-dairy-farm-1" aria-label="Permalink for Section 3.1.4"></a></div>  
	
	<dl>
	  <dt>Submitter(s)</dt>
          <dd>
	    Mun Hwan CHOI, ChangKyu LEE, Sunghyun YOON
	  </dd>

	  <dt>Target Users</dt>
	  <dd>
	    <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-6">Service provider</a>, <a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-4">device manufacturer</a>, <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-2">device owner</a>, <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-3">cloud provider</a>
	  </dd>

	  <dt>Motivation</dt>
	  <dd>
	    <p>
	    Dairy farming requires significant labor in the feeding, milking, breeding, and manure disposal as well as the control and management of
	    the environmental conditions inside and outside the livestock barn. In particular, the milking accounts for more than 40% of the total
	    working time for handling a cow.
	    </p>
	    <p>
	    Recently, advanced countries in the dairy industry have introduced an IoT-based automatic milking system using various IoT devices and
	    equipment to reduce the labor for milking. The automatic milking system (AMS) with IoT devices and equipment, such as sensors,
	    high performance cameras, laser equipment, and robot arms, can perform the entire milking process which includes identification of cows
	    entering the milking box, washing udders, milking, collection, sterilization, storage, and milk composition analysis. The AMS has advantage
	    of solving the labor shortage problem in the dairy farm by enabling labor allocation for tasks other than milking unlike conventional methods
	    like pipeline, herringbone, tandem machines, etc. In addition, the AMS can improve productivity and quality of milk while reducing the
	    incidence rate of disease in cows.
	    </p>
	  </dd>

	  <dt>Expected devices</dt>
	  <dd>
	    <li>Object (cow) identifier such as RFID reader, QR code scanner or barcode scanner</li>
	    <li>sensors for detecting position and behavioral characteristic of cows, for measuring milking volume, and for monitoring environmental conditions inside and outside the livestock barn</li>
	    <li>3D camera, laser equipment for identification of nipple location of a cow</li>
	    <li>Robot arms for attaching/removing milking cups</li>
	    <li>Milk composition analyzer</li>
	    <li>Milk tank with cooling function</li>
	  </dd>

	  <dt>Expected data</dt>
	  <dd>
	    <p>
	    The AMS generates the following data, and the data need to be managed in an organic relationship with data for other purposes such as feeding,
	    parturition, disease control, and growth control in order to establish a comprehensive production and operation management strategy for dairy farms.
	    </p>
	    <p>
	    </p><li>Daily Number of milking, milking volume, and milking time per cow</li>
	    <li>Target production and actual production of the farm</li>
	    <li>Historical data for milking</li>
	    <li>Target milk yield for each cow and/or farm based on historical data</li>
	    <li>Health and disease management data for each cow</li>
	    <li>Component analysis results of milk</li>
	    <li>Operational status of devices, equipment, etc. installed in dairy farm</li>
	    <p></p>
	  </dd>

	  <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
	  <dd>
	    WoT Thing Description
	  </dd>

	  <dt>Descriptions</dt>
	  <dd>
	    <p>
	    When a cow enters a milking box, a object identifier installed in the milking room identifies the cow’s ID from the RFID tag, QR code or bar code attached to the cow.
	    Through this, the milking can be performed more systematically based on historical data, such as the number of milking or milk yield, managed by AMS.
	    </p>
	    <p>
	    Then, 3D camera, laser equipment, and sensors accurately identify the position of udders, and the robot arm attaches the milking cups to the udders
	    quickly to perform milking. Before and after the milking, cleaning and disinfection should be performed to remove any contaminant and bacteria.
	    A sensor installed in the milking cup measures the elapsed time and milk yield during milking.
	    </p>
	    <p>
	    In addition, the components of milk, which are content of fat, protein, lactose, etc., are analyzed, and the analysis results are transmitted
	    to the AMS in order to manage the quality of milk, disease and health status of the cow. After milking, the milk is delivered to a milk tank
	    with cooling capability to maintain freshness of the milk. The AMS collects the data generated during the entire milking process, and analyzes
	    the data to establish a milk production strategy of a dairy farm. The farmer or the manager of a dairy farm can monitor the milking process
	    through a web page or a mobile app.
	    </p>
	    <p>
	    Automated system should be designed to minimize human intervention; however, it is more desirable to have the capability to directly control
	    the AMS in order to respond to an emergency situation.
	    </p>
	    <p>
	    The devices and equipment such as RFID reader/tags, milking cups, robot arms, milk component analyzer, and sensor are connected to a gateway,
	    which is a controller, installed in a dairy farm through wired or wireless networks. The gateway controlling various actuators and transferring
	    the data is connected to the cloud system through the Internet. Thus, all devices and equipment on the dairy farm can be accessed and controlled
	    through the cloud. The cloud utilizes technologies, such as AI and big data, to analyze the data transferred from the AMS. The analysis result
	    can be shared and distributed to all stakeholders and can be utilized as basic information for the creation of various new services enhancing
	    productivity and convenience of the dairy farm.
	    </p>
	  </dd>

	  <dt>Variants</dt>
	  <dd>
	    None.
	  </dd>

	  <dt>Security Considerations</dt>
	  <dd>
	    <p>
	    This use case does not specify any specific requirements on security matters. Any well-defined security management mechanisms can be applied for
	    this use case.
	    </p>
	  </dd>

	  <dt>Privacy Considerations</dt>
	  <dd>
	    <p>
	    In addition to farmers, various stakeholders such as farm workers, <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-7">Service Providers</a>, manufacturers, consumers of agricultural products,
	    third-party companies and government departments are also involved with the operation of a dairy farm. The data with various types and
	    characteristics generated during the operation of the AMS can be shared and distributed to one or more stakeholders.
	    </p>
	    <p>
	    Consequently, the right to access the data must be systematically managed according to the type, characteristics, and purpose of data utilization.
	    Through this, it is possible to protect the experience, know-how and unique agricultural knowledge or techniques of a farmer, and to secure the
	    dairy farm’s competitiveness.
	    </p>
	  </dd>

	  <dt>Accessibility Considerations</dt>
	  <dd>
	    None.
	  </dd>

	  <dt>Internationalisation (i18n) Considerations</dt>
	  <dd>
	    None.
	  </dd>

	  <dt>Requirements</dt>
	  <dd>
	    <p>
	    A wired or wireless communication link is required to exchange data generated by operation of AMS and commands for controlling IoT devices
	    and equipment. To prevent interfering with the free movement of cows and other agricultural works, using wireless communication link is recommended.
	    </p>
	    <p>
	    The data for the AMS should be delivered and stored with a common format regardless of device types and manufacturers, and should be expressed
	    in a standardized way for AI-based analysis and processing.
	    </p>
	  </dd>

	  <dt>Gaps</dt>
	  <dd>
	    <p>
	    In general, a gateway, which is a controller, installed in a dairy farm collects data and transmits the data to an external cloud connected through
	    a network. The gateway also delivers the control commands received from the cloud to the various actuators through the network.
	    However, if data loss or delay occurs due to a bottleneck, a disconnection between the gateway and the cloud, or due to the excessive internal
	    processing time of the cloud, it may be difficult to perform efficient and reliable milking operations. In order to solve these problems,
	    it is recommended to applying edge computing technologies to maintain essential functionalities for performing agricultural works including the milking.
	    </p>
	  </dd>

	  <dt>Existing standards</dt>
	  <dd>
	    None.
	  </dd>

	  <dt>Comments</dt>
	  <dd>
	    None.
	  </dd>
	<dl>
      </dl></dl></section>
	  
    <section id="UC-pest-control-in-open-field-1"><div class="header-wrapper"><h4 id="x3-1-5-pest-control-in-open-field"><bdi class="secno">3.1.5 </bdi>Pest control in Open-field</h4><a class="self-link" href="#UC-pest-control-in-open-field-1" aria-label="Permalink for Section 3.1.5"></a></div> 
      
      <dl>
          <dt>Submitter(s)</dt>
          <dd>Mun Hwan CHOI, ChangKyu LEE, Sunghyun YOON</dd>

          <dt>Target Users</dt>
          <dd><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-8">Service Provider</a>, <a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-5">Device Manufacturer</a>, <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-3">Device Owner</a>, <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-2">Device User</a>, <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-4">Cloud Provider</a></dd>

          <dt>Motivation</dt>
          <dd>
              Recently, the interest in pest control using unmanned aerial vehicles (UAVs), such as drones, for open-field agriculture is
              growing as the technology related to smart agriculture is advanced.<br><br>
              UAVs equipped with high-performance cameras and a variety of sensors closely monitor a wide range of agricultural land
              and detect unique spectral signals of crops. Meanwhile, sensors installed on the ground collect crop-growth status information.
              The data collected by UAVs and ground sensors are analyzed using various technologies including AI.
              UAVs take appropriate pest control, if the occurrence of pests is identified according to the analysis results.
              UAVs can set the target area and use the minimum amount of pesticides on the area in order to improve the productivity of
              farmhouses while minimizing the damage caused by pests. The pest control using UAVs can alleviate the labor shortage in
              rural areas due to the decrease of the agricultural population and the aging of the farmers.
              In addition, UAVs can also be an effective solution to protect farmers from serious side effects of pesticides by reducing
              the frequency of farmer’s contact with chemicals such as pesticides.
          </dd>

          <dt>Expected devides</dt>
          <dd>
              <li>UAVs (drones) equipped with high-performance cameras and sensors for monitoring and detecting pests</li>
              <li>Sensors for monitoring crop-growth status in ground</li>
              <li>Controllers for UAVs, and for related actuators installed in ground</li>
              <li>Data (image, video, etc.) analyzer in cloud</li>
          </dd>

          <dt>Expected data</dt>
          <dd>
              <li>Image and/or video data of farmland and crops
              </li><li>Data of soil conditions and crop-growth status</li>
              <li>Data on types of pests and appropriate control methods</li>
              <li>Result of pest control works</li>
          </dd>

          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>WoT Thing Description</dd>

          <dt>Description</dt>
          <dd>
              The pest control using UAVs includes the steps of data collection, data analysis and prescription, pest control operation,
              and utilization of data including operation results.<br><br>
              <li>In data collection step, UAVs collect data, such as images and/or videos, on farmland and crops by using built-in high-performance
                  cameras and sensors, and transmit them to the cloud. In addition, the sensors installed on the ground collect data related to
                  the soil condition and crop-growth status and transmit them to the cloud through a controller.</li>
              <li>In data analysis and prescription step, the cloud analyzes the collected data using various technologies including AI and big data technologies
                  to identify the occurrence of pests, occurrence area and the range of occurred pests, and types of occurred pests.
                  Then the cloud generates a prescription including the type, amount, and spray method of appropriate pesticides based on the
                  analysis results. This prescription is delivered to UAVs or a separate ground-operated pest control machine.
                  To generate accurate and effective prescription, the cloud may utilize public database provided by government or related <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-9">Service Providers</a>.</li>
              <li>In pest control operation step, according to the prescription received from the cloud, UAVs perform pest control operation.
                  UAVs can spray the correct amount of pesticide around the area where the pests occur, depending on the type of pests and the severity of symptoms.</li>
              <li>In data utilization step, the cloud stores and manages the data collected throughout the entire process for pest control.
                  The accumulated data are used as basic materials for establishing an optimal control plan regarding the location of farmland,
                  soil condition, the types and status of crops, the types of pests. Farmers can monitor the details and results of the overall control
                  operations using the web page or mobile app.</li>
          </dd>

          <dt>Variants</dt>
          <dd>None.</dd>

          <dt>Security Considerations</dt>
          <dd>
              This use case does not specify any specific requirements on security matters. Any well-defined existing security capabilities can be applied for this use case.
              However, appropriate security plan is required to protect the image or video data for pest control which are closely related to the profits of the farmhouse.
          </dd>

          <dt>Privacy Considerations</dt>
          <dd>
              To protect the agricultural technology of the farmer and secure competitiveness, it is required to establish a systematic access method for all data acquired
              during the pest control using UAVs. Only the stakeholders who have been contracted or promised in advance are allowed to access the data to be share or distributed,
              because various stakeholders may participate in other agricultural works as well as pest control.
          </dd>

          <dt>Accessibility Considerations</dt>
          <dd>None.</dd>

          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>None.</dd>

          <dt>Requirements</dt>
          <dd>In addition to the International Civil Aviation Organization (ICAO), each country has regulations for the safe operation and management of UAVs
              for non-military purposes. UAVs for pest control should be operated safely within the scope of related regulations, such as the available altitude
              and range of flight and the allowable weight of the payload.<br><br>
              UAVs, sensors and equipment from different manufacturers may not be compatible with each other. For data sharing and analysis,
              a standardized data format and compatible connection interface between different types of equipment and devise should be provided.
          </dd>

          <dt>Gaps</dt>
          <dd>
              Farmers may have own database and analysis system for pest control using UAVs. However, a significant cost is required to secure high-performance
              computing resources for analyzing images or videos and to manage large-capacity storage space.
              Therefore, it can be much more economical to utilize the cloud service.<br><br>
              In addition, a large-capacity battery and fast charging technology should be considered for the stable operation of UAVs that require a long flight.
              Wireless power transfer (WPT) technology may be a potential charging method for future agricultural UAVs.
          </dd>

          <dt>Existing Standards</dt>
          <dd>None.</dd>

          <dt>Comments</dt>
          <dd>None.</dd>
      </dl>
  </section>
        
    <section id="UC-livestock-health-management-1"><div class="header-wrapper"><h4 id="x3-1-6-livestock-health-management"><bdi class="secno">3.1.6 </bdi>Livestock Health Management</h4><a class="self-link" href="#UC-livestock-health-management-1" aria-label="Permalink for Section 3.1.6"></a></div> 
      
      <dl>
          <dt>Submitter(s)</dt>
          <dd>ChangKyu LEE, Mun Hwan CHOI, Sunghyun YOON</dd>

          <dt>Target Users</dt>
          <dd><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-10">Service Providers</a>, <a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-6">Device Manufacturers</a>, <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-3">Device Users</a></dd>

          <dt>Motivation</dt>
          <dd>
            <p>
            IoT and AI-based animal health management technologies are being introduced to overcome the difficulty of separating sick livestock from other livestock
            in narrow spaces where many livestock herds live. This helps to safely maintain livestock by monitoring their behavior and health status and taking quick and
            appropriate responses if disease is expected or occurs.
            </p>
            <p>
            IoT and AI-based animal health management technology plays an important role in monitoring livestock health, preventing diseases, and detecting them early.
            Through this technology, livestock's health status can be monitored in real-time by collecting and analyzing their biological signals, such as body temperature,
            heart rate, and respiration, and setting normal ranges. If abnormal data is detected, it sends an alert to the famer to take appropriate measures.
            </p>
            <p>
            Additionally, AI technology can be used to predict livestock's health status. By analyzing the relationship between livestock's health status and disease occurrence
            using AI models, predictive results on health status can be provided to take preventive measures.
            </p>
            <p>
            This IoT and AI-based animal health management technology is very useful for maintaining livestock's health, improving productivity, and minimizing disease occurrence
            by monitoring their health status, taking preventive measures, and providing early responses.
            </p>
          </dd>

          <dt>Expected devides</dt>
          <dd>
              <li>Sensors and/or cameras to collect data on behavioral characteristics and health status of livestock, environmental conditions inside and outside the livestock barn</li>
              <li>Wearable devices such as collars or ear tags attached to the livestock’s body to monitor the livestock’s location, behavior, and vital signs</li>
              <li>Communication devices including object identifiers (RFID readers, QR code scanners or barcode scanners), Bluetooth or Wi-Fi modules, and cellular to transmit
                the data from the sensors, cameras or wearable devices to a cloud server for analysis</li>
              <li>Environmental control devices such as light, air conditioner, etc.) to control the breeding environment of livestock</li>
              <li>Cloud-based analytical system to analyze the collected data. Edge devices including microcontrollers, gateways, and edge servers may be required for network
                stability and real-time data processing</li>
          </dd>

          <dt>Expected data</dt>
          <dd>
              <li>Identification data of a livestock: identification number, sex, age, etc.</li>
              <li>Health status data of a livestock: body weight, body temperature, heart rate, respiration rate, activity level, feed and water intake, fecal volume and its condition, etc.</li>
              <li>Disease data of a livestock: disease occurrence, type of disease, diagnosis and prescription results, etc.</li>
              <li>Environmental condition data of a livestock barn: temperature, humidity, ammonia, carbon dioxide level, etc.</li>
          </dd>

          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>WoT Thing Description</dd>

          <dt>Description</dt>
          <dd>
            <p>
            Overall, livestock health management involves a complex system of data collection, transmission, processing, analysis, and decision-making. By using this,
            it is possible to improve livestock health, prevent the spread of disease, and increase productivity. Livestock health management can be described from the perspective
            of data flow as follows.
            </p>
            <p>
            (Data collection) Data for livestock health management are collected from the livestock and the livestock barn being monitored. This data can include various types of
            physiological data, such as body temperature, heart rate, respiration rate, and fecal output, as well as environmental data, such as temperature, humidity, and air quality.
            </p>
            <p>
            (Data Processing) The data is then preprocessed on edge devices before being sent to the cloud server. The preprocessing step can involve cleaning the data, compressing it,
            and performing basic analysis to reduce the amount of data that needs to be transmitted.
            </p>
            <p>
            (Data transmission) Collected data is transmitted to a cloud server for analysis. This is typically done using wireless communication technologies such as Bluetooth,
            Wi-Fi, RFID, or cellular networks.
            </p>
            <p>
            (Data Analysis) The cloud server uses machine learning algorithms and AI models to analyze the data collected from the sensors and wearable devices.
            The analysis can include identifying patterns, predicting future health risks, and detecting early signs of illness or disease.
            </p>
            <p>
            (Decision Making) Based on the data analysis results, the livestock health management Service Provider or veterinarian with insights can make decisions about the care
            and treatment of the livestock. This can include taking preventative measures to reduce the risk of disease or illness, administering medication, or isolating sick livestock
            from the rest of the herd. Also, the livestock health management Service Provider or veterinarian establish a livestock health management plan that reflects the results of analysis.
            </p>
          </dd>

          <dt>Variants</dt>
          <dd>None.</dd>

          <dt>Security Considerations</dt>
          <dd>
            This use case does not define specific considerations for security issues. However, all data collected and analyzed for livestock health management should be managed
            using well-defined security technologies. In particular, it should be treated more safely because it is used as data for prescribing medicines for disease treatment.
          </dd>

          <dt>Privacy Considerations</dt>
          <dd>
            Establishing a systematic access method for all data acquired in livestock health management is necessary to protect the agricultural technology of farmers and
            ensure competitiveness. Only stakeholders who have a pre-existing contract or agreement are permitted to access and share/distribute the data.
          </dd>

          <dt>Accessibility Considerations</dt>
          <dd>None.</dd>

          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>None.</dd>

          <dt>Requirements</dt>
          <dd>
            <li>Protocol Requirements: Flexible.</li>
            <li>Contents Type Requirements: Flexible.</li>
            <li>Platform or Standard Requirements: None.</li>
            <li>Authentication and Authorization Mechanisms Requirements: Flexible.</li>
            <li>Communication Requirements: To transmit and share data collected from livestock or from the livestock barn, appropriate communication links and identification methods
                for individual livestock are necessary. High-speed communication links may be required to collect large data such as images or videos in real-time or to transmit data to
                external cloud server for data analysis.</li>
            <li>Data expression Requirements: Various data for livestock health management should be represented in a standardized format that is independent of the type or
                manufacturer of the device or equipment. Furthermore, all of this data must be stored and managed in a separate repository to maintain a history of the data,
                and data interoperability must be ensured.</li>
            <li>Other Requirements: Unlike a greenhouse or an open field, a livestock barn has an environment that is very humid and easily exposed to toxic gases due to manure.
                Since devices such as sensors and cameras installed in livestock barn can easily fail, the state of the device must be continuously managed remotely,
                and it must be replaced immediately if necessary.</li>
          </dd>

          <dt>Gaps</dt>
          <dd>None.</dd>

          <dt>Existing Standards</dt>
            <dd>None.</dd>

          <dt>Comments</dt>
            <dd>None.</dd>
      </dl>
  </section>
    <section id="UC-agricultural-machinery-management-1"><div class="header-wrapper"><h4 id="x3-1-7-agricultural-machinery-management"><bdi class="secno">3.1.7 </bdi>Agricultural Machinery Management</h4><a class="self-link" href="#UC-agricultural-machinery-management-1" aria-label="Permalink for Section 3.1.7"></a></div> 
      
      <dl>
          <dt>Submitter(s)</dt>
          <dd>Mun Hwan CHOI, ChangKyu LEE, Sunghyun YOON</dd>

          <dt>Target Users</dt>
          <dd><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-11">Service Providers</a>, machinery manufacturers, machinery owners, <a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-7">Device Manufacturer</a></dd>

          <dt>Motivation</dt>
          <dd>
            <p>
            Smart agriculture in open fields, which covers a considerably large area, requires various types of agricultural machinery such as tractors, combines, weeders, and pesticide sprayers,
            unlike greenhouse with limited space. However, since the cost of agricultural machinery is generally high, it is important to efficiently operate and manage the machinery
            to save costs and labor required for operating them.
            </p>
            <p>
            To manage agricultural machinery efficiently, farmers need to first establish an agricultural works plan that reflects the type of agricultural works required
            for each growth stage of the crops, the estimated time required, the type and quantity of machinery needed for each agricultural works.
            By implementing the established agricultural work plan, farmers can use machinery to complete the required agricultural work in the shortest time possible.
            In addition, IoT-connected machinery can share real-time progress status of the agricultural work and, if necessary, additional idle machinery can be added
            to shorten the time required for agricultural work.
            </p>
            <p>
            Various types of sensor devices installed on agricultural machinery collect data related to environmental conditions of the field and crop growth status.
            The collected data is used for the establishment of optimal production management strategies and optimization (update) of agricultural works plan to improve the productivity
            (convenience, operating cost) of farmhouse through AI-based analysis. Farmers can monitor the operational status of the agricultural machinery and the progress
            of the agricultural work anytime, anywhere through web or mobile devices, and can also transmit appropriate instructions in case of changes in the farming plan or equipment failures.
            </p>
          </dd>

          <dt>Expected devides</dt>
          <dd>
              <li>Communication device for data sharing between agricultural machinery and farm operation system</li>
              <li>GNSS (Global navigation satellite system) device or other geolocation system for tracking and monitoring the location of agricultural machinery</li>
              <li>IoT sensor devices for collecting environmental conditions and crop-growth status of farmland</li>
              <li>Operation recording devices of agricultural machinery and component failure monitoring sensors</li>
              <li>Data analysis systems for optimizing agricultural works plan and agricultural machinery management model</li>
          </dd>

          <dt>Expected data</dt>
          <dd>
              <li>Data including type of agricultural works, necessary agricultural machinery, required working hours for agricultural works plan according to crop-growth stages</li>
              <li>Operation status of the agricultural machinery, including location, operation status, fuel consumption, failure occurrence, etc.</li>
              <li>Environmental condition data of farmland and crop-growth status data collected from IoT sensor devices</li>
              <li>Agricultural work progress status and result report data</li>
              <li>Historical data related to agricultural works and agricultural machinery</li>
          </dd>

          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>WoT Thing Description</dd>

          <dt>Description</dt>
          <dd>
            <p>
            Efficient management of agricultural machinery is achieved through systematic management of various data, such as optimal agricultural works plans, machinery operation status,
            agricultural works execution results, and history of malfunctions or damages. This data can be analyzed based on AI and big data technology to establish the optimal
            production management strategy. Through this series of procedures, farm productivity can be improved.
            </p>
            <p>
            The farmer or agricultural machinery management service provider establish an agricultural works plan based on data such as the location of farmland,
            the types of agricultural works required, the time required to perform the agricultural works, the types of agricultural machinery required and their availability,
            and the history of past agricultural works execution. The establishment of the agricultural works plan is crucial because it serves as the basis for efficiently
            operating and managing agricultural machinery at the lowest cost possible. To establish an agricultural works plan, the farmer's requirements must be reflected,
            and consulting results from an agricultural expert group or expert system should be incorporated as necessary.
The system may also take into account factors such as local weather conditions and forecasts, including
historical conditions such as accumulated precipitation.
Management of machinery can also take into account predicted events, such as the
possible need for maintenance or repairs.
            </p>
            <p>
            Based on the established agricultural works plan, the necessary agricultural machinery is deployed and executes the corresponding agricultural works.
            During the process of agricultural works, the agricultural machinery collects and reports data on its operating status, occurrence of malfunctions or damages,
            agricultural works execution status and its results, as well as the status of the farmland and crops-growth to the farm operation system.
            The farm operation system can monitor the agricultural works progress in real-time, and can modify the agricultural works plan to immediately deploy the machinery
            that is not yet deployed or that can finish the assigned agricultural work soon, thus improving the operational efficiency of the agricultural machinery for the farm.
            </p>
            <p>
            The farm operation system analyzes the collected data comprehensively and utilizes it to update existing agricultural works plan and optimize production management
            strategies for the improvement of farm productivity. The collected and analyzed data can be shared with stakeholders, such as service providers, agricultural machinery
            manufacturers, and maintenance companies. Based on the shared data, service providers can improve the quality of agricultural machinery management services,
            while agricultural machinery manufacturers and maintenance companies can utilize the data to produce and maintain agricultural machinery that is optimized for
            the agricultural works demanded by farmers. Additionally, farmers can monitor the progress status and results of agricultural works through web or mobile devices.
            </p>
          </dd>

          <dt>Variants</dt>
          <dd>
            In small-scale farms, individual systems can be installed for managing agricultural machinery, but for managing various types of machinery in large-scale farms,
            it would be more cost-effective to use agricultural machinery management services provided by related business. In this case, the agricultural machinery is
            directly connected to the cloud server of the service provider to receive instructions for performing agricultural works and to report the results of the agricultural works.
          </dd>

          <dt>Security Considerations</dt>
          <dd>
            This use case does not define specific considerations for security issues. However, all data collected and analyzed for the agricultural machinery management
            should be managed using well-defined security technologies.
          </dd>

          <dt>Privacy Considerations</dt>
          <dd>
            In order to safeguard the agricultural technology utilized by farmers and maintain their competitiveness, it is essential to establish a structured approach
            for accessing all the data collected and shared during agricultural machinery management. Only stakeholders who have a pre-existing contract or agreement may be
            granted access to the data that is intended to be shared or distributed.
          </dd>

          <dt>Accessibility Considerations</dt>
          <dd>None.</dd>

          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>The data formats and units need to be adapted to the local standards, instructions need to be made available in the farmer's language, and scheduling needs to take into account cultural differences, such as holidays, daylight saving changes, or required breaks and hours for workers.</dd>

          <dt>Requirements</dt>
          <dd>
            <li>Protocol Requirements: Flexible.</li>
            <li>Contents Type Requirements: Flexible.</li>
            <li>Platform or Standard Requirements: None.</li>
            <li>Authentication and Authorization Mechanisms Requirements: Flexible.</li>
            <li>Communication Requirements: Diverse agricultural machinery and farm operation systems must be connected through a communication network to direct agricultural works and
              transmits the agricultural works execution results and collected data. As agricultural machinery is placed across a significantly large area for agricultural works,
              wireless communication methods utilizing technologies such as GSM, UMTS, LTE, CDMA, or 5G should be considered.</li>
            <li>Data Expression Requirement: Farmers may need or want to use equipment from various different manufacturers, either simultaneously or over time.
Therefore, various data for agricultural machinery management should be represented in a standardized format that is independent of the type or manufacturer of the agricultural
              machinery or equipment. Furthermore, all of this data must be stored and managed in a separate repository to maintain a history of the data, and data interoperability must be ensured.</li>
          </dd>

          <dt>Gaps</dt>
          <dd>None.</dd>

          <dt>Existing Standards</dt>
            <dd>None.</dd>

          <dt>Comments</dt>
            <dd>None.</dd>
      </dl>
  </section>
</section>

    <section id="smart-city"><div class="header-wrapper"><h3 id="x3-2-smart-city"><bdi class="secno">3.2 </bdi>Smart City</h3><a class="self-link" href="#smart-city" aria-label="Permalink for Section 3.2"></a></div>
      
      <section id="UC-smartcity-geolocation-1"><div class="header-wrapper"><h4 id="x3-2-1-smart-city-geolocation"><bdi class="secno">3.2.1 </bdi>Smart City Geolocation</h4><a class="self-link" href="#UC-smartcity-geolocation-1" aria-label="Permalink for Section 3.2.1"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            Jennifer Lin, Michael McCool
          </dd>
          <dt>Target Users</dt>
          <dd>
            <p>
              A Smart City managing mobile devices and sensors,
              including passively mobile sensor packs, packages,
              vehicles, and autonomous robots, where their location needs to
              be determined dynamically.
            </p>
            
          </dd>
          <dt>Motivation</dt>
          <dd>
            <p>
              Smart Cities need to track a large number of mobile devices and sensors.
              Location information may be integrated with a logistics or fleet management
              system.
              A reusable geolocation module is needed with a common network interface to
			  include in these various applications.
              For outdoor applications, GPS
              could be used, but indoors other geolocation technologies might be
              used, such as WiFi triangulation or vision-based navigation (SLAM).
              Therefore the geolocation information should be technology-agnostic.
            </p>
            <p>
              NOTE: we prefer the term "geolocation", even indoors, over "localization" to
              avoid confusion with language localization.
            </p>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <p>
              One of the following:
            </p><ul>
              <li>A geolocation system on a personal device, such as a smart phone.</li>
              <li>A geolocation system to be attached to some other portable device.</li>
              <li>A geolocation system attached to a mobile vehicle.</li>
              <li>A geolocation system on a payload transported by a vehicle.</li>
              <li>A geolocation system on an indoor mobile robot.</li>
            </ul>
            <p></p>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>Sensor ID</li>
              <li>Timestamp of last geolocation</li>
              <li>2D location
                <ul>
                  <li>typically latitude and longitude</li>
                  <li>May also be semantic, i.e. room in a building, exit</li>
                </ul>
              </li>
            </ul>
          </dd><dd>Optional:
            <ul>
              <li>Semantic location
                <ul>
                  <li>Possibly in addition to numerical lat/long location.</li>
                </ul>
              </li>
              <li>Altitude
                <ul>
                  <li>May also be semantic, i.e. floor of a building</li>
                </ul>
              </li>
              <li>Heading</li>
              <li>Speed</li>
              <li>Accuracy information
                <ul>
                  <li>Confidence interval, e.g. distance that true location will be within some probability.</li>
                  <li>Gaussian covariance matrix</li>
                  <li>For each measurement</li>
                  <li>For lat/long, may be a single value (see web browser API; radius?)</li>
                </ul>
              </li>
              <li>Geolocation technology (GPS, SLAM, etc.).
                <ul>
                  <li>Note that multiple technologies might be used together.</li>
                  <li>Include parameters such as sample interval, accuracy</li>
                </ul>
              </li>
              <li>For each geolocation technology, data specific to that technology:
                <ul>
                  <li>GPS: NMEA type [<cite><a class="bibref" data-link-type="biblio" href="#bib-nmea-0183" title="NMEA 0183 Interface Standard">NMEA-0183</a></cite>]</li>
                </ul>
              </li>
              <li>Historical data</li>
            </ul>
            <p>
              Note: the system should be capable of notifying consumers
              of changes in location.
              This may be used to implement geofencing by some other system.
              This may require additional parameters, such as the
              maximum distance that the device may be moved before a notification is
              sent, or the maximum amount of time between updates.
              Notifications may be sent by a variety of means, some of which may
              not be traditional push mechanisms (for example, email might be used).
              For geofencing applications, it is not necessary that the device be aware
              of the fence boundaries; these can be managed by a separate system.
            </p><p>
          </p></dd>
          <dt>Dependencies</dt>
          <dd>
            node-wot
          </dd>
          <dt>Description</dt>
          <dd>
            <p>
              Smart Cities have the need to observe the physical locations of
              large number of mobile devices
              in use in the context of a Fleet or Logistics Management System, or
              to place sensor data on a map in a Dashboard application.
              These systems may also include geofencing notifications and mapping
              (visual tracking) capabilities.
            </p>
          </dd>
          <dt>Variants</dt>
          <dd>
            <p>
            </p><ul>
              <li>A version of the system may log historical data so the past
                locations of the devices can be recovered.</li>
              <li>Geolocation technologies other than GPS may be used. The payload
                may contain additional information specific to the geolocation
                technology used. In particular, in indoor situations technologies such
                as WiFi triangulation or (V)SLAM may be more appropriate.</li>
              <li>Geofencing may be implemented using event notifications and
                will require setting of additional parameters such as maximum distance.</li>
            </ul>
            <p></p>
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            <p>
              High-resolution timestamps can be used in conjunction with cache manipulation to
              access protected regions of memory, as with the SPECTRE exploit. Certain
              geolocation APIs and technologies can return high-resolution timestamps which
              can be a potential problem. Eventually these issues will be addressed in cache
              architecture but in the meantime a workaround is to artificially limit the
              resolution of timestamps.
            </p>
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            <p>
              Location is generally considered private information when it is used with a device
              that may be associated with a specific person, such as a phone or vehicle, as it
              can be used to track that person and infer their activities or who they associate
              with (if multiple people are being tracked at once). Therefore APIs to access geographic location
              in sensitive contexts are often restricted, and access is allowed only after confirming
              permission from the user.
            </p>
          </dd>
          <dt>Gaps</dt>
          <dd>
            <p>
              There is no single standardized semantic vocabulary for representing location data.
              Location data can be point data, a path, an area or a volumetric object.
              Location information can be expressed using multiple standards,
              but the reader of location data in a TD or in data returned by an IoT device
              must be able to unambiguously describe location information.
            </p>
            <p>
              There are both dynamic (data returned by a mobile sensor) and static (fixed installation
              location) applications for geolocation data. For dynamic location data, some recommended vocabulary
              to annotate data schemas would be useful. For static location data, a standard format
              for metadata to be included in a TD itself would be useful.
            </p>
          </dd>
          <dt>Existing Standards</dt>
          <dd>
            <p>
            </p><ul>
              <li>NMEA: defines sentences from GPS devices [<cite><a class="bibref" data-link-type="biblio" href="#bib-nmea-0183" title="NMEA 0183 Interface Standard">NMEA-0183</a></cite>]</li>
              <li>World Geodetic System (WGS84) [<cite><a class="bibref" data-link-type="biblio" href="#bib-wgs84" title="World Geodetic System 1984 (WGS 84)">WGS84</a></cite>]:
                <ul>
                  <li>Defines lat/long/alt coordinate system used by most other geolocation standards</li>
                  <li>More complicated than you would think (need to deal with deviations of Earth from
                    a true sphere, gravitational irregularities, position of centroid, etc. etc.)</li>
                </ul>
              </li>
              <li>Basic Geo Vocabulary [<cite><a class="bibref" data-link-type="biblio" href="#bib-w3c-basic-geo" title="Basic Geo (WGS84 lat/long) Vocabulary">w3c-basic-geo</a></cite>]:
                <ul>
                  <li>Very basic RDF definitions for lat, long, and alt</li>
                  <li>Does not define heading or speed</li>
                  <li>Does not define accuracy</li>
                  <li>Does not define timestamps</li>
                  <li>Uses string as a data model (rather than a number)</li>
                </ul>
              </li>
              <li><abbr title="World Wide Web Consortium">W3C</abbr> Geolocation API [<cite><a class="bibref" data-link-type="biblio" href="#bib-geolocation-api" title="Geolocation API Specification 2nd Edition">geolocation-API</a></cite>]:
                <ul>
                  <li><abbr title="World Wide Web Consortium">W3C</abbr> Devices and Sensors WG is now handling</li>
                  <li>There is an updated proposal: <a href="https://w3c.github.io/geolocation-sensor/#geolocationsensor-interface">https://w3c.github.io/geolocation-sensor/#geolocationsensor-interface</a>
                  </li>
                  <li>Data schema of updated proposal is similar to existing API, but all elements are now optional</li>
                  <li>Data includes latitude, longitude, altitude, heading, and speed</li>
                  <li>Accuracy is included for latitude/longitude (single number in meters, 95% confidence,
                    interpretation
                    a little ambiguous, but probably intended to be a radius) and altitude, but not for heading or
                    speed.
                  </li>
                </ul>
              </li>
              <li>Open Geospatial Consortium [<cite><a class="bibref" data-link-type="biblio" href="#bib-ogc" title="Open Geospatial Consortium">OGC</a></cite>]:
                <ul>
                  <li>See OGC Abstract Specification Topic 2: Referencing by coordinates [<cite><a class="bibref" data-link-type="biblio" href="#bib-ogc-coords" title="OGC Abstract Specification Topic 2: Referencing by coordinates">OGC-coords</a></cite>]</li>
                  <li>Referring to locations by coordinates</li>
                  <li>Has standards defining semantics for identifying locations</li>
                  <li>Useful for mapping</li>
                </ul>
              </li>
              <li>ISO:
                <ul>
                  <li>ISO 19111 [<cite><a class="bibref" data-link-type="biblio" href="#bib-iso-19111-2007" title="Geographic information -- Spatial referencing by coordinates">iso-19111-2007</a></cite>], [<cite><a class="bibref" data-link-type="biblio" href="#bib-iso-19111-2019" title="ISOi 19111:2019 - Geographic information — Referencing by coordinates">iso-19111-2019</a></cite>]</li>
                  <ul>
                    <li>Standard for referring to locations by coordinates</li>
                    <li>Related to OGS standard above and WGS84</li>
                  </ul>
                  <li>Various other standards that relate to remote sensing, geolocation, etc.</li>
                  <li>Here is an example (see references): <a href="https://www.iso.org/obp/ui/#iso:std:iso:ts:19159:-2:ed-1:v1:en">https://www.iso.org/obp/ui/#iso:std:iso:ts:19159:-2:ed-1:v1:en</a>
                  </li>
                </ul>
              </li>
              <li>Semantic Sensor Network Ontology (SSN/SOSA) [<cite><a class="bibref" data-link-type="biblio" href="#bib-vocab-ssn" title="Semantic Sensor Network Ontology">vocab-ssn</a></cite>]:
                <ul>
                  <li>Defines "accuracy": <a href="https://www.w3.org/TR/vocab-ssn/#SSNSYSTEMAccuracy">https://www.w3.org/TR/vocab-ssn/#SSNSYSTEMAccuracy</a>
                  </li>
                  <li>Definition of accuracy is consistent with how it is used in Web Geolocation API</li>
                  <li>Also defines related terms Precision, Resolution, Latency, Drift, etc.</li>
                </ul>
              </li>
              <li>Timestamps:
                <ul>
                  <li><abbr title="World Wide Web Consortium">W3C</abbr> High Resolution Time [<cite><a class="bibref" data-link-type="biblio" href="#bib-hr-time-3" title="High Resolution Time">hr-time-3</a></cite>] </li>
                  <li>See also related issues such as latency defined in SSN</li>
                </ul>
              </li>
            </ul>
            <p>
              Note that accuracy and time are issues that apply to all kinds of sensors, not just
              geolocation. However, the specific geolocation technology of GPS
              is special since it is also a source of accurate time.
            </p>
          </dd>
        </dl>
      </section>
      <section id="UC-smartcity-dashboard-1"><div class="header-wrapper"><h4 id="x3-2-2-smart-city-dashboard"><bdi class="secno">3.2.2 </bdi>Smart City Dashboard</h4><a class="self-link" href="#UC-smartcity-dashboard-1" aria-label="Permalink for Section 3.2.2"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            Michael McCool
          </dd>
          <dt>Target Users</dt>
          <dd>
            <p>
              A Smart City managing a large number of devices whose data
              needs to be visualized and understood in context.
            </p>
            <p>
              Stakeholders include:
            </p><ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-4">Device Owners</a>: need to make data from devices available to dashboard system.</li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-4">Device User</a>: users of the dashboard system, such as members of city management,
                are indirectly "using" the devices by accessing their data, and
                in one variant, sending commands to actuators.</li>
              <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-5">Cloud Provider</a>: the dashboard system itself or components of it (such as a database or data ingestion
                system) may
                be hosted in the cloud.</li>
            </ul>
            <p></p>
            
          </dd>
          <dt>Motivation</dt>
          <dd>
            <p>
              In order to facilitate Smart City planning and decision-making, a Smart City
              dashboard interface makes it possible for city management to
              view and visualize all sensor data through the entire city in real time,
              with data identified as to geographic source location.
            </p>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <p>
              Actuators can include robots; for these, commands might be given to robots to move to new locations,
              drop off or pick up sensor packages, etc.
              However, it could also include other kinds of actuators, such as flood gates, traffic signals, lights,
              signs, etc.
              For example, posting a public message on an electronic billboard might be one task possible through the
              dashboard.
            </p>
            <p>
              Sensors can include those for the environment and for people and traffic management
              (density counts, thermal cameras, car speeds, etc.).
              status of robots, other actuators, and sensors, data visualization,
              and (optionally) historical comparisons.
            </p>
            <p>
              Dashboard would include mapping functionality.
              Mapping implies a need for location data for every actuator and sensor, which could be
              acquired through geolocation sensors (e.g. GPS) or assigned statically during installation.
            </p>
            <p>
              This use case also includes images from cameras and real-time image and data streaming.
            </p>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <p>
            </p><ul>
              <li>Environmental data for temperature, humidity, UV levels, pollution levels, etc.</li>
              <li>Infrastructure status (water flow, electrical grid, road integrity, etc.)</li>
              <li>Emergency sensing (flooding, earthquake, fire, etc.)</li>
              <li>Traffic (both people and vehicles)</li>
              <li>Health monitoring (e.g.fever tracking, mask detection, social distancing)</li>
              <li>Safety monitoring (e.g.wearing construction helmets on a construction site)</li>
              <li>Reports from non-IoT sources (for example, police reports of crimes, hospital emergency case reports)
              </li>
              <li>Images and data derived from images (people traffic and density can be derived from image analysis).
                All data would need an associated geolocation and timestamp so it can be placed in time and space.</li>
            </ul>
            <p></p>
          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>Thing description - support for data ingestion and normalization, geolocation and timestamp standards.
              </li>
              <li>Discovery - directories capable of tracking and managing a large number of devices on a large and
                possibly segmented network</li>
            </ul>
            <p></p>
          </dd>
          <dt>Description</dt>
          <dd>
            <p>
              Data from a large number and wide variety of sensors needs to be integrated
              into a single database and normalized, then placed in time and space, and
              finally visualized.
            </p>
            <p>
              The user, a member of city management responsible for making planning decisions,
              sees data visualized on a map suitable for planning decisions.
            </p>
            <p>
              Variants:
            </p><ul>
              <li>Historical data may also be available (allowing an analysis of trends over time).</li>
              <li>It may be possible to also issue commands to actuators through the interface.</li>
              <li>The system may be used for emergency response (for instance, closing floodgates in response to an
                expected tsunami)</li>
              <li>A subset of the data visualization capabilities may be made available to the public (for example,
                traffic)</li>
              <li>Filtering based on parameters such as location (area, state, county, country, zip code, etc.), sensor
                type, subject matter, etc.</li>
              <li>Ability to generate alerts off of various parameters</li>
              <li>Ability to produce logs off historical data</li>
            </ul>
            <p></p>
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            <p>
            </p><ul>
              <li>Access to data should only be provided to authorized users, although some may be made available
                publicly</li>
              <li>Access to actuators should only be provided to authorized users, and commands should be recorded for
                auditing.</li>
            </ul>
            <p></p>
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            <p>
            </p><ul>
              <li>Management of privacy-sensitive information, for example images of people,
                should be controlled and ideally not associated with specific individuals</li>
              <li>Data that can be used to track movements of particular individuals should be controlled or eliminated.
              </li>
              <li>Data purge functions should be supported to allow the permanent deletion of private data.</li>
            </ul>
            <p></p>
          </dd>
          <dt>Gaps</dt>
          <dd>
            <p>
            </p><ul>
              <li>Geolocation data standards</li>
              <li>Timestamp data standards</li>
              <li>Scalable Discovery</li>
            </ul>
            <p></p>
          </dd>
        </dl>
      </section>
      <section id="UC-interactive-public-spaces-1"><div class="header-wrapper"><h4 id="x3-2-3-interactive-public-spaces"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</h4><a class="self-link" href="#UC-interactive-public-spaces-1" aria-label="Permalink for Section 3.2.3"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael McCool

          </dd>
          <dt>Category</dt>
          <dd>

            Accessibility

            
          </dd><dt>Motivation</dt>
          <dd>

            Public spaces provide many opportunities for engaging, social and fun interaction.
            At the same time,
            preserving privacy while sharing tasks and activities with other people is a major issue
            in ambient systems.
            These systems may also deliver personalized information in combination
            with more general services presented publicly.

            A trustful discovery of the services and devices available in such environments
            is a necessity to guarantee personalization and privacy in public-space applications.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Public spaces supporting personalizable services and device access.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Command and status information transferred between the personal mobile device
            application and the public space's services and devices.
            <br>
            <br>
            Profile data for user preferences.

          </dd>
          <dt>Dependencies</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dd>Optional:
            <ul>
              <li>WoT Scripting API in application on mobile personal device and possibly
                in IoT orchestration services in the public space.</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Interactive installations such as touch-sensitive or gesture-tracking billboards
            may be set up in public places.
            Objects that present public information (e.g. a map of a shopping mall)
            can use a multimodal interface (built-in or in tandem with the user's mobile devices)
            to simplify user interaction and provide faster access.
            Other setups can stimulate social activities,
            allowing multiple people to enter an interaction simultaneously to work together
            towards a certain goal (for a prize)
            or just for fun (e.g. play a musical instrument or control a lighting exhibition).
            In a context where privacy is an issue
            (for example, with targeted/personalized alerts or advertisements),
            the user's mobile device acts as a mediator for the services
            running on the public network.
            This allows the user to receive relevant information in the way they see fit.
            Notifications can serve as triggers for interaction with public devices and services
            if the user chooses to do so.

          </dd>
          <dt>Variants</dt>
          <dd>

            The user may have additional mobile devices they want to incorporate into
            an interaction, for example a headset acting as an auditory aid or personal speech output
            device.

          </dd>
          <dt>Gaps</dt>
          <dd>

            Data format describing user interface preferences.

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            This use case is based on MMI UC 3.1 [<cite><a class="bibref" data-link-type="biblio" href="#bib-mmi-use-cases" title="Multimodal Interaction Use Cases">mmi-use-cases</a></cite>].

          </dd>
          <dt>Comments</dt>
          <dd>

            Does not include Requirements section from original MMI use case.
          </dd>
        </dl>
      </section>
      <section id="UC-meeting-room-event-assistance-1"><div class="header-wrapper"><h4 id="x3-2-4-meeting-room-event-assistance"><bdi class="secno">3.2.4 </bdi>Meeting Room Event Assistance</h4><a class="self-link" href="#UC-meeting-room-event-assistance-1" aria-label="Permalink for Section 3.2.4"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael McCool

          </dd>
          <dt>Category</dt>
          <dd>

            Accessibility

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Meeting space supporting personalizable services and device access.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Command and status information transferred between the personal mobile device
            application and the meeting space's services and devices.

            Profile data for user preferences.

          </dd>
          <dt>Dependencies</dt>
          <dd>

            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
              <li>Optional: WoT Scripting API in application on mobile personal device and possibly
                in IoT orchestration services in the meeting space.</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>

            A conference room where a series of meetings will take place.
            People can go in and out of the room before,
            after and during the meeting.
            The door is "touched" by a badge.
            An application on the user's mobile device can
            activate any available display in the room and the room and can access and
            receive notification from devices and services in the room.
            The chair of the meeting is notified by a dynamically composed graphic animation,
            audio notification or a mobile phone notification,
            about available devices and services, and
            can install applications indicated by links.

            The chair of the meeting selects a setup procedure by text amongst the provided links.
            These options could be, for example:
            photo step-by-step instructions (smartphone, HDTV display, Web site),
            audio instructions (MP3 audio guide, room speakers reproduction, HDTV audio)
            or RFID enhanced instructions (mobile SmartTag Reader, RFID Reader for smartphone).
            The chair of the meeting chooses the room speakers reproduction,
            then the guiding Service is activated and they start to set the video projector.
            After some attendees arrive,
            the chair of the meeting changes to the slide show option and continues to
            follow the instructions at the same step it was paused but with another more
            private modality for example, a smartphone slideshow.

          </dd>
          <dt>Variants</dt>
          <dd>

            The user may have additional mobile devices they want to incorporate into
            an interaction, for example a headset acting as an auditory aid or personal speech output
            device.

          </dd>
          <dt>Gaps</dt>
          <dd>

            Data format describing user interface preferences.

            Ability to install applications based on links that can access IoT services.

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            This use case is based on MMI UC 3.2 [<cite><a class="bibref" data-link-type="biblio" href="#bib-mmi-use-cases" title="Multimodal Interaction Use Cases">mmi-use-cases</a></cite>].

          </dd>
          <dt>Comments</dt>
          <dd>

            Does not include Requirements section from original MMI use case.
          </dd>
        </dl>
      </section>

      <section id="UC-cross-domain-discovery-in-a-smart-campus-1"><div class="header-wrapper"><h4 id="x3-2-5-cross-domain-discovery-in-a-smart-campus"><bdi class="secno">3.2.5 </bdi>Cross-Domain Discovery in a Smart Campus</h4><a class="self-link" href="#UC-cross-domain-discovery-in-a-smart-campus-1" aria-label="Permalink for Section 3.2.5"></a></div>
         
        <dl>

          <dt>Submitter(s)</dt>
          <dd>
            Andrea Cimmino and Raúl García Castro

          </dd>
          <dt>Target Users</dt>
          <dd>

            <ul>
              <li> <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-5">Device Owners</a></li>
              <li> <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-12">Service Provider</a></li>
              <li> network operator (potentially transparent for WoT use cases)</li>
              <li> directory service operator</li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            In this use case a network full of IoT devices is presented, in which these devices are registered in
            several Middle-Nodes. The challenge presented in this scenario is to be able to discover the different
            sensors, by issues a SPARQL query, and without having prior knowledge of where those devices are allocated.
            Therefore, the discovery SPARQL query must start from a specific Middle-Node and reach all those
            Middle-Nodes that are relevant to answer the query.

            This scenario requires that discovery does not only happen locally when a Middle-Node receives the query and
            checks if some Thing Description registered is suitable to answer the query. Instead, the scenario requires
            also that the Middle-Node forwards the query through the network (topology conformed by the middle-nodes) in
            order to find those Middle-Nodes that actually contain relevant Thing Descriptions. Notice from the
            following example that the query is not broadcasted in the network to prevent flooding, instead the
            Middle-Nodes follow some discovery heuristic to know where the query should be forwarded. Also, notice that
            in this scenario not all the Middle-Nodes have the IoT devices registered directly within, they are
            Middle-Nodes collectors, such as Middle-Node C, I, G, and D.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Any device from the energy context (e.g. solar panels, smart plugs, or smart energy meters), devices from
            the building context (e.g. light bulbs, light switches, occupancy sensors, or thermostats), devices from
            the environmental context (e.g. soil moisture, flood detection, or air humidity), devices from the
            wearables context (e.g. smart bands), and/or devices from the water context (e.g. water valves, or water
            quality sensors)

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Data coming from different contexts, such as Energy, Building, Environmental Wearables and Water.

          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            Current WoT-Discovery approach

          </dd>
          <dt> Description</dt>
          <dd>
            A campus has a wide range of IoT devices distributed across their grounds. These IoT devices belong to very
            different domains in a smart city, such as, energy, buildings, environment, water, wearable, etc. The IoT
            devices are distributed across the campus and belong to different infrastructures or even to individuals. A
            sample topology of this scenario could be the following:

            <br>
            <br>

            <div class="resize"><img src="images/smart-campus-topology.svg" alt="sample topology of a smart campus">
            </div>
            <br>
            <br>

            In this scenario, energy-related IoT devices monitor the energy use and income in the campus, among other
            things. From these measurements, an Energy Management System may predict a negative peak of incoming energy
            that would entail the failure of the whole system. In this case, a Service or a User needs to discover all
            those IoT devices that are not critical for the normal functioning of the campus (such as indoor or outdoor
            illumination, HVAC systems, or water heaters) and interact with them in order to save energy, by switching
            them off or reducing their consumption. Besides, the same Service or User will look for those IoT devices
            that are critical for the well-functioning of the campus (such as magnetic locks, water distribution system,
            or fire/smoke sensors) and ensure that they are up and running. Additionally, the Service or the User, will
            discover relevant people's wearable to warn them about the situation.

            <p>Sample flow:</p> A service, or a user, sends a (SPARQL) query to the discovery endpoint of a known
            Middle-Node (which can be wrapped by a GUI). The Middle-Node will try to answer the query first checking the
            Thing Descriptions of the IoT devices registered in such Middle-Node. Then, if the query requires further
            discovery, or it was not successfully answered the Middle-Node will forward the query to its *known*
            Middle-Nodes. Recursively, the Middle-Nodes will try to answer the query and/or forward the query to their
            known Middle-Nodes. When one Middle-Node is able to answer the query it will forward back to the former
            Middle-Node the partial query answer. Finally, when the discovery task finishes, the former Middle-Node will
            join all the partial query answers producing an unified view (which could be synchronous or asynchronous).

            <br>
            <br>

            For instance, assuming Middle-Node F receives a query that asks about all the discoverable Building IoT
            devices in the campus. First, the Middle-Node F will try to answer the query with the Thing Descriptions of
            the IoT registered within. Since Middle-Node F contains some Building IoT devices a partial query answer is
            achieved. However, since they query asked about all the discoverable Building IoT devices Middle-Node F
            should forward the query to its other known Middle-Nodes, i.e., Middle-Node G. This process will be repeated
            by the Middle-Nodes until the query reaches the Middle-Nodes H and B which are the ones that have registered
            Thing Descriptions about IoT buildings. Therefore, the query will travel through the topology as follows:
            <br>
            <br>
            <div class="resize"><img src="images/smart-campus-sample.svg" alt="query goes through the topology for a smart campus"></div>
            <br>
            <br>
            Finally, when Middle Nodes B and H compute two partial query answers, those answers will be forwarded back
            to Middle-Node F which will join them with its former partial query answer obtained from its registered
            Thing Descriptions. Finally, a global query answer will be provided.

          </dd>

          
          <dt>Security Considerations</dt>
          <dd>
            None, in this case an underneath infrastructure that handles security is assumed

          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None, although relevant in this case the core of the use case relies on the feature of finding across the
            network different IoT devices. It is assumed that there is an underneath infrastructure that handles privacy

          </dd>
          <dt>Gaps</dt>
          <dd>

            Been able to find suitable Middle-Nodes that are relevant to answer the query, with no prior knowledge

          </dd>
          <dt>Existing Standards</dt>
          <dd>
            None
          </dd>
          <dt>Comments</dt>
          <dd>
            None
          </dd>
        </dl>
      </section>

      <section id="UC-cultural-spaces-museums-1"><div class="header-wrapper"><h4 id="x3-2-6-cultural-spaces-museums"><bdi class="secno">3.2.6 </bdi>Cultural Spaces (Museums)</h4><a class="self-link" href="#UC-cultural-spaces-museums-1" aria-label="Permalink for Section 3.2.6"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Konstantinos Kotis, K. Zachila, A. Dimara

          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-6">Device Owners</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-5">Device User</a></li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-13">Service Provider</a></li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            
            <p>
              This use case is related to the semantic modeling of trustworthy IoT entities in energy-efficient cultural
              spaces such as museums.</p>
            <p>
              Nowadays, energy-saving issues have awakened the research community's interest due to the more and more
              increasing
              global electricity demand. An excessive
              use of energy is believed to derive from public and industrial buildings to cover their daily load
              requirements in
              the context of the provision of their services.
              Thus, the necessity of developing energy-efficient buildings could be proved beneficial. Notably, the
              improvement
              of buildings' energy efficiency leads to Building
              Energy Management Systems (BEMS).
            </p>
            BEMS objectives include but not limited to:
            <ol style="list-style-type:lower-alpha">
              <li>the continuous management of energy towards energy consumption optimization;</li>
              <li>the optimization of buildings' visiting conditions towards enhancing visitors experience and
                comfort,</li>
              <li>the optimization of buildings' environmental conditions towards the protection and preservation of
              </li>
              artifacts
              (indirect contribution).
            </ol>
            <p>
              The application of BEMS in the context of energy-saving at cultural spaces, and especially at the museums'
              spaces,
              is an evolving recent research interest. The protection and preservation of artworks and ancient objects
              isolated in museums, leads to the
              necessity of continuous monitoring of the environmental
              factors and indoor conditions like temperature, humidity and CO2. This monitoring involves Internet of
              Things
              (IoT) entities, which may be considered as an
              integral part of BEMS, to reduce energy consumption without: a) sacrificing humans' visiting experience
              and
              comfort indoor levels, and b) sacrificing artworks'
              protection and preservation.
            </p>
            The aim of the presented use case is to sketch and highlight the following requirements for knowledge
            representation:
            <ol style="list-style-type:lower-alpha">
              <li>representing knowledge related to the trustworthy IoT entities that are deployed in a museum i.e.,
                things
                (e.g,
                exhibits, spaces), sensors, actuators, people, data, applications;</li>
              <li>dealing with entities' heterogeneity via semantic interoperability and integration, especially for
                'smart'
                museum applications and generated data;</li>
              <li>representing knowledge related to saving energy e.g., lights, air-conditioning;</li>
              <li>representing knowledge related to museum visits and visitors towards enhancing visiting experience
                while
                preserving comfort;</li>
              <li>representing knowledge related to environmental conditions towards protecting and preserving museum
                artwork via
                continuous monitoring.</li>
            </ol>

            A selective representative list of scenarios related to such a use case are listed below. Its scenario is
            classified to one of the abovementioned requirements:
            <ul>
              <li>Requirement (a) (trustworthy IoT entities representation and management):
                 Count all the sculptures of the museum that are related to visits made by trustworthy students (with a
                trust
                degree more than 0.8).
                 Name all the trustworthy paintings of the museum created by "Picasso" (paintings that were created by
                Picasso
                with a trust degree more than 0.9).</li>
              <li>
                Requirement (b) (interoperability and integration):
                 If there are more than two visitors in room "UoAMuseumRoomA1" close to (nearby) an exhibit, classify
                this
                exhibit as an "interesting exhibit in
                room UoAMuseumRoomA1", turn up the light of this exhibit, and lower the light of the remaining exhibits
                in
                the
                room. This scenario is related to objectives (c) and (d) at the same time.
                 If the temperature of room "UoAMuseumRoomA1" and room "UoA-MuseumRoomA2" is less than 18 degrees
                Celsius,
                and
                there are visits in progress in these rooms, then activate the heating device in the rooms
                that those visits take place, and deactivate other sources of energy in the remaining rooms of the
                building.</li>
              <li>Requirement (c) (energy saving):
                 If there are no visitors in room "UoAMuseumRoomA1", then turn the lights off (or all the sources of
                energy).
                 If the museum's internal and external temperature is between 20 and 30 degrees Celsius, then keep the
                heating
                and cooling devices off.</li>
              <li>Requirement (d) (enhancing visiting experience and comfort):
                 When a visitor enters the museum for the first time, send him a message (e.g., SMS or tweet) with the
                number and
                types of rooms, the number
                and collections of exhibits, and the average duration of a visit per room.
                 If a visitor comes out of the museum, then send him a message with the names of the exhibits he liked
                most
                based
                on the observations he made
                during his/her visit.</li>
              <li>Requirement (e) (environmental conditions):
                 If the temperature in room "UoAMuseumRoomA1" is less than 18 degrees Celsius, then activate the
                heating
                device
                (for visitors' comfort).
                 If the humidity in room A is more than 55%, then activate the humidifier device (for exhibits
                protection).

                In respect to current WoT Things Description, the requirement here is to extend schema in order to
                represent
                trust
                (trustworthy things, trustworthy devices, trustworthy IoT entities in general).</li>
            </ul>

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Humidity sensor, temperature sensor, motion sensor, light sensor, proximity sensor, camera, aircondition,
            humidifier, light, smart lamp, smart lock, smart door.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Weather (indoors/outdoors) and climate data, sensor data, visitors/visiting data, profile data, movement
            (trajectory) data, cultural data.

          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>

            
            Web of Things Thing Description (WoT TD): to represent trust (trustworthy things and trustworthy IoT
            entities in
            general i.e., devices, people, processes, data).

          </dd>
          <dt>Description</dt>
          <dd>
            From users perspective, this use case sketches knowledge required for an ontology-based BEMS to answer
            queries
            such as:
            <li>Which exhibits are located in UoAMuseumRoomA1?</li>
            <li>How many sensors (all kinds) are hosted by IoTmuseumPlatformLG?</li>
            <li>Which rooms have been visited by Visitor01?</li>
            <li>What temperature measurements have been made in UoAMuseumRoomA1 between 09.00 and 17.00 on 07/12/2020?
            </li>
            <li>For observations that are made for Painting01 (in UoAMuseumRoomA1) at 09.00 on 15/01/2021, what is its
              status in
              terms of its lamp brightness level and nearby visitors?</li>
            
            <p>
              Reasoning with this knowledge, the identification of interesting exhibits and energy-related observations
              (based on sensing visitors' proximity to exhibits and observation of exhibits' lamp brightness level) is
              realized.</p>
            <p>
              For instance, if the brightness level of an exhibit's lamp is "medium" and there are more than two
              visitors
              near
              the exhibit, then this observation
              is classified as a) an interesting-exhibit observation and b) an observation to high level energy, meaning
              that
              the level of energy (light) for the
              lamp of the exhibit of this observation must be raised to high. In addition (another example), if the
              brightness
              level of the exhibit's lamp is "medium" and less
              than two visitors are nearby this, then classify this as an observation to low level energy, meaning that
              the
              level of energy (light) for the lamp of the exhibit of this observation must be raised to low. These
              examples indicate that a change (decrease or
              increase) to
              the level of light (energy) of the
              observed exhibit must be applied.
            </p>
          </dd>
          <dt>Security Considerations</dt>
          <dd>

            Due to visitors/visiting and profile data access requirement, as well as access to data related to
            public/private
            buildings, security issues must be considered.

          </dd>
          <dt>Privacy Considerations</dt>
          <dd>

            Due to visitors/visiting and profile data access requirement, as well as access to data related to
            public/private
            buildings, privacy issues must be considered.

          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>

            Accessibility must be a concern in the Cultural Spaces domain. Collaboration with the <abbr title="World Wide Web Consortium">W3C</abbr> Linked Data for
            Accessibility Community Group is needed.

          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>

            Internationalization must be a concern as the Culture is an international industry. Need to provide
            multilanguage
            labels in different languages e.g., English, French, Chinese.

          </dd>
          <dt>Requirements</dt>
          <dd>

            

          </dd>
          <dt>Gaps</dt>
          <dd>

            
            <p>Web of Things Thing Description (WoT TD): representation of IoT entities trust (trustworthy things,
              trustworthy
              IoT entities in general i.e., devices, people, processes, data).
              An IoT-trust related knowledge representation (in OWL) is provided by Kotis et al. as an example:
              https://github.com/KotisK/IoTontos/blob/master/Ontologies/IoT/IoT-trust-onto-v06.owl (or
              http://i-lab.aegean.gr/kotis/Ontologies/IoT/IoT-trust-onto-v06.owl).
            </p>
            <p>Related paper:
              Kotis, K., I. Athanasakis, and G. A. Vouros, "Semantically Enabling IoT Trust to Ensure and Secure
              Deployment of
              IoT Entities", Int. J. of Internet of Things and Cyber-Assurance, vol. 1, issue 1: Inderscience, pp. 3-21,
              2018.
              (<a href="http://dx.doi.org/10.1504/IJITCA.2018.10011243">http://dx.doi.org/10.1504/IJITCA.2018.10011243</a>)
            </p>
          </dd>
          <dt>Existing standards</dt>
          <dd>

            <ul>
              <li>SAREF4ENER ETSI Standard [<cite><a class="bibref" data-link-type="biblio" href="#bib-saref4ener" title="SAREF4ENER: an extension of SAREF for the energy domain created in collaboration with Energy@Home and EEBus associations">SAREF4ENER</a></cite>]</li>
              <li>SAREF4BLDG ETSI Standard [<cite><a class="bibref" data-link-type="biblio" href="#bib-saref4bldg" title="SAREF extension for building">SAREF4BLDG</a></cite>]</li>
              <li>Semantic Sensor Network Ontology (SSN/SOSA) [<cite><a class="bibref" data-link-type="biblio" href="#bib-vocab-ssn" title="Semantic Sensor Network Ontology">vocab-ssn</a></cite>]</li>
            </ul>

          </dd>
          <dt>Comments</dt>
          <dd>
            This use case has been driven by the research directions discussed in the following papers:
            <ul>
              <li>Zachila, K., K. Kotis, A. Dimara, S. Ladikou, and C. N. Anagnostopoulos, "Semantic modeling of
                trustworthy
                IoT
                entities in energy-efficient cultural spaces", 17th International Conference on Artificial Intelligence
                Applications and Innovations (AIAI 2021), Crete, Springer, 2021</li>
              <li>Dimara, A., C. N. Anagnostopoulos, K. Kotis, S. Krinidis, and T. Tzovaras, "BEMS in the Era of
                Internet of
                Energy: A Review", 17th International Conference on Artificial Intelligence Applications and Innovations
                (AIAI
                2021), Crete, Springer, 2021.</li>
            </ul>
            These directions focus on requirements to represent knowledge in a Smart Cultural space, to support semantic
            interoperability and trust of heterogeneous IoT entities (things, devices, people, processes, data).
            In respect to the WoT Thing Description (WoT TD), the need to represent trust of IoT entities is
            accentuated.
            An IoT-trust related knowledge representation (in OWL) is provided by Kotis et al. here (as an example):
            <a href="https://github.com/KotisK/IoTontos/blob/master/Ontologies/IoT/IoT-trust-onto-v06.owl">https://github.com/KotisK/IoTontos/blob/master/Ontologies/IoT/IoT-trust-onto-v06.owl</a>
            (or
            <a href="http://i-lab.aegean.gr/kotis/Ontologies/IoT/IoT-trust-onto-v06.owl">http://i-lab.aegean.gr/kotis/Ontologies/IoT/IoT-trust-onto-v06.owl</a>).
          </dd>
        </dl>
      </section>



    </section>

    <section id="smart-buildings"><div class="header-wrapper"><h3 id="x3-3-building-technologies"><bdi class="secno">3.3 </bdi>Building Technologies</h3><a class="self-link" href="#smart-buildings" aria-label="Permalink for Section 3.3"></a></div>
      
      <section id="UC-smart-building-1"><div class="header-wrapper"><h4 id="x3-3-1-smart-building"><bdi class="secno">3.3.1 </bdi>Smart Building</h4><a class="self-link" href="#UC-smart-building-1" aria-label="Permalink for Section 3.3.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>
            Sebastian Kaebisch
          </dd>
          
          <dt>Target Users</dt>
          <dd>

          </dd>
          <dt>Motivation and Description</dt>
          <dd>

            Buildings such as office buildings, hotels, airports, hospitals, train stations and sports stadiums
            typically consist of heterogeneous IoT systems such as lightings, elevators, security (e.g. door
            control), air-conditionings, fire warnings, heatings, pools, parking control, etc.

            Monitoring, controlling, and management of such a heterogeneous IoT landscape is quite challenging in
            terms of engineering and maintenance.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            All kind of sensors and actuators (e.g. HVAC).

          </dd>
          <dt>Expected Users</dt>
          <dd>

            <ul>
              <li>systems engineers</li>
              <li>system administrators</li>
              <li>third party user</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Heterogeneous data models from different IoT systems such as BACnet, KNX, and Modbus.

          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            WoT Thing Description and Thing Model, WoT Architecture, WoT Binding Templates (covering protocol
            specifica)

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            BACnet [<cite><a class="bibref" data-link-type="biblio" href="#bib-bacnet" title="BACnet">BACnet</a></cite>], KNX [<cite><a class="bibref" data-link-type="biblio" href="#bib-knx" title="KNX">KNX</a></cite>], OPC UA [<cite><a class="bibref" data-link-type="biblio" href="#bib-opc ua" title="OPC Unified Architecture">OPC UA</a></cite>], Modbus [<cite><a class="bibref" data-link-type="biblio" href="#bib-modbus" title="Modbus">Modbus</a></cite>]

          </dd>
          
        </dl>
      </section>

      <section id="UC-connected-building-energy-efficiency-1"><div class="header-wrapper"><h4 id="x3-3-2-connected-building-energy-efficiency"><bdi class="secno">3.3.2 </bdi>Connected Building Energy Efficiency</h4><a class="self-link" href="#UC-connected-building-energy-efficiency-1" aria-label="Permalink for Section 3.3.2"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Farshid Tavakolizadeh
            

          </dd>
          <dt>Target Users</dt>
          <dd>

            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-7">Device Owners</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-6">Device User</a></li>
              <li>directory service operator</li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            Construction and renovation companies often deal with the challenge of delivering target energy-efficient
            buildings given specific budget and time constraints. Energy efficiency, as one of the key factors for
            renovation investments, depends on the availability of various data sources to support the renovation
            design and planning. These include climate data and building material along with residential comfort and
            energy consumption profiles. The profiles are created using a combination of manual inputs and sensory
            data collected from residents.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            <ul>
              <li>Gateway (e.g. Single-board computer with a Z-Wave controller)</li>
            </ul>

            Z-wave Sensors:
            <ul>
              <li>Power Meter</li>
              <li>Gas Meter</li>
              <li>Smart Plug</li>
              <li>Heavy Duty Switch</li>
              <li>Door/Window Sensors</li>
              <li>CO2 Sensor</li>
              <li>Thermostat</li>
              <li>Multi-sensors (Motion, Temperature, Light, Humidity, Vibration, UV)</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>

            <ul>
              <li>Ambient conditions</li>
              <li>Occupancy model</li>
            </ul>

          </dd>
          
          <dt>Description</dt>
          <dd>

            Renovation of residential buildings to improve energy efficiency depend on a wide range of sensory
            information to understand the building conditions and consumption models. As part of the pre-renovation
            activities, the renovation companies deploy various sensors to collect relevant data over a period of
            time. Such sensors become part of a wireless sensor network (WSN) and expose data endpoint with the help
            of one or more gateway devices. Depending on the protocols, the endpoints require different interaction
            flows to securely access the current and historical measurements. The renovation applications need to
            discover the sensors, their endpoints and how to interact with them based on search criteria such as the
            physical location, mapping to the building model or measurement type.

          </dd>
          

          
          
          <dt>Privacy Considerations</dt>
          <dd>
            The TD may expose personal information about the building layout and residents.
          </dd>
          <dt>Gaps</dt>
          <dd>

            There is no standard vocabulary for embedding application-specific meta data inside the TD. It is possible
            to extend the TD context and add additional fields but with too much flexibility, every application may
            end up with a completely different structure, making such information more difficult to discover. In this
            use-case, the application specific data are:
            <ul>
              <li>the mapping between each thing and the space in the building model</li>
              <li>various identifiers for each thing (e.g. sensor serial number, z-wave ID, SenML name)</li>
              <li>indoor coordinates</li>
            </ul>

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            <ul>
              <li>OGC Sensor Things [<cite><a class="bibref" data-link-type="biblio" href="#bib-ogc sensor things" title="OGC Sensor Things API">OGC Sensor Things</a></cite>] model includes a
                <code>properties</code> property for each Thing which is a non-normative JSON Object for application-specific
                information (not to be confused with TD's <code>properties</code> which is a Map of instances of PropertyAffordance
              </li>
            </ul>

          </dd>
          
        </dl>
      </section>


      <section id="UC-automated-smart-building-management-1"><div class="header-wrapper"><h4 id="x3-3-3-automated-smart-building-management"><bdi class="secno">3.3.3 </bdi>Automated Smart Building Management</h4><a class="self-link" href="#UC-automated-smart-building-management-1" aria-label="Permalink for Section 3.3.3"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>
            Edison Chung, Hervé Pruvost, Georg Ferdinand Schneider
          </dd>
          <dt>Category</dt>
          <dd>

            Smart Building

          </dd>
          <dt>Target Users</dt>
          <dd>

            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-8">Device Owners</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-7">Device User</a></li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-14">Service Provider</a></li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-8">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-1">Gateway Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-1">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            <p>When operating smart buildings, aggregating and managing all data provided by heterogeneous devices in
              these buildings still require a lot of manual effort. Besides the hurdles of data acquisition that
              relies on multiple protocols, the acquired data generally lacks contextual information and metadata
              about its location and purpose. Usually, each service or application that consumes data from building
              things requires information about its content and its context like, e.g.:</p>
            <ul>
              <li>which thing produces the data (sensor, meter, actuator, other technical component...) in a building;
              </li>
              <li>which physical quantity or process is represented (temperature, energy supply, monitoring,
                actuation);</li>
              <li>which other building things are involved (e.g. sensor hosted by a duct or a space).</li>
            </ul>
            <p>Through the increased use of model-based data exchange over the whole life cycle of a building, often
              referred to as Building Information Modeling (BIM) (Sacks et al., 2018), a curated source for data
              describing the building
              itself is available including, amongst others, the topology of the building structured into e.g. sites,
              stores and spaces.</p>
            <p>Automatically tracking down data and their related things in a building would especially ease the
              configuration and operation of Building Automation and Control Systems (BACS) and Heating
              Ventilation and Air-Conditioning (HVAC) services during commissioning, operation, maintenance and
              retrofitting. To tackle these challenges, still, building experts make use of metadata and naming
              conventions which are manually implemented in Building Management Systems (BMS) databases to annotate
              data and things. An important property of a thing is its location within the topology of a building as
              well
              as where its related data are produced or used. For example, this applies to the temperature sensor of a
              space,
              the temperature setpoint of a zone, a mixing damper flap actuator of a HVAC component, etc. In addition,
              other
              attributes of things are of interest, such as cost or specific manufacturer data. One difficulty is
              especially the lack of a standardized way of creating, linking and sharing this information in an
              automated manner. On the contrary, manufacturers, service providers and users introduce their own
              metadata for their own purpose. As a solution, the Web of Things (WoT) Thing Description (TD) aims at
              providing normalized and syntactic interoperability between things.</p>
            <p>To support this effort, this use case is motivated by the need to enhance semantic interoperability
              between things in smart buildings and to provide them with contextual links to building information. This
              building information is usually obtained from a BIM model. The use case builds on Web of Data technologies
              and reuses schemas available from the Linked Building Data domain. It should serve as a use case template
              for many applications in an Internet of Building Things (IoBT).</p>

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            <ul>
              <li>Actuators</li>
              <li>Sensors</li>
              <li>Devices from the building context</li>
              <li>Devices from the HVAC system</li>
              <li>Smart devices</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>

            <ul>
              <li>Sensor ID</li>
              <li>Thing Descriptions</li>
              <li>Protocol integrations</li>
              <li>Sensor readings</li>
              <li>Building topology</li>
              <li>Semantic location</li>
              <li>Geolocation</li>
            </ul>

          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            <ul>
              <li>Web of Things (WoT) Thing Description (TD) [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-thing-description" title="Web of Things (WoT) Thing Description">wot-thing-description</a></cite>]</li>
              <li>Web of Things (WoT) Binding Templates [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-binding-templates" title="Web of Things (WoT) Binding Templates">wot-binding-templates</a></cite>]</li>
              <li>WoT Discovery - Geolocation (Proposal) [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-geolocation-proposal" title="WoT Discovery - Geolocation">wot-geolocation-proposal</a></cite>]</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>

            <p>The goal of this use case is to show the potential to automate workflows and address the heterogeneity of
              data as observed in the smart building domain. The examples show the potential benefits of combining WoT
              TD with contextual data obtained from BIM.</p>
            <p>The use cases is based on the <a href="https://github.com/TechnicalBuildingSystems/OpenSmartHomeData">Open
                Smart Home Dataset</a>, which introduces a BIM model for a residential flat combined with observations
              made by typical smart home sensors. We extend the dataset with Thing Descriptions of some of the items.
              The respective Thing Description of a temperature sensor in the kitchen of the considered flat is as
              follows:</p>
            <div class="example" id="TemperatureSensor">
        <div class="marker">
    <a class="self-link" href="#TemperatureSensor">Example<bdi> 1</bdi></a>
  </div> <pre class=""><code class="lang-json hljs" aria-busy="false">{
    "id": "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#TemperatureSensor",
    "@context": [
        "https://www.w3.org/2019/wot/td/v1",
        {
            "osh": "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#",
            "bot": "https://w3id.org/bot#",
            "sosa": "http://www.w3.org/ns/sosa/",
            "om": "http://www.ontology-of-units-of-measure.org/resource/om-2/",
            "ssns": "http://www.w3.org/ns/ssn/systems/",
            "brick": "https://brickschema.org/schema/Brick#",
            "schema": "http://schema.org"
        }
    ],
    "title": "TemperatureSensor",
    "description": "Kitchen Temperature Sensor",
    "@type": ["sosa:Sensor", "brick:Zone_Air_Temperature_Sensor", "bot:element"],
    "@reverse": {
        "bot:containsElement": {
            "@id": "osh:Kitchen"
        }
    },
    "securityDefinitions": {
        "basic_sc": {
            "scheme": "basic",
            "in": "header"
        }
    },
    "security": [
        "basic_sc"
    ],
    "properties": {
        "Temperature": {
            "type": "number",
            "unit": "om:degreeCelsius",
            "forms": [
                {
                    "href": "https://kitchen.example.com/temp",
                    "contentType": "application/json",
                    "op": "readproperty"
                }
            ],
            "readOnly": true,
            "writeOnly": false
        }
    },
    "sosa:observes": {
        "@id": "osh:Temperature",
        "@type": "sosa:ObservableProperty"
    },
    "ssns:hasSystemCapability": {
        "@id": "osh:SensorCapability",
        "@type": "ssns:SystemCapability",
        "ssns:hasSystemProperty": {
            "@type": ["ssns:MeasurementRange"],
            "schema:minValue": 0.0,
            "schema:maxValue": 40.0,
            "schema:unitCode": "om:degreeCelsius"
        }
    }
}
</code></pre>
      </div>
            <p>Where the contextual information on the measurement range of the sensor is specified using the <a href="http://www.w3.org/ns/ssn/systems/">SSNS</a> schema. The location information of the thing <a href="#TemperatureSensor">TemperatureSensor</a> is
              provided based on the <a href="https://w3id.org/bot">Building Topology Ontology (BOT)</a>, a minimal
              ontology developed by the <a href="https://www.w3.org/community/lbd/"><abbr title="World Wide Web Consortium">W3C</abbr> Linked Building Data Community
                Group (<abbr title="World Wide Web Consortium">W3C</abbr> LBD CG)</a> to describe the topology of buildings in the semantic web. Additionally, the
              thing description of the corresponding actuator is given below.</p>
            <p></p>
            <div class="example" id="TemperatureActuator">
        <div class="marker">
    <a class="self-link" href="#TemperatureActuator">Example<bdi> 2</bdi></a>
  </div> <pre class="">    <code class="lang-json hljs" aria-busy="false">{
    "id": "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#TemperatureActuator",
    "@context": [
        "https://www.w3.org/2019/wot/td/v1",
        {
            "osh": "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#",
            "bot": "https://w3id.org/bot#",
            "sosa": "http://www.w3.org/ns/sosa/",
            "ssn": "http://www.w3.org/ns/ssn/",
            "brick": "https://brickschema.org/schema/Brick#"
        }
    ],
    "title": "TemperatureActuator",
    "description": "Kitchen Temperature Actuator",
    "@type": ["sosa:Actuator", "brick:Zone_Air_Temperature_Setpoint", "bot:element"],
    "@reverse": {
        "bot:containsElement": {
            "@id": "osh:Kitchen"
        }
    },
    "securityDefinitions": {
        "basic_sc": {
            "scheme": "basic",
            "in": "header"
        }
    },
    "security": [
        "basic_sc"
    ],
    "actions": {
        "TemperatureSetpoint": {
            "forms": [
                {
                    "href": "https://kitchen.example.com/tempS"
                }
            ]
        }
    },
    "ssn:forProperty": {
        "@id": "osh:Temperature",
        "@type": "sosa:ActuatableProperty"
    }
}
</code></pre>
      </div>
          </dd><dt><em>Combining Topological Context and Thing Descriptions</em></dt>
          <p>The scenario considered is related to the replacement of a temperature sensor in a BACS. The topological
            information localizing the things, e.g. the <a href="#TemperatureSensor">temperature sensor</a> can
            be used to automatically commission the newly replaced sensor and link it to existing control
            algorithms. For this purpose, the identifiers of suitable sensors and actuators are needed and can be,
            for example, queried via <a href="https://www.w3.org/TR/sparql11-query/">SPARQL</a>. Here the query uses
            some additional classification of sensors from the Brick
              schema, v1.1 [<cite><a class="bibref" data-link-type="biblio" href="#bib-brick" title="Brick Schema">Brick</a></cite>].</p>

          <div class="example" id="sparql">
        <div class="marker">
    <a class="self-link" href="#sparql">Example<bdi> 3</bdi></a>
  </div> <pre class=""><code class="lang-sparql hljs" aria-busy="false">PREFIX bot: &lt;https://w3id.org/bot&gt;
PREFIX brick: &lt;https://brickschema.org/schema/Brick#&gt;
PREFIX osh: &lt;https://w3id.org/ibp/osh/OpenSmartHomeDataSet#&gt;
SELECT ?sensor ?actuator
WHERE{
  ?space a bot:Space .
  ?space bot:containsElement ?sensor .
  ?space bot:containsElement ?actuator .
  ?sensor a brick:Zone_Air_Temperature_Sensor .
  ?actuator a brick:Zone_Air_Temperature_Setpoint .
}
</code></pre>
      </div>
          <p>Similarly this data can be obtained via a REST API built upon the <a href="https://tools.ietf.org/html/rfc7231#section-4">HTTP</a> protocol. Below is an example endpoint
            applying <a href="https://roy.gbiv.com/pubs/dissertation/top.htm">REST</a> style for getting the same
            information for a specific space name:</p>
          <div class="example" id="RESTApiCall">
        <div class="marker">
    <a class="self-link" href="#RESTApiCall">Example<bdi> 4</bdi></a>
  </div> <pre class=""><code class="lang-json hljs" aria-busy="false">GET "https://server.example.com/api/locations?space=osh:Kitchen&amp;sensorType=brick:Zone_Air_Temperature_Sensor&amp;actuatorType=brick:Zone_Air_Temperature_Setpoint"
API response:
{
  "location": {
    "site": {
      "id": "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#Site1",
      "name": "Site1"
    },
    "building": {
      "id": "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#Building1",
      "name": "Building1"
    },
    "zone": null,
    "storey": {
      "id": "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#Level2",
      "name": "Level2"
    },
    "space": {
      "id": "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#Kitchen",
      "name": "Kitchen"
    },
  "sensors": [
    "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#TemperatureSensor"
  ],
  "actuators": [
    "https://w3id.org/ibp/osh/OpenSmartHomeDataSet#TemperatureActuator"
  ]
}
</code></pre>
      </div>
          <p>In this example query, the REST endpoint has been defined using the <a href="https://www.openapis.org/">OpenAPI specification</a>
            and is provided by a RESTful server. A data binding is needed between the server and the underlying backend
            storage, here the triple store
            that contains the involved ontologies (osh, bot, ssn, brick...). The data binding relies on similar SPARQL
            queries as the one shown above.
            As a result the endpoint can deliver information to a target application that consumes custom JSON rather
            than triples.
            Similar implmentation could be achieved using <a href="https://www.w3.org/community/graphql-rdf/">GraphQL</a>.
          </p>
          <dt><em>Automated Update of Fault Detection Rule based on Thing Description</em></dt>
          <p>Another related use case in smart buildings, which would greatly benefit from harmonised thing
            descriptions and attached location information is related to the detection of unexpected behavior,
            errors and faults. An example for such a detection of faults is the rule-based surveillance of sensor
            values. A generic rule applicable to sensors is that the observation values stay within the measurement
            range of the sensor. Again, in the case of maintenance as described above a sensor is replaced.</p>
          <p>Some agent configuring fault detection rules can obtain the measurement range from the sensor's TD
            (see above) to obtain the parameters to configure the mentioned rule. Again, a query or API call
            retrieving this information (schema:minValue/ schema:maxValue) can be used to update the upper and lower
            bound of the values provided by the <a href="#TemperatureSensor">sensor</a>.</p>

          
          <dt>Security Considerations</dt>
          <dd>

            <p>Security in smart buildings is of importance. In particular, access control needs to be properly secured.
              This applies also for data access which can be secured using existing security schemes (API Keys,
              OAuth2...).
              Moreover, from certain observations, e.g. electricity consumption, clues can be indirectly given such as
              presence in a
              home. Hence, security needs must be defined and properly addressed.</p>

          </dd>
          <dt>Privacy Considerations</dt>
          <dd>

            <p>Privacy considerations can be of a concern if observations of sensors can be matched to individuals.
              It is of the responsibility of building owners, managers and users to define their own privacy policies
              for their data and share necessary consents if necessary.
            </p>

          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>

            <p>Accessibility is a major concern in the buildings domain. Efforts exist in also providing accessibility
              data in a
              electronic format. The <abbr title="World Wide Web Consortium">W3C</abbr> LBD CG is in contact with the <a href="https://www.w3.org/community/lda/"><abbr title="World Wide Web Consortium">W3C</abbr>
                Linked Data for Accessibility Community Group</a>.
            </p>

          </dd>
          <dt>Internationalization (i18n) Considerations</dt>
          <dd>

            <p>Internationalization is a concern as the Buildings industry is a global industry. This is reflected in
              some efforts, e.g. BOT used in the examples above does provide multilanguage labels in up to 16
              different languages including english, french and chinese.</p>

          </dd>
          
          <dt>Existing Standards</dt>
          <dd>
            <ul>
              <li>SAREF4BLDG ETSI Standard [<cite><a class="bibref" data-link-type="biblio" href="#bib-saref4bldg" title="SAREF extension for building">SAREF4BLDG</a></cite>]</li>
              <li>Semantic Sensor Network Ontology (SSN/SOSA) [<cite><a class="bibref" data-link-type="biblio" href="#bib-vocab-ssn" title="Semantic Sensor Network Ontology">vocab-ssn</a></cite>]</li>
              <li><a href="https://standards.buildingsmart.org/IFC/DEV/IFC4/ADD2/OWL/index.html">Industry Foundation
                  Classes (IFC) an
                  ISO standard</a></li>
              <li><a href="https://w3id.org/bot">Building Topology Ontology (BOT)</a></li>
              <li>Brick Schema [<cite><a class="bibref" data-link-type="biblio" href="#bib-brick" title="Brick Schema">Brick</a></cite>]</li>
            </ul>

          </dd>
          <dd>References:
            <ul>
              <li>
                <a href="https://doi.org/10.1002/9781119287568">Sacks, R., Eastman, C., Lee, G., &amp; Teicholz, P. (2018).
                  BIM handbook: A guide to building information modeling for owners, designers, engineers, contractors,
                  and facility managers. John Wiley &amp; Sons.</a>
              </li>
            </ul>
          </dd>
        </dl>
      </section>

      <section id="UC-portable-building-applications-1"><div class="header-wrapper"><h4 id="x3-3-4-portable-building-applications"><bdi class="secno">3.3.4 </bdi>Portable Building Applications</h4><a class="self-link" href="#UC-portable-building-applications-1" aria-label="Permalink for Section 3.3.4"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Gabe Fierro

          </dd>
          <dt>Target Users</dt>
          <dd>

            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-9">Device Owners</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-8">Device User</a></li>
              <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-6">Cloud Provider</a></li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-15">Service Provider</a></li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-9">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-2">Gateway Manufacturer</a></li>
              <li>directory service operator</li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            The growing adoption of energy management systems, building automation and management systems and IoT
            devices is producing larger volumes and varieties of data.
            As a result, data-driven smart building applications are becoming increasingly common and practical to
            adopt.
            Examples of these applications include:
            <ul>
              <li>automated fault detection and diagnosis</li>
              <li>virtual metering (calculating the energy or power consumption of a subsystem that is not directly
                metered)</li>
              <li>building performance measurement and energy audits</li>
              <li>predictive occupancy, energy consumption models</li>
              <li>high-performance "sequences of operations" for various subsystems, such as HVAC</li>
            </ul>

            There is still significant cost in deploying these applications because of the effort required to customize
            and configure their operation for each individual building.
            While ontologies exist for describing sensors and the data they produce and for describing the spatial
            topology of buildings, the applications above require modeling the context of data sources that are embedded
            <strong>within</strong> building subsystems.
            Therefore, there is a need to model the topology and composition of building subsystems, including HVAC
            systems, lighting systems, electrical systems, domestic water systems and hot and chilled water systems.
            This must be done in a way that adequately contextualizes data but also provides necessary metadata to
            determine which applications or which analyses are appropriate.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            <ul>
              <li>Actuators</li>
              <li>Sensors</li>
              <li>Devices from the building context</li>
              <li>Devices from the HVAC system</li>
              <li>Smart devices</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>

            <ul>
              <li>thing descriptions</li>
              <li>building system topology and composition</li>
              <li>building topology and composition</li>
            </ul>

          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>

            <ul>
              <li>Web of Things (WoT) Thing Description (TD) [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-thing-description" title="Web of Things (WoT) Thing Description">wot-thing-description</a></cite>]
              </li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>
            <p>
              In these settings, devices are usually not commercial off-the-shelf IoT devices, but rather "packaged
              units"
              and other "lower level" devices that perform physical tasks on behalf of a larger system: pumps, fans,
              variable frequency drives, variable air volume boxes and chillers are all examples.
              Such devices are connected to one another using wires, pipes, ducts and other mechanisms.
              Sensors, actuators and other data sources and sinks are associated with the devices in these subsystems.
              Through some digital control system, they relay telemetry on the current behavior, status and performance
              of
              devices and properties of the substances and media touched by the building subsystem.
            </p>
            <p>
              It is important for descriptions of these systems to be built on standardized, well-known names for
              equipment and other devices in building subsystems. Reliance on generic terminology is not sufficient to
              distinguish the different kinds of systems and different kinds of equipment in a broadly consistent and
              interpretable manner. Research and practice shows that a common terminology must be established in order
              to
              reduce the costs associated with developing and deploying data-driven applications that touch the
              internals
              of cyber-physical systems.
            </p>
            <p>
              To support this use case, WoT descriptions should describe the networked devices present in building
              subsystems and their data capabilities.
              These capabilities should be related to properties of the substances or media that a device is operating
              on.
              For example, a smart thermostat's API may present a "mode" as a read-only property.
              "Mode" commonly refers to what the thermostat is "calling for", e.g. cooling, heating, fan; this is
              commonly
              captured as a numerical value.
              The mode is read by HVAC equipment, such as a rooftop-unit, which then enacts the desired conditioning.
              The WoT description of the mode property should permit the determination of what properties of <em>other
                devices and entities in the building</em> may be affected by the value of the mode property.
              In this example, the mode property representation should indicate that the mode property indirectly
              affects
              the temperature of air in the rooms that are connected to the equipment controlled by the thermostat.
            </p>
            <p><strong>Example: Rogue Zone Detection</strong></p>
            <p>
              "Rogue zones" are regions of the building that drive demand by calling for heating or cooling
              significantly
              more than other zones. One simple way to detect rogue zones is to observe zones (which may consist of
              multiple rooms) which are consistently above or below their setpoint by more than some delta. The
              following
              SPARQL query uses Brick to identify the air temperature setpoint and sensors associated with terminal
              units,
              and to identify the zones fed by those terminal units.
            </p>
            <div class="example" id="example-rogue-zone-detection-sparql">
        <div class="marker">
    <a class="self-link" href="#example-rogue-zone-detection-sparql">Example<bdi> 5</bdi></a><span class="example-title">: Rogue Zone Detection (SPARQL)</span>
  </div> <pre aria-busy="false"><code class="hljs css">PREFIX brick: &lt;http://brickschema.org/schema/Brick#&gt;
SELECT ?term ?zone ?sat ?sp WHERE {
?term <span class="hljs-selector-tag">a</span> brick:Terminal_Unit .
?zone a brick:HVAC_Zone .
?sat a brick:Supply_Air_Temperature_Sensor .
?sp a brick:Supply_Air_Temperature_Setpoint .

?term brick:feeds ?zone .
?term brick:hasPoint ?sat, ?sp .
}</code></pre>
      </div>

            <p><strong>Example: Measuring Temperature Before and After a Cooling Coil</strong></p>
            <p>
              A common fault detection and diagnosis operation is to detect broken or underperforming cooling coils.
              These
              are hollow loops through which chilled water flows; the loops are placed into an air stream in order to
              cool
              the air. The flow of chilled water through the coil is controlled by a valve. In order to tell if the coil
              is broken or underperforming, the temperature of the air <em>before</em> and <em>after</em> the coil is
              measured. If the
              temperature after the coil is not appreciably lower than the temperature before the coil <em>while the
                valve is
                open</em>, then there may be a fault on the coil.
            </p>
            <div class="example" id="example-measuring-temperature-before-and-after-a-cooling-coil-sparql">
        <div class="marker">
    <a class="self-link" href="#example-measuring-temperature-before-and-after-a-cooling-coil-sparql">Example<bdi> 6</bdi></a><span class="example-title">: Measuring Temperature Before and After a Cooling Coil (SPARQL)</span>
  </div> <pre aria-busy="false"><code class="hljs css">PREFIX brick: &lt;http://brickschema.org/schema/Brick#&gt;
SELECT ?ahu ?mat ?sat ?pos ?room WHERE {
?ahu <span class="hljs-selector-tag">a</span> brick:AHU .
?sat a brick:Supply_Air_Temperature_Sensor .
?mat a brick:Mixed_Air_Temperature_Sensor .
?ccv a brick:Cooling_Valve .
?pos a brick:Position_Sensor .
?room a brick:Room .

?ahu brick:hasPoint ?mat, ?sat .
?ahu brick:hasPart ?ccv .
?ccv brick:hasPoint ?pos .
?ahu brick:feeds+/brick:hasPart? ?room .
}</code></pre>
      </div>

          </dd>
          <dt>Security Considerations</dt>
          <dd>

            It is important to protect access to this representation of the building and its devices; access to the
            model can reveal the uses of space within the building and what equipment is required to make those spaces
            comfortable and safe. Proper threat models, modes of access and effective security must all be developed.

          </dd>
          <dt>Privacy Considerations</dt>
          <dd>

            With the detail available in the model, it is possible to associate data sources with the spaces in the
            building (indeed, this is one of the purposes of the use case) which may then be linked to individuals or
            organizations within the building. It is of the responsibility of building owners, managers and users to
            define their own privacy policies for their data and share necessary consents if necessary.

          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>

            Accessibility is a major concern in the buildings domain. Efforts exist in also providing accessibility data
            in a electronic format. The <abbr title="World Wide Web Consortium">W3C</abbr> LBD CG is in contact with the <a href="https://www.w3.org/community/lda/"><abbr title="World Wide Web Consortium">W3C</abbr> Linked Data for Accessibility Community Group</a>.

          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>

            Internationalization is a concern as the building industry is a global industry. Not only are translations
            of the concepts and properties to other languages necessary, but the ontology should give consideration to
            alternative categories and organizations. For example, in hot and humid climates, the term HVAC (*Heating*,
            Ventilation and Air Condition) is often abandoned in favor of ACMV (Air-Conditioning and Mechanical
            Ventilation) due to the lack of a need for heating.

          </dd>
          <dt>Requirements</dt>
          <dd>

            <ul>
              <li>Integration with Brick Ontology [<cite><a class="bibref" data-link-type="biblio" href="#bib-brick" title="Brick Schema">Brick</a></cite>]: Brick has not yet decided on how the values coming out of devices,
                sensors, etc. should be represented. WoT has the potential to fulfill that role.</li>
            </ul>

          </dd>
          <dt>Gaps</dt>
          <dd>
            <p>
              A very useful feature would be semantic descriptions of standard enumerations of device statuses, alarms
              and
              other multi-valued properties.
              One example is the numerical encoding of the thermostat mode above (e.g. "0 means off", "1 means 1-stage
              heat", etc.).
            </p>
            <p>
              Many of the semantics are standard across manufacturers and models because they describe well-known and
              industry standard properties that must be accessible by users, but are encoded in different ways.
              The ability to refer to standardized error codes, device status, and so on would be a tremendous advance
              towards enabling vendor-agnostic treatment of data.
            </p>
          </dd>
          <dt>Existing standards</dt>
          <dd>

            <ul>
              <li>Brick Schema [<cite><a class="bibref" data-link-type="biblio" href="#bib-brick" title="Brick Schema">Brick</a></cite>]</li>
              <li>Building Topology Ontology (BOT) [<cite><a class="bibref" data-link-type="biblio" href="#bib-bot" title="Building Topology Ontology">BOT</a></cite>]</li>
              <li>Semantic Sensor Network Ontology (SSN/SOSA) [<cite><a class="bibref" data-link-type="biblio" href="#bib-vocab-ssn" title="Semantic Sensor Network Ontology">vocab-ssn</a></cite>]</li>
              <li>SAREF4BLDG ETSI Standard [<cite><a class="bibref" data-link-type="biblio" href="#bib-saref4bldg" title="SAREF extension for building">SAREF4BLDG</a></cite>]</li>
              <li>SAREF4SYST ETSI Standard [<cite><a class="bibref" data-link-type="biblio" href="#bib-saref4syst" title="SAREF4SYST: an extension of SAREF for typology of systems and their inter-connections">SAREF4SYST</a></cite>]</li>
              <li>Web of Things (WoT) Thing Description (TD) [<cite><a class="bibref" data-link-type="biblio" href="#bib-wot-thing-description" title="Web of Things (WoT) Thing Description">wot-thing-description</a></cite>]</li>
            </ul>

          </dd>
          
        </dl>
      </section>
    </section>

    <section id="manufacturing"><div class="header-wrapper"><h3 id="x3-4-manufacturing"><bdi class="secno">3.4 </bdi>Manufacturing</h3><a class="self-link" href="#manufacturing" aria-label="Permalink for Section 3.4"></a></div>
      
      <section id="UC-production-monitoring-1"><div class="header-wrapper"><h4 id="x3-4-1-production-monitoring"><bdi class="secno">3.4.1 </bdi>Production Monitoring</h4><a class="self-link" href="#UC-production-monitoring-1" aria-label="Permalink for Section 3.4.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>
            Michael Lagally
          </dd>
          <dt>Target Users</dt>
          <dd>

            <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-10">Device Owners</a>, <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-7">Cloud Provider</a>.

          </dd>
          <dt>Motivation</dt>
          <dd>
            <p>
              Production lines for industrial manufacturing consist of multiple machines, where each machine
              incorporates sensors for various values.
              A failure of a single machine can cause defective products or a stop of the entire production.
            </p>
            <p>
              Big data analysis enables to identify behavioral patterns across multiple production lines of the entire
              production plant and across multiple plants.
            </p>
            <p>
              The results of this analysis can be used for optimizing consumption of raw materials, checking the status
              of production lines and plants and predicting and preventing fault conditions.
            </p>

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Various sensors, e.g. temperature, light, humidity, vibration, noise, air quality.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Discrete sensor values, such as temperature, light, humidity, vibration, noise, air quality readings.
            The data can be delivered periodically or on demand.

          </dd>
          <dt>Dependencies</dt>
          <dd>

            Thing Description: groups of devices, aggregation / composition mechanism, thing models
            Discovery/Onboarding: Onboarding of groups of devices

          </dd>
          <dt>Description</dt>
          <dd>
            <p>
              A company owns multiple factories which contain multiple production lines.
              Examples are production lines and environment sensors.
              These devices collect data from multiple sensors and transmit this information to the cloud. Sensor data
              is stored in the cloud, can be visualized and analyzed using machine learning / AI.
            </p>
            <p>
              The cloud service allows to manage single and groups of devices.
              Combining the data streams from multiple devices allows to get an easy overview of the state of all
              connected devices in the user's realm.
            </p>
            <p>
              In many cases there are groups of devices of the same kind, so the aggregation of data across devices can
              serve to identify anomalies or to predict impending outages.
            </p>
            <p>
              The cloud service allows to manage single and groups of devices and can help to identify abnormal
              conditions.
              For this purpose a set of rules can be defined by the user, which raises alerts towards the user or
              triggers actions on devices based on these rules.
            </p>
            <p>
              This enables the early detection of pending problems and reduces the risk of machine outages, quality
              problems or threats to the environment or life of humans. It increases production efficiency,
              improves production logistics (such as raw material delivery and production output).
            </p>
          </dd>
          
          <dt>Comments</dt>
          <dd>
            See also Digital Twin use case.
          </dd>
        </dl>
      </section>
      <section id="UC-cross-protocol-interaction-in-industry-4.0-scenarios-1"><div class="header-wrapper"><h4 id="x3-4-2-cross-protocol-interaction-in-industry-4-0-scenarios"><bdi class="secno">3.4.2 </bdi>Cross-protocol Interaction in Industry 4.0 Scenarios</h4><a class="self-link" href="#UC-cross-protocol-interaction-in-industry-4.0-scenarios-1" aria-label="Permalink for Section 3.4.2"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>
            Sebastian Kaebisch
          </dd>
          <dt>Reviewer(s)</dt>
          <dd>
            Michael McCool, Ryuichi Matsukura, Kunihiko Toumura, Michael Legally, Michael Koster
          </dd>
          <dt>Category</dt>
          <dd>
            vertical
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-11">Device Owners</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-9">Device User</a></li>
              <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-8">Cloud Provider</a></li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-16">Service Provider</a></li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-10">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-3">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-2">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Industry 4.0 is associated with next generation of manufacturing to increase efficiency, flexibility, and
            productivity. This also includes the broader interplay between the OT and IT domain as well as the further
            integration of services from different application areas. Technology domains such as from smart infrastructure
            and web forecasting services like traffic and weather forecasts are expected to be integrated directly into
            the manufacturing process as well as in the product lifecycle. To realize cross-domain applications for the
            Industrie 4.0 context, a frequent exchange with suppliers or local infrastructure providers (e.g., power
            supplier) is needed and it is necessary to interact with manufacturing systems that usally offers an OPC UA [<cite><a class="bibref" data-link-type="biblio" href="#bib-opc ua" title="OPC Unified Architecture">OPC UA</a></cite>]
            interface. WoT can act as a common and standardized application layer and can be used to support Industry 4.0
            use cases. In this context, well-formed bindings for most established industry standards such as OPC UA should
            be supported.
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            Typically automation devices or server endpoints that are able to host an OPC UA server (controller, gateways
            / edges, etc).
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            There are some experiences of OPC UA bindings in previous WoT PlugFests and there is a sample binding
            implementation in <a href="https://github.com/eclipse/thingweb.node-wot/">node-wot</a>. However, there needs
            to be a formal definition to map the interaction affordances of a TD to OPC UA. In that context an official
            OPC UA Binding Note document should be developed that can be used as official reference to design Thing
            Descriptions for OPC UA use cases.
          </dd>
          <dt>Description</dt>
          <dd>
            A bottling line consists of a filling module (switchable between 2 fillers and 4 fillers), a capping module, a
            labeling module, and a transport system. The production line is provided via an OPC UA endpoint for control
            and monitoring purposes.
            <div class="resize"><img src="images/industry-4.0.png" alt="Bottling Line Example"></div>
            In the context of enhancing productivity and sustainability, the goal is to operate the bottling line in such
            a way that production is further increased when sufficient or surplus renewable energy is available.
            The backend system checks periodically a Smart Grid endpoint (via HTTP) how the current power production is
            and how much renewable energy is produced.
            Based on the bottling line's current power consumption, which is measured via Modbus, the backend system
            decides to increase productivity when surplus renewable energy is available.
            In doing so, the backend system interacts via OPC UA to release the 4 fillers of the filling module and
            increases the speed of the transport system.
            If the backend system detects that less renewable energy is being produced, it will initiate standard
            production and reduce the transport speed and return the 2 fillers of the filling module.
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            OPC UA has different security modes (sign and/or encrypted, policies, and authentication). Those should be
            addressed and described in Thing Descriptions with a standardized vocabulary definition. Additional security
            considerations may apply if a web bridge is created using WoT servients. OT networks are often isolated and
            OPC UA may have special requirements for distribution of key materials and credentials.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            OPC UA comes with different approaches to protect data (also see Security Considerations above).
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            none
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            OPU-UA data model contains some places to provide human-readable text (e.g., browse name). This should be also
            reflected in the Thing Description with the correct language context.
          </dd>
          <dt>Requirements</dt>
          <dd>
            An OPC UA binding for Web of Things needs an own set of OPC UA specific vocabulary definitions which should be
            developed together with the experts from the OPC Foundation. Also see the <a href="https://opcfoundation.org/news/opc-foundation-news/w3c-and-opcf-to-integrate-opc-ua-into-the-web-of-things/">liaison</a>.
          </dd>
        </dl>
      </section>
    </section>

    <section id="retail"><div class="header-wrapper"><h3 id="x3-5-retail"><bdi class="secno">3.5 </bdi>Retail</h3><a class="self-link" href="#retail" aria-label="Permalink for Section 3.5"></a></div>
      
      <section id="UC-retail-operations-1"><div class="header-wrapper"><h4 id="x3-5-1-retail-operations"><bdi class="secno">3.5.1 </bdi>Retail Operations</h4><a class="self-link" href="#UC-retail-operations-1" aria-label="Permalink for Section 3.5.1"></a></div> 
        
        <dl>

        <dt>Submitter(s)</dt>
        <dd>

          David Ezell, Michael Lagally, Michael McCool

        </dd>
        <dt>Target Users</dt>
        <dd>

          Retailers, customers, suppliers.

        </dd>
        <dt>Motivation</dt>
        <dd>
          <p>
            Integrating and interconnecting multiple devices into the common retail workflow
            (i.e., transaction log) drastically improves retail business operations at multiple levels.
            It brings operational visibility,including consumer behavior and environmental information,
            that was not previously possible or viable in a meaningful way.
          </p>
          <p>
            It drastically speeds up the process of root cause analysis of operational issues and
            simplifies the work of retailers.
          </p>
        </dd>
        <dt>Expected Devices</dt>
        <dd>

          Connected sensors, such as people counters, presence sensors, air quality, room occupancy, door sensors.
          Cloud services. Video analytics edge services.

        </dd>
        <dt>Expected Data</dt>
        <dd>

          Inventory data, supply chain status information, discrete sensor data or data streams.

        </dd>
        
        <dt>Description</dt>
        <dd>

          Falling costs of sensors, communications, and handling of very large volumes of data combined with cloud
          computing enable retail business operations with increased operational efficiency, better customer
          service,
          and even increased revenue growth and return on investment.

          Accurate forecasts allow retailers to coordinate demand-driven outcomes that deliver connected customer
          interactions.
          They drive optimal strategies in planning, increasing inventory productivity in retail supply chains,
          decreasing operational costs and driving customer satisfaction from engagement, to sale, to fulfilment.

          Understanding of store activity juxtaposed with traditional information streams can boost worker and
          consumer safety,
          comply better with work safety regulations, enhance system and site security, and improve worker
          efficiency
          by providing real-time visibility into worker status, location, and work environment.

        </dd>
        <dt>Variants</dt>
        <dd>

          <ul>
            <li>Use edge computing, in particular video analytics, in combination with IoT devices to deliver an
              enhanced
              customer experience, better manage inventory, or otherwise improve the store workflow.</li>

        </ul></dd>
        <dt>Security Considerations</dt>
        <dd>

          <ul>
            <li>In retail, replay attacks can cause monetary loss, customers may be incorrectly charged or
              over-charged.</li>
            <li>To avoid replay attacks, "Things" should implement a sequence number for each message and digital
              signature.</li>
            <li>Servers ("Things" or "Cloud") should verify the signature and disallow for duplicated messages.</li>
            <li>For "Things" relying on electronic payments, "Things" must comply with PCI-DSS requirements.</li>
            <li>"Things" must never store credit card information.</li>
            <li>Customer satisfaction and trust depends on availability, so attacks such as Denial-of-Service (DoS)
              need to be prevented or mitigated.</li>
            <li>To prevent DoS, implement "Things" with early DoS detection.</li>
            <li>Have an automated DoS system that will notify the controlling unit of the problem.</li>
            <li>Implement IP white list, that could be part of the DoS early detection system.</li>
            <li>Make sure your network perimeter is defended with up to date firewall software.</li>
          </ul>

        </dd>
        <dt>Privacy Considerations</dt>
        <dd>

          As a general rule, personal consumer information should not be stored.
          That is especially true in the retail industry where a security breach could cause financial, reputation,
          and brand damage.
          If personal or information that can identify a consumer is to be stored,
          it should be to conduct business and with the explicit acknowledgment of the consumer.
          WoT vendors and integrators should always have a privacy policy and make it easily available.
          By default, devices should adopt an opt-out policy.
          That means, unless the consumer explicitly allowed for the data capture and storage, avoid doing it.

        </dd>
        

    </dl></section>
      <section id="UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1"><div class="header-wrapper"><h4 id="x3-5-2-retail-all-stop-button-outdoor-emergency-stop-plunger"><bdi class="secno">3.5.2 </bdi>Retail All Stop Button (Outdoor Emergency Stop Plunger)</h4><a class="self-link" href="#UC-retail-all-stop-button-outdoor-emergency-stop-plunger-1" aria-label="Permalink for Section 3.5.2"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Outdoor Facility Equipment
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-12">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-11">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-4">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-3">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            There is a lack of visibility to equipment problems for maintenance, as well as safety issues from
            inoperable E-Stop systems. There is also a lack of visibility or knowledge of a tripped/faulty E-Stop that
            can disrupt fuel operations altogether.

            Expected outcomes:
            <ul>
              <li>Proactively respond to device issues.</li>
              <li>Respond to safety-related issues quickly and efficiently.</li>
              <li>Return to normal fuel operations when equipment has been triggered accidentally or due to faulty
                equipment.</li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>All stop button device for the fueling system.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The button is operational and online;</li>
              <li>An alert for when the button is used or reset to normal operations; and</li>
              <li>The date and time it was used or reset to normal operations. </li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers want to ensure that the fuel emergency All Stop Button for shutting off all the pumps at the
            island is operational.
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None. The required data is not PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
      <section id="UC-retail-indoor-door-sensor-1"><div class="header-wrapper"><h4 id="x3-5-3-retail-indoor-door-sensor"><bdi class="secno">3.5.3 </bdi>Retail Indoor Door Sensor</h4><a class="self-link" href="#UC-retail-indoor-door-sensor-1" aria-label="Permalink for Section 3.5.3"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Indoor Facilities and Power Equipment
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-13">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-12">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-5">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-4">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            Not being able to access door sensors can drive security and possible theft scenarios. Open refrigeration
            and freezer access doors can lead to spoilage of product and food safety concerns. Door sensors can also
            create false temperature alarms or cause additional wear on equipment that is maintaining temperatures.
            Store personnel are responsible to manage access points, which can be difficult and impacts their ability to
            service customers and manage labor. Furthermore, corporate loss prevention, security, and store support
            teams are not able to address concerns in real-time.

            Expected outcomes:
            <ul>
              <li>The status of delivery or rear entry doors can be used to send notifications if left open or
                unattended for long periods of time.</li>
              <li>The status of office and restricted area doors is also important for securing cash and reporting data,
                as well as access to electrical or network equipment rooms.</li>
              <li>Refrigerated areas also need to be monitored to protect inventory from spoilage or theft.</li>
              <li>Restroom doors can be monitored for usage, maintenance, or ensuring customer health issues do not
                emerge while using the facilities.</li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>Door sensor device.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The status of facility door sensors (i.e., online, offline, open, closed) coupled with date and time
                details for pairing with camera/video data for monitoring access;</li>
              <li>The status of office and restroom door sensors with details from time elapsed and from last change in
                status;</li>
              <li>The status of refrigeration door sensors (i.e., online, offline) paired with temperature sensors,
                which allows for temperature threshold limits to be evaluated with door sensors to explain temperature
                deviations, send notifications, and manage quality and safety;</li>
              <li>The door sensor usage for date/time and duration for monitoring and evaluating deliveries or equipment
                problems; and</li>
              <li>Tracking for the number of times refrigeration doors are opened/closed within specific time periods to
                allow merchandising and marketing personnel to understand usage and traffic flow, inventory management,
                promotional program impacts, or product placement details.</li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers need to ensure that the door sensors are functional, as these can be vital to employee and
            customer safety, as well as operations. Having the ability to accurately identify the number of associates
            and customers within the facility, as well as the status of access points, is important for physical
            security, facilities, and loss prevention groups to ensure health and safety compliance.

            There are multiple door sensors within the store:
            <ul>
              <li>Door sensor for beverage vaults</li>
              <li>Door sensor for refrigeration </li>
              <li>Door sensor for bathrooms and bathroom Stalls</li>
              <li>Door sensors for delivery or rear entry to the facility</li>
              <li>Door sensor for back office/management or storage rooms</li>
            </ul>
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None. The required data is not PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
      <section id="UC-retail-indoor-and-outdoor-freezers"><div class="header-wrapper"><h4 id="x3-5-4-retail-indoor-and-outdoor-freezers"><bdi class="secno">3.5.4 </bdi>Retail Indoor and Outdoor Freezers</h4><a class="self-link" href="#UC-retail-indoor-and-outdoor-freezers" aria-label="Permalink for Section 3.5.4"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Indoor Food Preparation and Food Service Devices
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-14">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-13">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-6">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-5">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            Not being able to monitor freezer equipment (temperatures, condenser energy, etc.) places the burden on
            store personnel. Freezer issues can lead to spoilage of product and food safety concerns.

            Expected outcomes:
            <ul>
              <li>The status of freezer issues can be used to send notifications to both store and service personnel.
              </li>
              <li>Equipment patterns can identify issues before they occur, which avoids large losses due to spoilage
                and/or equipment failure that then impacts ongoing sales. </li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>Indoor or Outdoor Freezer devices.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The status of the freezer (i.e., on, off, defrost, or maintenance mode);</li>
              <li>The current operating temperature of the freezer;</li>
              <li>The door status (i.e., open or closed), including the date and time of activity for evaluating
                excessive usage and temperature impacts; and</li>
              <li>A log of times that the temperature varied above or below desired set ranges.</li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers need to ensure that the freezers are online and operating within normal parameters. Monitoring
            freezers supports health and safety requirements and avoids wasted product, whether it’s food or other
            consumable items (e.g., ice).

            Outdoor Food Preparation and Food Service Devices
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None. The required data is not PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
      <section id="UC-retail-kitchen-refrigerator-1"><div class="header-wrapper"><h4 id="x3-5-5-retail-kitchen-refrigerator"><bdi class="secno">3.5.5 </bdi>Retail Kitchen Refrigerator</h4><a class="self-link" href="#UC-retail-kitchen-refrigerator-1" aria-label="Permalink for Section 3.5.5"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Indoor Food Preparation and Food Service Devices
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-15">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-14">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-7">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-6">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            Not being able to monitor kitchen equipment (temperatures, condenser energy, etc.) places the burden on
            store personnel. Refrigeration issues can lead to spoilage of product and food safety concerns, as well as
            energy usage issues and other kitchen efficiency problems.

            Expected outcomes:
            <ul>
              <li>The status of refrigeration can be used to send notifications to both store and service personnel.
              </li>
              <li>Equipment patterns can identify issues before they occur, which avoids large losses due to spoilage
                and/or equipment failure that then impacts ongoing sales.</li>
              <li>Retailers can also use the data to better understand operational details in order to improve
                efficiencies during specific time periods or change standards related to kitchen work area designs.</li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>Kitchen Refrigerator device.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The status of the refrigerator (i.e., on, off, offline);</li>
              <li>The current operating temperature of the refrigerator;</li>
              <li>Door status (i.e., open or closed), including the date and time of activity for evaluating excessive
                usage and temperature impacts;</li>
              <li>Times that the temperature varied above or below a desired set range;</li>
              <li>The history of high and low temperature alerts; and</li>
              <li>Internal light status.</li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers need to ensure that the kitchen refrigerator is online and operating within normal parameters.
            Temperature monitoring and control will ensure food is safe for sale and consumption, while also supporting
            temperature recordkeeping requirements.
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None. The required data is not PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
      <section id="UC-retail-restroom-devices-1"><div class="header-wrapper"><h4 id="x3-5-6-retail-restroom-devices"><bdi class="secno">3.5.6 </bdi>Retail Restroom Devices</h4><a class="self-link" href="#UC-retail-restroom-devices-1" aria-label="Permalink for Section 3.5.6"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Indoor Facilities and Power Equipment
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-16">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-15">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-8">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-7">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            There is a lack of visibility to the equipment for maintenance and issue identification. Restroom issues can
            go unnoticed and unreported for periods of time. Restrooms often are a priority for customers, so restroom
            issues can directly drive away business and customer traffic inside the store. Restroom service also creates
            inefficiencies in the store’s labor.

            Expected outcomes:
            <ul>
              <li>Quickly and proactively identifying issues from misuse or faulty devices can avoid health, safety and
                customer facing problems.</li>
              <li>Timely identification allows onsite personnel to respond, reduce problems, and avoid additional
                impacts to the store’s operations.</li>
              <li>Proactive efforts at the store level can also improve labor efficiencies by scheduling activities as
                needed or prior to busy periods.</li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>Restroom devices.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The toilets are operational and serviceable;</li>
              <li>The status of motion sensors and their frequency of engagement, which is used for preventative
                maintenance or to address issues (e.g., constant running water);</li>
              <li>The status of sensors for water consumption, such as flush/actuator monitoring;</li>
              <li>The status of bowl water levels and +/- level tolerance for preventative maintenance;</li>
              <li>Paper levels and the status of auto paper dispensers;</li>
              <li>Hand dryer status (i.e., powered on, offline, online); and</li>
              <li>Sink water pressure level and status.</li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers need to ensure that restroom toilets are operational and not experiencing malfunctions.
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None. The required data is not PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
      <section id="UC-retail-lighting-control-1"><div class="header-wrapper"><h4 id="x3-5-7-retail-lighting-control"><bdi class="secno">3.5.7 </bdi>Retail Lighting Control</h4><a class="self-link" href="#UC-retail-lighting-control-1" aria-label="Permalink for Section 3.5.7"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Indoor Facilities and Power Equipment
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-17">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-16">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-9">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-8">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            There is a lack of visibility to the equipment for maintenance and issue identification. Lighting issues
            impact aesthetics and the customer experience. It also presents safety concerns for store personnel and
            customers. Overuse of lighting, such as in storage rooms, can increase costs unnecessarily. Energy
            consumption can impact store efficiencies and costs.

            Expected outcomes:
            <ul>
              <li>Service</li>
              <li>Tracking energy consumption</li>
              <li>Improving interior aesthetics</li>
              <li>Ensuring lighting is appropriate for time of day and areas within the store (both customer and store
                associate related) for safety reasons</li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>Lighting Control device.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The status of lights (i.e., on, off, offline);</li>
              <li>The status of light ballasts, where applicable; and</li>
              <li>The date/time information of status changes (e.g., on/off) and the location within the store.</li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers need to ensure that the indoor lights are operational. Controlling and monitoring lighting is
            applicable to restrooms, storage spaces, refrigeration units, offices, and equipment and electrical rooms.
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None. The required data is not PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
      <section id="UC-retail-outdoor-canopy-lighting-control-1"><div class="header-wrapper"><h4 id="x3-5-8-retail-outdoor-canopy-lighting-control"><bdi class="secno">3.5.8 </bdi>Retail Outdoor Canopy Lighting Control</h4><a class="self-link" href="#UC-retail-outdoor-canopy-lighting-control-1" aria-label="Permalink for Section 3.5.8"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Outdoor Facility Equipment
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-18">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-17">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-10">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-9">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            There is a lack of visibility for the store operator into equipment problems for maintenance and energy
            management. There are safety concerns for the forecourt and store entry locations. There are customer
            experience and brand identity issues stemming from safety and aesthetic issues.

            Expected outcomes:
            <ul>
              <li>Proactively respond to device issues.</li>
              <li>Provide better insight into energy consumption.</li>
              <li>Keep locations well-lit and safe.</li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>Lighting monitor.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The status of lights (e.g., on, off, or offline);</li>
              <li>The status of light ballasts, where applicable; and</li>
              <li>The date/time information of status changes (e.g., on/off) and location within the store.</li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers want to ensure that all the canopy lights are operational and turned on at the correct times of
            day. Lighting is important for aesthetics but also for customer and facility safety requirements. Being able
            to identify when lighting is out of order, insufficient, or enabled at the wrong times can have energy and
            safety implications, as well as affect the overall customer experience of the brand.

          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None. The required data is not PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
      <section id="UC-retail-fountain-drink-ice-machine-1"><div class="header-wrapper"><h4 id="x3-5-9-retail-fountain-drink-ice-machine"><bdi class="secno">3.5.9 </bdi>Retail Fountain Drink Ice Machine</h4><a class="self-link" href="#UC-retail-fountain-drink-ice-machine-1" aria-label="Permalink for Section 3.5.9"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Indoor Food Preparation and Food Service Devices
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-19">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-18">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-11">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-10">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            There is a lack of visibility to the fountain drink devices for maintenance and issue identification.
            Because the equipment is self serve and customer facing, problems will directly impact the customer
            experience. Additionally, a lack of visibility can create issues for inventory management and sales when
            product is out or unavailable.

            Expected outcomes:
            <ul>
              <li>Proactively monitor fountain drink equipment and schedule maintenance.</li>
              <li>Inform store personnel of issues so they can take necessary measures for labor effectiveness and
                customer service.</li>
              <li>Utilize equipment patterns to proactively schedule maintenance to occur at appropriate times for the
                operations of the store. </li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>Fountain Drink Ice Machine device.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The status of the ice machine (i.e., powered on, off, offline);</li>
              <li>The machine’s ice temperature and ice quality settings;</li>
              <li>The status of the water supply;</li>
              <li>The status of the water filter quality and date/time of last maintenance;</li>
              <li>Notifications for temperature deviations or maintenance requirements; and</li>
              <li>The status of available ice and reports of when the measurement has dropped below a predefined level
                (e.g., 25%). </li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers need to ensure that the ice machine is operational with no malfunctions. Ice availability is
            important for product quality and can impact the customer experience.
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            None. The required data is not PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
      <section id="UC-retail-camera-device-1"><div class="header-wrapper"><h4 id="x3-5-10-retail-camera-device"><bdi class="secno">3.5.10 </bdi>Retail Camera Device</h4><a class="self-link" href="#UC-retail-camera-device-1" aria-label="Permalink for Section 3.5.10"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            <ul>
              <li>David Ezell, Conexxus</li>
              <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
            </ul>
          </dd>
          <dt>Category</dt>
          <dd>
            Retail
          </dd>
          <dt>Class</dt>
          <dd>
            Indoor Facilities and Power Equipment
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-20">Device Owners</a> (retailers)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-19">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-12">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-11">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Identifying data and information relative to the devices and systems described within this document can
            reduce downtime and delays related to customer transactions. Long lines can lead to customers leaving,
            diminishing customer service, and lead to lost sale opportunities for new or existing customers.
            Additionally, important health and safety regulations can be observed, automated, and managed to ensure
            quality is consistent and accurate.

            Not being able to access cameras remotely is problematic to loss prevention and store security. It also can
            make research and investigations more difficult, costly (labor), or even impossible, depending on the
            scenario.

            Expected outcomes:
            <ul>
              <li>Proactively monitor cameras and schedule service proactively.</li>
              <li>Inform internal stakeholders of potential issues (e.g., loss prevention).</li>
              <li>Use other functioning equipment to remediate potential collection challenges until service is
                restored.</li>
            </ul>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <ul>
              <li>Digital camera device.</li>
            </ul>
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <ul>
              <li>The positioning of the camera relative to its settings and date/time stamp of any movement;</li>
              <li>Camera status (i.e., power, online, offline) relative to the video recording system;</li>
              <li>Camera status (i.e., power, online, offline) relative to the invoicing system; and</li>
              <li>Details related to the recording frame rate and resolution.</li>
            </ul>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
            </ul>
          </dd>
          <dt>Description</dt>
          <dd>
            Retailers would like to ensure that loss prevention and security cameras are operational and recording
            events as expected, which would be required in concert with the objectives of the camera recording system.

          </dd>
          <dt>Security Considerations</dt>
          <dd>
            Devices subject to replay attacks and DOS attacks.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            Any recording of individuals must be protected as PII.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            None. No direct user (human) interface is affected.
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            None. No direct user (internationalized) interface is affected.
          </dd>
        </dl>
      </section>
    </section>

    <section id="health"><div class="header-wrapper"><h3 id="x3-6-health"><bdi class="secno">3.6 </bdi>Health</h3><a class="self-link" href="#health" aria-label="Permalink for Section 3.6"></a></div>
      

      <section id="public-health"><div class="header-wrapper"><h4 id="x3-6-1-public-health"><bdi class="secno">3.6.1 </bdi>Public Health</h4><a class="self-link" href="#public-health" aria-label="Permalink for Section 3.6.1"></a></div>
        
        <section id="UC-smart-city-public-health-monitoring-1"><div class="header-wrapper"><h5 id="x3-6-1-1-smart-city-public-health-monitoring"><bdi class="secno">3.6.1.1 </bdi>Smart City Public Health Monitoring</h5><a class="self-link" href="#UC-smart-city-public-health-monitoring-1" aria-label="Permalink for Section 3.6.1.1"></a></div> 
          
          <dl>

            <dt>Submitter(s)</dt>
            <dd>

              Jennifer Lin
              
            </dd>

            
            <dt>Target Users</dt>
            <dd>

              Agencies, companies and other organizations in a Smart City with
              significant pedestrian traffic in a pandemic situation.

            </dd>
            <dt>Motivation</dt>
            <dd>

              A system to monitor the health of people in public places is useful to
              control the spread of infectious diseases. In particular, we would like
              to identify individuals with temperatures outside the norm (i.e. running
              a fever) and then take appropriate action. Actions can include sending
              a notification or actuating a security device, such as a gate.

              This mechanism should be non-invasive and non-contact since the solution
              should not itself contribute to the spread of infectious diseases.

              Data may also be aggregated for statistics purposes, for example, to
              identify the number of people in an area with elevated temperatures.
              This has additional requirements to avoid double-counting individuals.

            </dd>
            <dt>Expected Devices</dt>
            <dd>One of the following:
              <ul>
                <li>A thermal camera.</li>
                <li>Face detection (AI) service
                  <ul>
                    <li>May be on device or be an edge or cloud service.</li>
                  </ul>
                </li>
              </ul>
            </dd>
            <dd>Optional:
              <ul>
                <li>RGB and/or depth camera registered with the thermal camera</li>
                <li>Cloud service for data aggregation and analytics.</li>
                <li>Some way to identify location (optional)
                  Note that location might be static and configured during installation,
                  but might also be based on a localization technology if the device needs to be
                  portable (for example, if it needs to be set up quickly for an event).</li>
              </ul>

            </dd>
            <dt>Expected Data</dt>
            <dd>

              <ul>
                <li>Sensor ID</li>
                <li>Timestamp</li>
                <li>Number of people identified with a fever in image</li>
                <li>Estimated temperature for each person
                  <ul>
                    <li>May be coarse, low/normal/high</li>
                  </ul>
                </li>
                <li>Location
                  <ul>
                    <li>Latitude, Longitude, Altitude, Accuracy</li>
                    <li>Semantic (e.g. a particular building entrance)</li>
                  </ul>
                </li>
                <li>Thermal image</li>
              </ul>
            </dd>
            <dd>Optional:
              <ul>
                <li>RGB image</li>
                <li>Depth image</li>
                <li>Localization technology (see localization use case)</li>
                <li>Integration with local IoT devices: gates, lights, or people (guards)</li>
                <li>Bounding boxes around faces of identified people in image(s)</li>
                <li>Data that can be used to uniquely identify a face (distinguish it from others)
                  <ul>
                    <li>Aggregation system may output the total number of unique faces with fever</li>
                  </ul>
                </li>
              </ul>
              <p>Note 1: the system should be capable of notifying consumers (such as security personnel),
                of fever detections.
                This may be email, SMS, or some other mechanism, such as MQTT publication.</p>
              <p>Note 2: In all cases where images are captured, privacy considerations apply.</p>
              <p>It would also be useful to count unique individuals for statistics purposes,
                but not necessarily based on identifying particular people. This is to
                avoid counting the same person multiple times.</p>
            </dd>
            <dt>Dependencies</dt>
            <dd>

              node-wot

            </dd>
            <dt>Description</dt>
            <dd>

              A thermal camera image is taken of a group of people
              and an AI service is used to identify faces in the image.
              The temperature of each person is then estimated from the registered face;
              for greater accuracy, a consistent location for sampling should be used, such
              as the forehead.
              The estimated temperature is compared to high (and optionally, low)
              thresholds and a notification (or other action) is taken if the
              temperature is outside the norm.
              Additional features may be extracted to identify unique individuals.

            </dd>
            <dt>Variants</dt>
            <dd>

              <ul>
                <li>Enough information is included in the notification that the specific
                  person that raised the alarm can be identified. For example, if an RGB
                  camera is also registered with the thermal camera, then a bounding box may
                  be indicated via JSON and the RGB image included; or the bounding box could
                  be actually drawn into the sent image, or the face could be cropped out.
                  This is useful if, for example, a notification needs to be sent to health
                  or security workers who need to identify the person in a crowd.</li>
                <li>Instead of simply a notification, an action may be taken, such as closing
                  or refusing to open a gate at the entrance to a building, to prevent sick
                  employees from entering the building.</li>
                <li>To generate statistics, for example to count the number of people with
                  fevers, then unique individuals need to be identified to avoid counting
                  the same person more than once.
                </li><li>The same sensors might be used to determine the number of people in
                  an area and send a notification if crowded conditions are detected, in
                  order to support social distancing behavior (for instance, supporting
                  an app that notifies users when a destination is crowded) in a pandemic situation.</li>
                <li>Cameras that provide video streams rather than still images.</li>
              </ul>

            </dd>
            <dt>Security Considerations</dt>
            <dd>

              <ul>
                <li>Because PII is involved (see below) access should be controlled (only provided to authorized
                  users) and communications protected (encrypted).</li>
              </ul>

            </dd>
            <dt>Privacy Considerations</dt>
            <dd>
              <ul>
                <li>Images of people and their health status is involved.
                  <ul>
                    <li>If later these are made public then the health information of a particular person would be
                      released
                      publicly.</li>
                    <li>There is also the possibility that the camera data could be in error, and should be confirmed
                      with
                      a
                      more accurate sensor.</li>
                    <li>This information needs to be treated as PII and protected: only distributed to authorized users,
                      and
                      deleted when no longer needed.</li>
                    <li>However, derived aggregate information can be kept and published.</li>
                  </ul>
                </li>
              </ul>
            </dd>
            <dt>Gaps</dt>
            <dd>

              <ul>
                <li>Onboarding mechanism for rapidly deploying a large number of devices</li>
                <li>Standard vocabulary for geolocation information</li>
                <li>Implementations able to handle image payload formats, possibly in combination with non-image data
                  (e.g. images and JSON in a single response)</li>
                <li>Video streaming support (if we wish to serve video stream from the camera instead of still images)
                </li>
                <li>Standard ways to specify notification mechanisms and data payloads for things like SMS and email
                  (in addition to the expected MQTT, CoAP, and HTTP event mechanisms)</li>
              </ul>

            </dd>
            
            <dt>Comments</dt>
            <dd>

              <ul>
                <li>May be additional requirements for privacy since images of people and their health status is
                  involved.</li>
                <li>Different sub-use cases: immediate alerts or actions vs. aggregate data gathering</li>
              </ul>

            </dd>
          </dl>
        </section>
        <section id="UC-interconnected-medical-devices-in-a-hospital-icu-1"><div class="header-wrapper"><h5 id="x3-6-1-2-interconnected-medical-devices-in-a-hospital-icu"><bdi class="secno">3.6.1.2 </bdi>Interconnected Medical Devices in a Hospital ICU</h5><a class="self-link" href="#UC-interconnected-medical-devices-in-a-hospital-icu-1" aria-label="Permalink for Section 3.6.1.2"></a></div> 
          
          <dl>

            <dt>Submitter(s)</dt>
            <dd>
              Taki Kamiya
            </dd>
            <dt>Target Users</dt>
            <dd>

              <ul>
                <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-21">Device Owners</a></li>
                <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-10">Device User</a></li>
                <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-9">Cloud Provider</a></li>
                <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-17">Service Provider</a></li>
                <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-20">Device Manufacturer</a></li>
                <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-13">Gateway Manufacturer</a></li>
                <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-12">Identity Provider</a></li>
              </ul>

            </dd>
            <dt>Motivation</dt>
            <dd>

              Preventable medical errors may account for more than 100,000 deaths per year in U.S. alone. These errors
              are mainly caused by failures of communication such as a chart misread or the wrong data passed along to
              machines or staffs. Part of the problem could be solved if the machines could speak to one another.
              Manufacturers have little incentive to make their proprietary code and data easily to accessible and
              process able by their competitors’ machines. So the task of middleman falls to the hospital staffs. In
              addition to saving lives, a common framework could result in collecting and recording more clinical data
              on patients, making it easier to deliver precision medicine.

            </dd>
            

            
            <dt>Description</dt>
            <dd>
              <p>
                Physiological Closed-Loop Control (PCLC) devices are a group of emerging technologies, which use
                feedback from physiological sensor(s) to autonomously manipulate physiological variable(s) through
                delivery of therapies conventionally delivered by clinician(s).
              </p>
              <p>
                Clinical scenario without PCLC. An elderly female with end-stage renal failure was given a standard
                insulin infusion protocol to manage their blood glucose, but no glucose was provided. Their blood
                glucose
                dropped to 33, then rebounded to over 200 after glucose was given. This scenario has not changed for
                decades.
              </p>
              <p>
                The desired state with PCLC implemented in an ICU. A patient is receiving an IV insulin infusion and is
                having the blood glucose continuously monitored. The infusion pump rate is automatically adjusted
                according to the real-time blood glucose levels being measured, to maintain blood glucose values in a
                target range. If the patient’s glucose level does not respond appropriately to the changes in insulin
                administration, the clinical staff is alerted.
              </p>
              <p>
                Medical devices do not interact with each other autonomously (monitors, ventilator, IV pumps, etc.)
                Contextually rich data is difficult to acquire. Technologies and standards to reduce medical errors and
                improve efficiency have not been implemented in theater or at home.
              </p>
              <p>
                In recent years, researchers have made progress developing PCLC devices for mechanical ventilation,
                anesthetic delivery applications, and so on. Despite these promises and potential benefits, there has
                been limited success in the translation of PCLC devices from <a href="https://today.duke.edu/2014/07/benchbedside">bench to bedside</a>. A key challenge to bringing
                PCLC devices to a level required for a clinical trials in humans is risk management to ensure device
                reliability and safety.
              </p>
              <p>
                The United States Food and Drug Administration (FDA) classifies new hazards that might be introduced by
                PCLC devices into three categories. Besides clinical factors (e.g. sensor validity and reliability,
                inter- and intra-patient physiological variability) and usability/human factors (e.g. loss of
                situational awareness, errors, and lapses in operation), there are also engineering challenges including
                robustness, availability, and integration issues.
              </p>
            </dd>
            <dt>Variants</dt>
            <dd>

              US military developed ONR SBIR (Automated Critical Care System Prototype), and found those issues.

              <ul>
                <li>No plug and play, i.e. cannot swap O2 Sat with another manufacturer.</li>
                <li>No standardization of data outputs for devices to interoperate.</li>
                <li>Must have the exact make/model to replace a faulty device or system will not work.</li>
              </ul>

            </dd>
            <dt>Security Considerations</dt>
            <dd>
              <p>
                Security considerations for interconnected and dynamically composable medical systems are critical not
                only because laws such as [<cite><a class="bibref" data-link-type="biblio" href="#bib-hipaa" title="The Health Insurance Portability and Accountability Act of 1996 (HIPAA), Public Law 104-191">HIPAA</a></cite>] mandate it, but also
                because security attacks can have serious safety consequences for patients. The systems need to support
                automatic verification that the system components are being used as intended in the clinical context,
                that the components are authentic and authorized for use in that environment, that they have been
                approved by the hospital’s biomedical engineering staff and that they meet regulatory safety and
                effectiveness requirements.
              </p>
              <p>
                For security and safety reasons, <a href="https://www.astm.org/Standards/F2761.htm">ICE
                  F2761-09(2013)</a> compliant medical devices never interact directly each other. All interaction is
                coordinated and controlled via the applications.
              </p>
              <p>
                While transport-level security such as TLS provides reasonable protection against external attackers,
                they do not provide mechanisms for granular access control for data streams happening within the same
                protected link. Transport-level security is also not sufficiently flexible to balance between security
                and performance. Another issue with widely used transport-level security solutions is the lack of
                support for multicast.
            </p></dd>
            <dt>Privacy Considerations</dt>
            <dd>
             Medical applications need to be conformant with the appropriate medical privacy standards and legal requirements.
            </dd>
            <dt>References</dt>
            <dd>
              Standards relevant to this use case include regional standards for the management of personal health data,
              including but not limited to [<cite><a class="bibref" data-link-type="biblio" href="#bib-hipaa" title="The Health Insurance Portability and Accountability Act of 1996 (HIPAA), Public Law 104-191">HIPAA</a></cite>] in the United States, [<cite><a class="bibref" data-link-type="biblio" href="#bib-gdpr" title="General Data Protection Regulation (GDPR), EU Public Law 104-191">GDPR</a></cite>] in the EU, and [<cite><a class="bibref" data-link-type="biblio" href="#bib-pipeda" title="Personal Information Protection and Electronic Documents Act (PIPEDA)">PIPEDA</a></cite>] in Canada.
            </dd>
            <dt>Gaps</dt>
            <dd>

              Multicast support. It has proven useful for efficient and scalable discovery and information exchange in
              industrial systems.

            </dd>
            <dt>Existing Standards</dt>
            <dd>

              <p><a href="https://www.astm.org/Standards/F2761.htm">F2761-09 (2013)</a> </p>

              Medical Devices and Medical Systems - Essential safety requirements for equipment comprising the
              patient-centric integrated clinical environment (ICE) - Part 1: General requirements and conceptual
              model.

              The idea behind ICE is to allow medical devices that conform to the ICE standard, either natively or
              using an adapter, to interoperate with other ICE-compliant devices regardless of manufacturer.

              <p><a href="https://www.openice.info/">OpenICE</a></p>

              OpenICE is an initiative to create a community implementation of F2761-09 (ICE - Integrated Clinical
              Environment) based on <a href="https://www.omg.org/spec/DDS/About-DDS/">DDS</a>.

              <p><a href="https://secwww.jhuapl.edu/mdira/documents">MDIRA Specification Document Version
                  1.0</a>. </p>

              MDIRA Version 1.0 provides requirements and implementation guidance for MDIRA-compliant systems focused
              on trauma and critical care in austere environments.

              Johns Hopkins University Applied Physics Laboratory (JHU-APL) lead a research project in collaboration
              with US military to develop a framework of autonomous / closed loop prototypes for military health care
              which are dual use for the civilian healthcare system.

            </dd>
            

            
          </dl>
        </section>
      </section>

      <section id="private-health"><div class="header-wrapper"><h4 id="x3-6-2-private-health"><bdi class="secno">3.6.2 </bdi>Private Health</h4><a class="self-link" href="#private-health" aria-label="Permalink for Section 3.6.2"></a></div>
        
        <section id="UC-health-notifiers-1"><div class="header-wrapper"><h5 id="x3-6-2-1-health-notifiers"><bdi class="secno">3.6.2.1 </bdi>Health Notifiers</h5><a class="self-link" href="#UC-health-notifiers-1" aria-label="Permalink for Section 3.6.2.1"></a></div> 
          
          <dl>

            <dt>Submitter(s)</dt>
            <dd>

              Michael McCool

            </dd>
            <dt>Target Users</dt>
            <dd>

              End user with a health problem they wish to monitor.

              Health services provider (doctor, nurse, paramedic, etc.).

            </dd>
            <dt>Motivation</dt>
            <dd>

              In critical situations regarding health,
              like a medical emergency,
              media multimodality may be the most effective way to communicate alerts,
              When the goal is to monitor the health evolution of a
              person in both emergency and non-emergency contexts,
              access via networked devices may be the most effective way to collect data and
              monitor a patient's status.

            </dd>
            <dt>Expected Devices</dt>
            <dd>

              Medical facilities supporting device and service access.

            </dd>
            <dt>Expected Data</dt>
            <dd>

              Command and status information transferred between the personal mobile device
              application and the meeting space's services and devices.

              Profile data for user preferences.

            </dd>
            <dt>Dependencies</dt>
            <dd>

              <ul>
                <li>WoT Thing Description</li>
                <li>WoT Discovery</li>
                <li>Optional: WoT Scripting API in application on mobile personal device and possibly
                  in IoT orchestration services.</li>
              </ul>

            </dd>
            <dt>Description</dt>
            <dd>

              In medical facilities,
              a system may provide multiple options to control sensor operations
              by voice or gesture ("start reading my blood pressure now").
              These interactions may be mediated by an application installed into a smartphone.
              The system integrates information from multiple sensors
              (for example, blood pressure and heart rate);
              reports medical sensor readings periodically (for example, to a remote medical facility)
              and sends alerts when unusual readings/events are detected.

            </dd>
            <dt>Variants</dt>
            <dd>

              The user may have additional mobile devices they want to incorporate into
              an interaction, for example a headset acting as an auditory aid or personal speech output
              device.

            </dd>
            <dt>Gaps</dt>
            <dd>

              Data format describing user interface preferences.

              Ability to install applications based on links that can access IoT services.

            </dd>
            <dt>Existing Standards</dt>
            <dd>

              This use case is based on MMI UC 3.2 [<cite><a class="bibref" data-link-type="biblio" href="#bib-mmi-use-cases" title="Multimodal Interaction Use Cases">mmi-use-cases</a></cite>].

            </dd>
            <dt>Comments</dt>
            <dd>

              Does not include Requirements section from original MMI use case.
            </dd>
          </dl>
        </section>
</section>



     <section id="Biomedical"><div class="header-wrapper"><h4 id="x3-6-3-biomedical-devices"><bdi class="secno">3.6.3 </bdi>Biomedical Devices</h4><a class="self-link" href="#Biomedical" aria-label="Permalink for Section 3.6.3"></a></div>
        
        <section id="UC-digital-microscopes-1"><div class="header-wrapper"><h5 id="x3-6-3-1-digital-microscopes"><bdi class="secno">3.6.3.1 </bdi>Digital Microscopes</h5><a class="self-link" href="#UC-digital-microscopes-1" aria-label="Permalink for Section 3.6.3.1"></a></div> 
          
          <dt>Submitter(s)</dt>
          <dd>
            Adam Sobieski
          </dd>
          <dt>Category</dt>
          <dd>
            This use case could be horizontal, insofar as it advances digital microscopy for consumers, and could be
            vertical,
            insofar as it equips biomedical professionals, scientists, and educators.
          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-22">Device Owners</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-11">Device Users</a></li>
              <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-10">Cloud Provider</a>s</li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-18">Service Providers</a></li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-21">Device Manufacturers</a></li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-13">Identity Provider</a>s</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            Microscopes are utilized throughout biomedicine, the sciences, and education. Advancing digital microscopes and
            enabling their interoperability with mixed-reality collaborative spaces via WoT architecture and standards can
            equip
            biomedical professionals, scientists, and educators, amplifying and accelerating their performance and
            productivity.
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            Mixed-reality collaborative spaces are device agnostic. Users can collaborate while making use of AR devices, VR
            devices, mobile computers, and desktop computers.
            The expected devices include AR and VR equipment (e.g., head-mounted displays), computing devices, and digital
            microscopes.
          </dd>
          <dt>Expected Data</dt>
          <dd>
            <p>
              The expected data include 2D and 3D streams produced by digital microscopes and recordings thereof. These
              streams
              may contain metadata which describe the instantaneous magnifications and timescales of data.
              The expected data also include the output streams produced by services. These streams could, for instance,
              contain
              annotation data.
            </p>
            <p>
              With respect to annotating video streams, one could make use of secondary video tracks with
              uniquely-identified
              bounding boxes or more intricate silhouettes defining spatial regions on which to attach semantic data, e.g.,
              metadata or annotations, using yet other secondary tracks. Similar approaches could work for point-cloud-based
              and
              mesh-based animations.
            </p>
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            To be determined
          </dd>
          <dt>Description</dt>
          <dd>
            <p>
              Mixed-reality collaborative spaces enable users to visualize and interact with data and to work together from
              multiple locations on shared tasks and projects.
            </p>
            <p>
              Digital microscopes could be accessed and utilized from mixed-reality collaborative spaces via WoT
              architecture and
              standards. Digital microscopes could be thusly utilized throughout biomedicine, the sciences, and education.
              Data from digital microscopes could be processed by services to produce outputs useful to users. Users could
              select
              and configure one or more such services and route streaming data or recordings through them to consume
              resultant
              data in a mixed-reality collaborative space. Graphs, or networks, of such services could be created by users.
              Services could also communicate back to digital microscopes to control their mechanisms and settings. Services
              which
              simultaneously process digital microscope data and communicate back to control such devices could be of use
              for
              providing users with automatic focusing, magnification, and tracking.
            </p>
            <p></p>
            Multimodal user interfaces could be dynamically generated for digital microscope content by making use of the
            output
            data provided by computer-vision-related services. Such dynamic multimodal user interfaces could provide users
            with
            the means of pointing and using spoken natural language to indicate precisely which contents that they wish to
            focus
            on, magnify, or track.
            <p></p>
            <p>
              For example, a digital microscope could be magnifying and streaming 2D or 3D imagery of a living animal cell.
              This
              data could be processed by a service which provides computer-vision-related annotations, labeling parts of the
              cell:
              the cell nucleus, Golgi apparatus, ribosomes, the endoplasmic reticulum, mitochondria, and so forth. The
              resultant
              visual content with its algorithmically-generated annotations could then be interacted with by users. Users
              could
              point and use spoken natural language to indicate precisely which parts of the living animal cell that they
              wished
              for the digital microscope to focus on, magnify, or track.
            </p>
          </dd>
          <dt>Security Considerations</dt>
          <dd>
            The streaming of digital microscope data should be securable for biomedical scenarios.
            Access to the controls and settings of digital microscopes should be securable for education scenarios so that
            teachers can adjust the controls and students cannot.
          </dd>
          <dt>Privacy Considerations</dt>
          <dd>
            In biomedical scenarios, there are privacy issues pertaining to the use of biological samples and medical data
            from
            patients.
          </dd>
          <dt>Accessibility Considerations</dt>
          <dd>
            To be determined
          </dd>
          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            Output data from services could include natural-language content or labels. Such content or labels could be
            multilingual.
            Dynamically generated multimodal user interfaces utilizing such content or labels could also be multilingual.
          </dd>
          <dt>Requirements</dt>
          <dd>
            <p>
              Requirements that are not addressed in the current WoT standards or building blocks include streaming
              protocols and
              formats for 3D digital microscope data and recordings. While digital microscopes could stream video using a
              variety
              of existing protocols and formats, the streaming of other forms of 3D data and animations, e.g., point clouds
              and
              meshes, could be facilitated by recommendation.
            </p>
            <p>
              Users could select and configure one or more services and route data streaming from digital microscopes
              through them
              to consume the resultant data in a mixed-reality collaborative space. Additionally, services could be designed
              to
              communicate back to and control the mechanisms and settings of digital microscopes.
              Requirements that are not addressed in the current WoT standards or building blocks include a means of
              interconnecting services. Perhaps services could utilize WoT architecture and could be described as WoT
              things, or
              virtual devices, which provide functionality including that with which to establish data connectivity between
              them.
            </p>
          </dd>
          
          
        </section>
      </section>
      </section>


    <section id="energy"><div class="header-wrapper"><h3 id="x3-7-energy"><bdi class="secno">3.7 </bdi>Energy</h3><a class="self-link" href="#energy" aria-label="Permalink for Section 3.7"></a></div>
      
      <section id="UC-smart-grids-1"><div class="header-wrapper"><h4 id="x3-7-1-smart-grids"><bdi class="secno">3.7.1 </bdi>Smart Grids</h4><a class="self-link" href="#UC-smart-grids-1" aria-label="Permalink for Section 3.7.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Christian Glomb

          </dd>
          <dt>Target Users</dt>
          <dd>

            <ul>
              <li>Grid operators on all voltage levels line Distribution System Operators (DSO), Transmission System
                Operators (TSO)</li>
              <li>Plant operators (centralized as well as de-centralized producers)</li>
              <li>Virtual Power Plant (VPP) operators</li>
              <li>Energy grid markets</li>
              <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-11">Cloud Providers</a> where grid backend services are hosted and where Operation Technology bridges to
                Information Technology</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-22">Device Manufacturers</a>, owners, and users; devices include communication gateways, monitoring and
                control units</li>
            </ul>

          </dd>
          

          
          <dt>Expected Devices</dt>
          <dd>

            A smart grid integrates all players in the electricity market into one overall system through the
            interaction of generation, storage, grid management and consumption. Power and storage plants are already
            controlled today in such a way that only as much electricity is produced as is needed. Smart grids include
            consumers as well as small, decentralized energy suppliers and storage locations in this control system,
            so that on the one hand, consumption is more homogeneous in terms of time and space (see also intelligent
            electricity consumption) and on the other hand, in principle inhomogeneous producers (e.g. wind power) and
            consumers (e.g. lighting) can be better integrated.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            <ul>
              <li>Weather and climate data</li>
              <li>Metering data (both production as well as consumption as well as storage, e.g. 15 min. intervals)
              </li>
              <li>Real time data from PMUs (Phasor Measurement Units)</li>
              <li>Machine and equipment monitoring data (enabling health checks)</li>
              <li>...</li>
            </ul>

          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            WoT Architecture, WoT Binding Templates (covering protocol specifica)

          </dd>
          <dt>Description</dt>
          <dd>

            The term Smart Grid refers to the communicative networking and control of power generators, storage
            facilities, electrical consumers, and grid equipment in power transmission and distribution networks for
            electricity supply. This enables the optimization and monitoring of the interconnected components. The aim
            is to secure the energy supply on the basis of efficient and reliable system operation.

          </dd>
          <dt>Variants</dt>
          <dd>
            <dl>
              <dt>Decentralized Power Generation</dt>
              <dd>
                While electricity grids with centralized power generation have dominated up to now, the trend is moving
                towards decentralized generation plants, both for generation from fossil primary energy through small
                CHP
                plants and for generation from renewable sources such as photovoltaic systems, solar thermal power
                plants,
                wind turbines and biogas plants. This leads to a much more complex structure, primarily in the area of
                load control, voltage maintenance in the distribution grid and maintenance of grid stability. In
                contrast
                to medium to large power plants, smaller, decentralized generation plants also feed directly into the
                lower voltage levels such as the low-voltage grid or the medium-voltage grid. This use case variants
                also
                includes operation and control of energy storages like batteries.
              </dd>

              <dt>Virtual Power Plants</dt>
              <dd>
                A Virtual Power Plant (VPP) is an aggregation of Distributed Energy Resources (DERs) that can act as an
                entity on energy markets or as an ancillary service to grid operation.
                The individual DERs often have a primary use on their own, with electric generation/consumption being a
                side-effect resp. secondary use. This results in negotiations/collaborations between many different
                parties e.g. such as the DER owner, the VPP operator, the grid operator and others.
              </dd>

              <dt>Smart Metering</dt>
              <dd>
                For consumers, a major change is the installation of smart meters. Their core tasks are remote reading
                and
                the possibility to realize fluctuating prices within a day at short notice. All electricity meters must
                therefore be replaced by those with remote data transmission.
              </dd>

              <dt>Other variants</dt>
              <dd>
                Emergency response, grid synchronization, grid black start
              </dd>
            </dl>
          </dd>

          <dt>Building Blocks</dt>
          <dd>
            <ul>
              <li>Multi-Stakeholder Operation: Multiple involved parties have to find a common mode of operation</li>
              <li>Device Lifecycle Management: Since the VPP is a dynamic system of loosely coupled DERs, the
                appearance and disappearance of DERs as well as the software management on the devices itself requires
                a means to orchestrate the lifecycle of individual device's respective components.</li>
              <li>Embedded Runtime: Especially for DERs in remote locations, maintaining a close couple control loop
                can be expensive if feasible at all. Therefore, it is desirable to be able to offload control logic to
                the DER itself.</li>
              <li>Ensemble Discovery: In order to dynamically find matching DERs needed for the operational goal of a
                VPP, a registry with different options of DER discovery is needed.</li>
              <li>Content-Negotiation: The different stakeholders have to interact and therefore need a common data
                format.</li>
              <li>Resource Description: The DER has to describe itself to enable discovery of single DERs and
                ensembles, also the operational data needs to be understood by the different stakeholders without
                engineering effort.</li>
              <li>Push Services: As there is a fan-out with many devices that probably have a rate-limited connection
                connecting to one single command center, a bidirectional communication mechanism is needed rather than
                polling for the reverse direction</li>
              <li>Object Memory: As multiple and interchangeable stakeholders are involved in the application, a
                backlog of the object is beneficial for scrollkeeping</li>
            </ul>

          </dd>
          <dt>Non-Functionals</dt>
          <dd>
            <ul>
              <li>Privacy: As fine-grained metering information provides sensitive data about a household, the system
                should show a high degree of privacy</li>
              <li>Trust: Since the data exchange between the virtual power plant and the distributed energy resource
                leads to a physical action that invokes high currents and monetary flows, the integrity of both
                parties and the exchange's data is crucial</li>
              <li>Layered L7 Communication: Since multiple different links are used for monitoring and control,
                integration requires a clear and consistent separation of information from the used serialization and
                application protocols to enable the exchange of homogenous information over heterogenous application
                layer protocols</li>
            </ul>
          </dd>
          
          <dt>Existing Standards</dt>
          <dd>
            <ul>
	    <li>IEC 61850 - International standard for data models and communication protocols [<cite><a class="bibref" data-link-type="biblio" href="#bib-iec 61850" title="IEC 61850:2022 - Communication networks and systems for power utility automation">IEC 61850</a></cite>]</li>
	    <li>IEEE 1547 - US standard for interconnecting distributed resources with electric power systems [<cite><a class="bibref" data-link-type="biblio" href="#bib-ieee 1547" title="IEEE 1547-2018 - Interconnection and Interoperability of Distributed Energy Resources with Associated Electric Power Systems Interfaces">IEEE 1547</a></cite>]</li>

          </ul></dd>
          
        </dl>
      </section>
    </section>

    <section id="UC-transportation-1"><div class="header-wrapper"><h3 id="x3-8-transportation"><bdi class="secno">3.8 </bdi>Transportation</h3><a class="self-link" href="#UC-transportation-1" aria-label="Permalink for Section 3.8"></a></div> 
      
      <dl>

        <dt>Submitter(s)</dt>
        <dd>
          Zoltan Kis
        </dd>
        <dt>Sub-categories</dt>
        <dd>
          Transportation - Infrastructure
          Transportation - Cargo
          Transportation - People

        </dd>
        <dt>Target Users</dt>
        <dd>
          <p>
            Smart Cities: managing roads, public transport and commuting, autonomous and human driven vehicles,
            transportation tracking and control systems, route information systems, commuting and public transport,
            vehicles, on-demand transportation, self driving fleets, vehicle information and control systems,
            infrastructure sharing and payment system, smart parking, smart vehicle servicing, emergency monitoring,
            etc.
          </p>
          <p>
            Transport companies: managing shipping, air cargo, train cargo and last mile delivery transportation
            systems including automated systems.
          </p>
          <p>
            Commuters: Mobility as a service, booking systems, route planning, ride sharing, self-driving,
            self-servicing infrastructure, etc.
          </p>
        </dd>
        <dt>Motivation</dt>
        <dd>
          <p>
            Provide common vocabulary for describing transport related services and solutions that can be reused
            across sub-categories, for easier interoperability between various systems owned by different
            stakeholders.
          </p>
          <p>
            Thing models could be defined in many subdomains to help integration or interworking between multiple
            systems.
          </p>
          <p>
            Transportation of goods can be optimized at global level by enhancing interoperability between vertical
            systems.
          </p>
        </dd>
        <dt>Expected Devices</dt>
        <dd>

          Road information system (routes, conditions, navigation).
          Road control system (e.g. virtual rails).
          Traffic management services, e.g. intelligent traffic light system with localization and identification
          (by satellite, radio frequency identification, cameras etc.).
          Emergency monitoring and data/location sharing.
          Airport management.
          Shipping docks and ports management.
          Train networks management.
          Public transport vehicles (train, metro, tram, bus, minibus), mobility as a service (ride sharing, bicycle
          sharing, scooters etc.).
          Transportation network planning and management (hubs, backbones, sub-networks, last mile network).
          Electronic timetable management system.
          Vehicles (human driven, self-driving, isolated or part of fleet).
          Connected vehicles (cars, ships, airplanes, trains, buses etc).
          Devices needed for cargo.

        </dd>
        <dt>Expected Data</dt>
        <dd>

          Vehicle data (identification, location, speed, route, selected vehicle data).
          Weather and climate data.
          Contextual data (representing various risk factors, delays, etc.).

        </dd>
        <dt>Dependencies</dt>
        <dd>

          Localization technologies.
          Automotive data.
          Contextual data.
          Cloud integration.

        </dd>
        <dt>Description</dt>
        <dd>

          Transportation system implementers will be able to use a unified data description model across various
          systems.

        </dd>
        <dt>Variants</dt>
        <dd>

          There will be different verticals, such as:

          <ul>
            <li>Smart City public transport</li>
            <li>Smart City traffic management</li>
            <li>Smart city vehicle management</li>
            <li>Cargo traffic management</li>
            <li>Cargo vehicle management</li>
          </ul>

        </dd>
        
        
        <dd>

        </dd>
      </dl>
    </section>

    <section id="automotive"><div class="header-wrapper"><h3 id="x3-9-automotive"><bdi class="secno">3.9 </bdi>Automotive</h3><a class="self-link" href="#automotive" aria-label="Permalink for Section 3.9"></a></div>
      
      <section id="UC-smart-car-configuration-management-1"><div class="header-wrapper"><h4 id="x3-9-1-smart-car-configuration-management"><bdi class="secno">3.9.1 </bdi>Smart Car Configuration Management</h4><a class="self-link" href="#UC-smart-car-configuration-management-1" aria-label="Permalink for Section 3.9.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael McCool

          </dd>
          <dt>Category</dt>
          <dd>
            Accessibility
          </dd>
          <dt>Motivation</dt>
          <dd>

            User interface personalization is a task that most often needs to be repeated
            for all Devices a user wishes to interact with recurringly.
            With complex devices,
            this task can also be very time-consuming,
            which is problematic if the user regularly accesses similar,
            but not identical devices, as in the case of several cars rented over a month.

            A standardized set of personal information and preferences that could be used
            to configure personalizable devices automatically would be very helpful for all
            these cases in which the interaction becomes a customary practice.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Personal mobile device running an application providing command
            mediation capabilities.

            IoT-enabled smart car supporting
            remote sensing, actuation, and configuration functionality.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Command and status information transferred between the personal mobile device
            application and the car's services and devices.

            Profile data for user preferences.

          </dd>
          <dt>Dependencies</dt>
          <dd>

            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
              <li>Optional: WoT Scripting API in application on mobile personal device and possibly
                in IoT orchestration services in the car.</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>

            Basic in-car functionality is standardized to be managed by other devices.
            A user can control seat, radio or AC settings through a personalized multimodal interface
            shared by the car and their personal mobile device.
            User preferences are stored on the mobile Device (or in the cloud),
            and can be transferred across different car models handling a specific functionality
            (e.g. all cars with touchscreens should be able to adapt to a "high contrast" preference).

            The car can make itself available as a complex modality component that wraps around all
            functionality and supported modalities,
            or as a collection of modality components such as touchscreen, speech recognition system,
            or audio player.
            In the latter case,
            certain user preferences may be shared with other environments.

            For example,
            a user may opt to select the "high contrast" scheme at night on all of their displays,
            in the car or at home.
            A car that provides a set of modalities can be also adapted by the mobile device
            to compose an interface for its functionality,
            for example to manage playback of music tracks through the car's voice control system.
            Sensor data provided by the phone can be mixed with data recorded by the car's own sensors
            to profile user behavior which can be used as context in multimodal interaction.

          </dd>
          <dt>Variants</dt>
          <dd>

            Additional portable devices may be brought into the car and also be
            incorporated into an application, for example, a GPS navigation system.

          </dd>
          <dt>Gaps</dt>
          <dd>

            Data format describing user interface preferences.

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            This use case is based on MMI UC 2.1 [<cite><a class="bibref" data-link-type="biblio" href="#bib-mmi-use-cases" title="Multimodal Interaction Use Cases">mmi-use-cases</a></cite>].

          </dd>
          <dt>Comments</dt>
          <dd>

            Does not include Requirements section from original MMI use case.
          </dd>
        </dl>
      </section>
    </section>

    <section id="smart-home"><div class="header-wrapper"><h3 id="x3-10-smart-home"><bdi class="secno">3.10 </bdi>Smart Home</h3><a class="self-link" href="#smart-home" aria-label="Permalink for Section 3.10"></a></div>
      

      <section id="audio_video"><div class="header-wrapper"><h4 id="x3-10-1-audio-video"><bdi class="secno">3.10.1 </bdi>Audio/Video</h4><a class="self-link" href="#audio_video" aria-label="Permalink for Section 3.10.1"></a></div>
      
      

      <section id="UC-home-wot-devices-synchronize-to-tv-programs-1"><div class="header-wrapper"><h5 id="x3-10-1-1-home-wot-devices-synchronize-to-tv-programs"><bdi class="secno">3.10.1.1 </bdi>Home WoT devices synchronize to TV programs</h5><a class="self-link" href="#UC-home-wot-devices-synchronize-to-tv-programs-1" aria-label="Permalink for Section 3.10.1.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Hiroki Endo,
            Masaya Ikeo,
            Shinya Abe,
            Hiroshi Fujisawa

          </dd>
          <dt>Target Users</dt>
          <dd>

            Person watching TV, Broadcasters

          </dd>
          <dt>Motivation</dt>
          <dd>

            A lot of home devices, such as TV, cleaner, and home lighting, connect to an IP network.
            When you watch a content program, these devices should cooperate for enhancing your experience.

            If the cleaning robot makes a loud noise while watching the TV program, it will hinder viewing.
            Also, even if you set up the theater environment with smart lights, it is troublesome to operate it
            yourself each time the TV program switches.

            Therefore, by WoT device to operate in accordance with the TV program being viewed, thereby improving the
            user experience.

            WoT devices work according to TV programs:

            <ul>
              <li>Cleaning robot stops at an important situation,</li>
              <li>Color of smart lights are changed according to TV programs,</li>
              <li>Smart Mirror is notified that favorite TV show will start.</li>
            </ul>

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            <ul>
              <li>Hybridcast TV</li>
              <li>Hybridcast Connect application (in a smartdevice such as smartphone)</li>
              <li>Cleaning Robot</li>
              <li>Smart Light (such as Philips Hue)</li>
              <li>Smart Mirror</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>

            The trigger value of the scene of the TV program.
            Hybridcast connect application know the Thing Description of the devices in home. (Discovery?)

          </dd>
          


          
          <dt>Description</dt>
          <dd>
            <p>
              Home smart devices behave according to TV programs.
            </p>
            <p>
              Hybridcast applications in TV emit information about TV programs for smart home devices.
              (Hybridcast is a Japanese Integrated Broadcast-Broadband system. Hybridcast applications are HTML5
              applications that work on Hybridcast TV.)
            </p>
            <p>Hybridcast Contact application receives the information and controls smart home devices.</p>
            <div class="resize"><img src="images/scenario_nhk.png" alt="Hybridcast Connect Application"></div>
          </dd>
          

          
          <dt>Existing Standards</dt>
          <dd>

            Hybridcast and Hybridcast Connect: a Japanese Integrated Broadcast-Broadband system [<cite><a class="bibref" data-link-type="biblio" href="#bib-hybridcast" title="IPTVFJ STD-0013 Hybridcast Operational Guideline Version 2.8">Hybridcast</a></cite>],
	    <a href="https://github.com/nhkrd">Reference Implementations</a>),
            HbbTV,
            ATSC 3.0,
            etc.

          </dd>
          <dt>Comments</dt>
          <dd>

          </dd>
        </dl>

      </section>

      <section id="UC-leaving-and-coming-home-1"><div class="header-wrapper"><h5 id="x3-10-1-2-leaving-and-coming-home"><bdi class="secno">3.10.1.2 </bdi>Leaving and Coming Home</h5><a class="self-link" href="#UC-leaving-and-coming-home-1" aria-label="Permalink for Section 3.10.1.2"></a></div> 
        

        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            Tetsushi Matsuda, Keiichi Teramoto, Takashi Murakami, Morio Hirahara (ECHONET Consortium)
          </dd>

          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-12">Device User</a></li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-19">Service Provider</a> (Home Management Service Provider)</li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-23">Device Manufacturer</a></li>
            </ul>
          </dd>

          <dt>Motivation</dt>
          <dd>
            The purpose of this use case is to improve the usability of home appliances for <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-13">Device Users</a> by allowing
            <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-14">Device Users</a> to configure the operation modes of all devices at home without configuring those devices one
            by one when they leave and come home.
          </dd>

          <dt>Expected Devices</dt>
          <dd>
            Lighting, Air Conditioner, Security Sensor, Smartphone
          </dd>

          <dt>Expected Data</dt>
          <dd>
            The operation modes of lighting, air conditioner and security sensor. Reading and updating those operation
            modes on demand.
          </dd>

          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
          </dd>

          <dt>Description</dt>
          <dd>
            <div class="resize"><img src="./images/wot-use-case-echonet.png" alt="echonet use case"></div>
            <ul>
              <li>Configuration by a <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-15">Device User</a> before starting to use a service
                <ul>
                  <li>A <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-16">Device User</a> logs in the server of a "home management service provider" with which the user has a
                    contract.</li>
                  <li>The user specifies the operation modes of lighting, air conditioner and security sensor for the
                    time when the user is out of home, the time when the user comes home and the time when the specified
                    amount of time has passed after the user comes home.</li>
                </ul>
              </li>
            </ul>

            <ul>
              <li>When the <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-17">Device User</a> leaves home
                <ul>
                  <li>The <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-18">Device User</a> accesses the server of a "home management service provider" with a smartphone and
                    notifies the server that the user is going to leave home.</li>
                  <li>The server updates the operation modes of lighting, air conditioner and security sensor according
                    to the configuration specified by the user for the time when the user is out of home.</li>
                  <li>The server reads the operation modes of lighting, air conditioner and security sensor and informs
                    the user's smartphone of those operation modes.</li>
                </ul>
              </li>
            </ul>

            <ul>
              <li>When the <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-19">Device User</a> comes home
                <ul>
                  <li>The <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-20">Device User</a> accesses the server of a "home management service provider" with a smartphone and
                    notifies the server that the user will return home soon.</li>
                  <li>The server updates the operation modes of lighting, air conditioner and security sensor according
                    to the configuration specified by the user for the time when the user comes home.</li>
                  <li>The server reads the operation modes of lighting, air conditioner and security sensor and informs
                    the user's smartphone of those operation modes.</li>
                  <li>When the specified amount of time has passed after the user returns home, the server updates the
                    operation modes of lighting, air conditioner and security sensor according to the configuration
                    specified by the user for the time when the specified amount of time has passed after the user comes
                    home.</li>
                  <li>The server reads the operation modes of lighting, air conditioner and security sensor and informs
                    the user's smartphone of those operation modes.</li>
                </ul>
              </li>
            </ul>
          </dd>

          <dt>Security Considerations</dt>
          <dd>
            <ul>
              <li>It is necessary to prevent unauthorized users other than the <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-21">Device User</a> from using the service
                provided by the home management service provider.</li>
              <li>It is necessary to disallow home management service providers other than the home management service
                providers permitted by the <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-22">Device User</a> in advance to control devices at the <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-23">Device User</a>'s home.</li>
            </ul>
          </dd>

          <dt>Privacy Considerations</dt>
          <dd>
            It is necessary to protect the information on what operations are done on the devices that are controlled or
            monitored at the <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-24">Device User</a>'s home. It is also necessary to protect the information obtained from the
            devices that are controlled or monitored at the <a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-25">Device User</a>'s home.
          </dd>

          <dt>Accessibility Considerations</dt>
          <dd>
            User interface provided by a smartphone had better consider accessibility.
          </dd>

          <dt>Internationalisation (i18n) Considerations</dt>
          <dd>
            User interface provided by a smartphone had better support internationalization.
          </dd>

          <dt>Gaps</dt>
          <dd>
            The method for controlling multiple devices in an orchestrated manner is dependent on the implementation of
            a client application in the current WoT specification. That is a reasonable design choice. However, the
            orchestrated control of multiple devices needs to be implemented by each client application even if the same
            control is done by multiple client applications.
          </dd>

          <dt>Existing standards</dt>
          <dd>
            ECHONET Lite (https://echonet.jp/spec_v113_lite_en/ ) and ECHONET Lite Web API Guideline
            (https://echonet.jp/web_api/ in Japanese ).
          </dd>
        </dl>
      </section>

    </section>

    <section id="education"><div class="header-wrapper"><h4 id="x3-10-2-education"><bdi class="secno">3.10.2 </bdi>Education</h4><a class="self-link" href="#education" aria-label="Permalink for Section 3.10.2"></a></div>
      
      <section id="UC-education-shared-devices-1"><div class="header-wrapper"><h5 id="x3-10-2-1-education-shared-devices"><bdi class="secno">3.10.2.1 </bdi>Education Shared Devices</h5><a class="self-link" href="#UC-education-shared-devices-1" aria-label="Permalink for Section 3.10.2.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Ege Korkan

          </dd>
          
          <dt>Target Users</dt>
          <dd>

            For the education category:

            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-23">Device Owners</a> : The university -&gt; Research Group -&gt; Specific Lab</li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-26">Device User</a> : Students and potentially anyone who participates in plugfests</li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-20">Service Provider</a> : The university -&gt; Research Group</li>
              <li>network operator : The university</li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            This use case motivates a standardized use of shared resources. One example is when a physical resource of
            the Thing should not be used by multiple Consumers at the same time like the arm of the robot but its
            position can be read my multiple Consumers.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Concrete devices are irrelevant for this use case but devices with a physical state is required. However,
            we have currently the following devices that are connected to Raspberry Pis where the WoT stack (node-wot
            or similar) is running. Concrete device models can be given upon request.

            <ul>
              <li>Robotic arms</li>
              <li>Conveyor belts</li>
              <li>Motorized sliders where the robots or devices can be mounted on</li>
              <li>Philips Hue devices: Light bulbs, LED Strips, Motion sensors, Switch. We do not have the source code
                of these devices (brownfield) </li>
              <li>Various sensors (brightness, humidity, temperature, gyroscopic sensors)</li>
              <li>LED Screen to display messages</li>
            </ul>

            There are also IP Cameras but they are not WoT compatible and are not planned to be made compatible.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Atmospheric data of a room, machine sensors

          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            Thing Description, Scripting API, possibly security

          </dd>
          <dt>Description</dt>
          <dd>

            We are offering a practical course for the students where they can interact fully remotely with WoT
            devices and verify their physical actions via video streams. We have sensors and actuators like robots.
            Students then build mashup applications to deepen their knowledge of WoT technologies. Official page of
            the course is <a href="https://campus.tum.de/tumonline/wbLv.wbShowLVDetail?pStpSpNr=950504601&amp;pSpracheNr=1">here</a>.

          </dd>
          

          
          <dt>Security Considerations</dt>
          <dd>

            The devices are connected to the Internet and are secured behind a router and proxy.

          </dd>
          <dt>Privacy Considerations</dt>
          <dd>

            None from the WoT point of view since we want the devices to be used by anyone and the devices do not
            share any information that is related to the students or us as the provider of the devices.
            However, there are cameras which can show humans entering the room as a side effect (they are meant to
            monitor the devices). The streams are accessible only to authorized users, the room has signs on the door
            and there is a cage around the area that is filmed.

          </dd>
          <dt>Gaps</dt>
          <dd>

            <p>Thing Description</p>

            <ul>
              <li>How to give hints that a particular action should not be used by others at the same time. A new
                keyword (like <code>"shared":true</code>) would be needed for devices that do not implement a describable
                mechanism.</li>
              <li>How to describe the mechanism that the Thing implements to manage the shared resources. Does it
                happen in the security level? </li>
            </ul>

            <p>Scripting API</p>

            <ul>
              <li>How does the Consumer code change when this mechanism is used. Does it get settled in the
                implementation or scripting level. </li>
            </ul>

          </dd>
          
        </dl>
      </section>
    </section>

  </section> 

	</section>  

  <section id="sec-horizontal-ucs"><div class="header-wrapper"><h2 id="x4-use-cases-for-multiple-domains"><bdi class="secno">4. </bdi>Use Cases for multiple domains</h2><a class="self-link" href="#sec-horizontal-ucs" aria-label="Permalink for Section 4."></a></div>
    

    <section id="UC-discovery-1"><div class="header-wrapper"><h3 id="x4-1-discovery"><bdi class="secno">4.1 </bdi>Discovery</h3><a class="self-link" href="#UC-discovery-1" aria-label="Permalink for Section 4.1"></a></div> 
      
      <dl>
        <dt>Submitter(s)</dt>
        <dd>
          Michael McCool
        </dd>
        <dt>Target Users</dt>
        <dd>

            All stakeholders:
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-24">Device Owners</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-27">Device User</a></li>
              <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-12">Cloud Provider</a></li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-21">Service Provider</a></li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-24">Device Manufacturer</a></li>
              <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-14">Gateway Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-14">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            Discovery defines a distribution mechanism for the metadata contained in WoT Things Descriptions,
            and allows Things to advertise their capabilities and for potential consumers to find Things that
            match their needs. A standardized discovery mechanism is an enabler for convenient and ad-hoc
            orchestration of combinations of Things from different vendors while supporting appropriate security
            and privacy controls.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            <ul>
              <li>Thing - any device or service that wishes to distribute (advertise) its metadata.</li>
              <li>Consumer - any device or service that wishes to find Things whose location and metadata satisfies
                specified constraints.</li>
              <li>Discovery Service - Mechanism by which metadata is distributed, which can involve a variety of
                services to handle spatial and semantic queries, register Thing Descriptions, provide access controls,
                etc.</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>

            <ul>
              <li>Thing Descriptions - metadata describing a Thing</li>
            </ul>

          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            <ul>
              <li>WoT Discovery</li>
            </ul>

            Note: this is a "horizontal" use case, and is driven by requirements in multiple verticals.

          </dd>
          <dt>Description</dt>
          <dd>

            A user wishing to build or instantiate an IoT service needs access to Thing Descriptions of installed and
            running
            devices satisfying specific requirements. These requirements can include being in or near a certain
            location,
            accessible using particular protocols or on a certain network,
            satisfying certain semantic categories, having certain capabilities, or having specific sub-APIs
            (interfaces).
            Discovery is the general process whereby WoT Thing Descriptions satisfying a specific set of such
            constraints are retrieved by a running system.

          </dd>

          <dt>Variants</dt>
          <dd>
            <ul>
              <li>Run-time discovery allows late binding of orchestration services to particular devices and requires
                that
                consumers be able to adapt to Thing Descriptions discovered when a service is deployed.</li>
              <li>Development-time discovery may be useful during system development to build services that can
                interface to
                a particular class of Thing Descriptions. In this case what actually needs to be discovered Thing
                Models,
                not specific Thing Descriptions.</li>
            </ul>

          </dd>
          <dt>Security Considerations</dt>
          <dd>

            <ul>
              <li>The distribution mechanism needs to be able to clearly authenticate potential users.</li>
              <li>The distribution mechanism for metadata should only provide metadata to authorized users.</li>
              <li>The distribution mechanism should be able to resist denial-of-service attacks seeking to overwhelm it
                within spurious requests.</li>
              <li>The distribution mechanism should be able to preserve the integrity of metadata.</li>
            </ul>

          </dd>
          <dt>Privacy Considerations</dt>
          <dd>

            <ul>
              <li>Metadata should only be distributed to appropriate sets of requesters, with the definition of
                "appropriate" configurable by the source of the metadata.</li>
              <li>Unauthorized users should not be able to access or infer information that they do not have access
                rights to.</li>
              <li>Providers of metadata should be able to withdraw metadata from distribution at any time.</li>
              <li>Metadata should not be retained indefinitely.</li>
            </ul>

          </dd>
          <dt>Gaps</dt>
          <dd>

            <ul>
              <li>The current WoT standards define a metadata format (the Thing Description) but not a means of
                distributing it.</li>
            </ul>

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            <ul>
              <li>WoT Thing Description</li>
              <li>CoreRD</li>
              <li>DID</li>
            </ul>

          </dd>
          <dt>Comments</dt>
          <dd>

            <ul>
              <li>Many discovery mechanisms already exist but many do not satisfy all the requirements above, e.g. they
                may have insufficient
                privacy controls. A standards solution that builds upon prior work in this area is desirable.</li>
          </ul></dd>
      </dl>
    </section>

    <section id="UC-multi-vendor-system-integration-out-of-the-box-interoperability-1"><div class="header-wrapper"><h3 id="x4-2-multi-vendor-system-integration-out-of-the-box-interoperability"><bdi class="secno">4.2 </bdi>Multi-Vendor System Integration - Out of the box interoperability</h3><a class="self-link" href="#UC-multi-vendor-system-integration-out-of-the-box-interoperability-1" aria-label="Permalink for Section 4.2"></a></div> 
      
      <dl>
        <dt>Submitter(s)</dt>
        <dd>
          Michael Lagally
        </dd>
        <dt>Target Users</dt>
        <dd>
          <ul>
            <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-25">Device Owner</a></li>
            <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-22">Service Provider</a></li>
            <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-13">Cloud Provider</a></li>
            <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-25">Device Manufacturer</a></li>
            <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-15">Gateway Manufacturer</a></li>
          </ul>

        </dd>
        <dt>Motivation</dt>
        <dd>

          <ul>
            <li>As a <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-26">Device Owner</a>, I want to know whether a device will work with my system before I purchase it to
              avoid wasting money.
              <ul>
                <li>Installers of IoT devices want to be able to determine if a given device will be compatible with
                  the
                  rest of their installed systems and whether they will have access to its data and affordances.</li>
              </ul>
            </li>
          </ul>
          <ul>
            <li>As a developer, I want TDs to be as simple as possible so that I can efficiently develop them.
              <ul>
                <li>Here "simple" should relate to the end goal, "efficiently develop"; that is, TDs should be
                  straightforward for the average developer to complete and validate.</li>
              </ul>
            </li>
          </ul>
          <ul>
            <li>As a developer, I want to be able to validate that a Thing will be compatible with a Consumer
              without having to test against every possible consumer.</li>
          </ul>
          <ul>
            <li>As a <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-14">Cloud Provider</a> I want to onboard, manage and communicate with as many devices as possible out
              of the box.
              This should be possible without device specific customization.</li>
          </ul>
        </dd>
        <dt>Expected Devices</dt>
        <dd>sensors, actuators, gateways, cloud, directory service.</dd>
        <dt>Expected Data</dt>
        <dd>discrete or streaming data.</dd>
        <dt>Affected WoT deliverables and/or work items</dt>
        <dd>WoT Profile, WoT Thing Description</dd>
        <dt>Description</dt>
        <dd>
          <p>
          As a consumer of devices I want to be able to process data from any device that conforms to a class of
          devices.
         </p><p>
          I want to have a guarantee that I'm able to correctly interact with all affordances of the Thing that
          complies with this class of devices.
          Behavioral ambiguities between different implementations of the same description should not be possible.
          </p><p>
          I want to integrate it into my existing scenarios out of the box, i.e. with close to zero configuration
          tasks.
      </p>
        </dd>
        
        
        <dt>Comments</dt>
        <dd>

          The profile specification is currently in development by the architecture task force.
          The current draft of the specification is available at: <a href="https://github.com/w3c/wot-profile">https://github.com/w3c/wot-profile</a>
          <br>
          Recommendations for commonalities and interoperability profiles of IoT platforms:<a href="https://european-iot-pilots.eu/wp-content/uploads/2018/11/D06_02_WP06_H2020_CREATE-IoT_Final.pdf">https://european-iot-pilots.eu/wp-content/uploads/2018/11/D06_02_WP06_H2020_CREATE-IoT_Final.pdf</a>
        </dd>
      </dl>
    </section>

    <section id="UC-virtual-thing-1"><div class="header-wrapper"><h3 id="x4-3-virtual-thing"><bdi class="secno">4.3 </bdi>Virtual Thing</h3><a class="self-link" href="#UC-virtual-thing-1" aria-label="Permalink for Section 4.3"></a></div> 
      
      <dl>

        <dt>Submitter(s)</dt>
        <dd>

          <ul>
            <li>David Ezell, Conexxus</li>
            <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
          </ul>

        </dd>
        <dt>Category</dt>
        <dd>

          Retail

        </dd>
        <dt>Class</dt>
        <dd>

          Indoor Facilities and Power Equipment

        </dd>

        
        <dt>Target Users</dt>
        <dd>
          <ul>
            <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-27">Device Owners</a> (retailers)</li>
            <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-26">Device Manufacturers</a></li>
            <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-16">Gateway Manufacturer</a></li>
            <li>network operator (potentially transparent for WoT use cases)</li>
          </ul>

        </dd>
        <dt>Motivation</dt>
        <dd>
          <p>
          One of the most powerful features of the Web of Things is the ability for Thing Descriptions (TDs) to provide and
          abstract interface. This abstraction can remain constant when device capabilities change, when device suppliers
          are changed, or when new computational capabilities become available.
          </p><p>
          A "Virtual Thing" refers to a software simulation of a device conforming to a TD. That TD describes affordances
          generated in software from inputs that may or may not be similar to a physical thing that the same TD defines.
          </p><p>
          These inputs most often (but not always) will refer to data streams which, when examined with intelligent software
          (an AI), will allow that software to imitate the properties, actions, and events that an actual physical device
          would normally provide.
          </p>
          <div class="resize"><img src="./images/DataStreamToWoT.png" alt="Virtual Thing - Message Flow"></div>
          <p>
          In a simple case, software could interpret data from a new door sensor product (possibly from a new manufacturer)
          and imitate the actions, properties, and events supported by the older device. This capability allows consuming
          software to remain unchanged and insulated from the churn caused by introducing new devices into the ecosystem.
          The consuming software will continue to use the original Thing Description as the interface definition.
          </p><p>
          In a more complex case, a data stream can be processed in software to imitate a physical device. Such "virtual
          things" allow the sensing hardware to be upgraded (in this case to video camera devices) without forcing a
          complete rewrite of software that was built to consume the original Thing Description. It is also possible for the
          data stream to be used to imitate multiple "virtual things", and also support new Thing Descriptions alongside the
          older ones.
          </p><p>
          Being able to use existing Thing Descriptions as an abstraction for "virtual things" will allow those with a
          device estate to save considerable time and effort in maintaining software and hardware in the estate.
          </p><p>
          Expected outcomes:
          </p><ul>
            <li>Allow newer devices to support older Thing Descriptions using software imitation.</li>
            <li>Provide powerful new multi-purpose devices, supporting multiple Thing Descriptions.</li>
            <li>Allow new and old devices to exist side by side in the device estate.</li>
            <li>Insulate existing software from changes.</li>
          </ul>
        </dd>
        <dt>Expected Devices</dt>
        <dd>
          <ul>
            <li>Digital camera device.</li>
            <li>Digital audio device.</li>
          </ul>
        </dd>
        <dt>Expected Data</dt>
        <dd>
          <ul>
            <li>Expected data is defined in the original TDs, and software is used to imitate the older devices</li>
          </ul>
        </dd>
        <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
        <dd>
          <ul>
            <li>WoT Thing Description</li>
            <li>WoT Discovery</li>
          </ul>
         </dd>
        <dt>Description</dt>
        <dd>
          <p>
          Retailers would like to avoid the expense of rewriting software when new capabilities become available, and would
          like to maintain existing functionality even while introducing new and more powerful TDs.
        </p><p>
          A video camera produces a data stream that can be processed to imitate a variety of "virtual things" defined with
          existing TDs. One such TD is a "door sensor." The video data stream can be processed to recognize when the door is
          open or closed, and can the processing software can emit "doorOpen" boolean events when the door is open or
          closed, and also emit "doorOpenPastLimit" events if the door has been open for too long. Any consuming software
          designed to understand the original door sensor TD will continue to work with this more advanced camera hardware,
          eliminating logistical challenges for retail management and reducing costs.
        </p>
        </dd>
        <dt>Security Considerations</dt>
        <dd>
          Devices subject to replay attacks and DOS attacks.
        </dd>
        <dt>Privacy Considerations</dt>
        <dd>
          Any recording of individuals must be protected as PII. This use case will likely keep any data stream for local
          processing, reducing the danger of video or audio capture.
        </dd>
        <dt>Accessibility Considerations</dt>
        <dd>
          None. No direct user (human) interface is affected.
        </dd>
        <dt>Internationalisation (i18n) Considerations</dt>
        <dd>
          None. No direct user (internationalized) interface is affected.
        </dd>


      </dl>
    </section>

    <section id="digital-twin"><div class="header-wrapper"><h3 id="x4-4-digital-twin"><bdi class="secno">4.4 </bdi>Digital Twin</h3><a class="self-link" href="#digital-twin" aria-label="Permalink for Section 4.4"></a></div>
      
      <section id="UC-digital-twin-1"><div class="header-wrapper"><h4 id="x4-4-1-digital-twin-1"><bdi class="secno">4.4.1 </bdi>Digital Twin (1)</h4><a class="self-link" href="#UC-digital-twin-1" aria-label="Permalink for Section 4.4.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael Lagally

          </dd>
          <dt>Target Users</dt>
          <dd>

            <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-28">Device Owners</a>, <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-15">Cloud Provider</a>.

          </dd>
          <dt>Motivation</dt>
          <dd>
            <p>
              A digital twin is the virtual representation of a physical asset such as a machine, a vehicle, robot,
              sensor.
              Using a digital twin allows businesses to analyze their physical assets to troubleshoot in real time,
              predict future problems, minimize downtime, and perform simulations to create new business opportunities.
            </p>
            <p>
              A digital twin may also be called a twin or a shadow. Digital twin technology may be referred to as device
              virtualization.
            </p>
            <p>
              Digital twins can be located in the edge or in the cloud.
            </p>
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            <p>
              Various devices such as sensors, machines, vehicles, production lines, industry robots.
            </p>
            <p>
              Digital twin platforms at the edge or in the cloud.
            </p>
          </dd>
          <dt>Expected Data</dt>
          <dd>

            Machine status information, discrete sensor data or data streams.

          </dd>
          <dt>Dependencies</dt>
          <dd>

            <ul>
              <li>WoT Architecture </li>
              <li>WoT Thing Description </li>
              <li>WoT Profile </li>
              <li>WoT Scripting? </li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>

            The user benefits from using digital twins with the following scenarios:

            <ul>
              <li>Better visibility: Continually view the operations of the machines or devices, and the status of
                their interconnected systems.</li>
            </ul>

            <ul>
              <li>Accurate prediction: Retrieve the future state of the machines from the digital twin model by using
                modeling.</li>
            </ul>

            <ul>
              <li>What-if analysis: Easily interact with the model to simulate unique machine conditions and perform
                what-if analysis using well-designed interfaces.</li>
            </ul>

            <ul>
              <li>Documentation and communication: Use of the digital twin model helps to understand, document, and
                explain the behavior of a specific machine or a collection of machines.</li>
            </ul>

            <ul>
              <li>Integration of disparate systems: Connect with back-end applications related to supply chain
                operations such as manufacturing, procurement, warehousing, transportation, or logistics.</li>
            </ul>

          </dd>
          <dt>Variants</dt>
          <dd>
            <dl>
              <dt>Virtual Twin</dt>
              <dd>
                <p>
                  The virtual twin is a representation of a physical device or an asset. A virtual twin uses a model
                  that
                  contains observed and desired attribute values and also uses a semantic model of the behavior of the
                  device.
                </p>
                <p>
                  Intermittent connectivity: An application may not be able to connect to the physical asset. In such a
                  scenario, the application must be able to retrieve the last known status and to control the operation
                  states of other assets.
                </p>
                <p>
                  Protocol abstraction: Typically, devices use a variety of protocols and methods to connect to the IoT
                  network. From a users perspective this complexity should not affect other business applications such
                  as
                  an
                  enterprise resource planning (ERP) application.
                </p>
                <p>
                  Business rules: The user can specify the normal operating range of a property in a semantic model.
                  Business rules can be declaratively defined and actions can be automatically invoked in the edge or on
                  the
                  device.
                </p>
                <p>
                  Example: In a fleet of connected vehicles, the user monitors a collection of operating parameters,
                  such
                  as
                  fuel level, location, speed and others. The semantics-based virtual twin model enables the user to
                  decide
                  whether the operating parameters are in normal range. In out of range conditions the user can take
                  appropriate actions.
                </p>
              </dd>

              <dt>Predictive Twin</dt>
              <dd>
                <p>
                  In a predictive twin, the digital twin implementation builds an analytical or statistical model for
                  prediction by using a machine-learning technique. It need not involve the original designers of the
                  machine. It is different from the physics-based models that are static, complex, do not adapt to a
                  constantly changing environment, and can be created only by the original designers of the machine.
                </p>
                <p>
                  A data analyst can easily create a model based on external observation of a machine and can develop
                  multiple models based on the user’s needs.
                  The model considers the entire business scenario and generates contextual data for analysis and
                  prediction.
                </p>
                <p>
                  When the model detects a future problem or a future state of a machine, the user can prevent or
                  prepare
                  for them.
                  The user can use the predictive twin model to determine trends and patterns from the contextual
                  machine
                  data. The model helps to address business problems.
                </p>
              </dd>

              <dt>Twin Projections</dt>
              <dd>
                <p>
                  In twin projections, the predictions and the insights integrate with back-end business applications,
                  making IoT an integral part of business processes.
                  When projections are integrated with a business process, they can trigger a remedial business
                  workflow.
                </p>
                <p>
                  Prediction data offers insights into the operations of machines. Projecting these insights into the
                  back-end applications infrastructure enables business applications to interact with the IoT system and
                  transform into intelligent systems.
                </p>
              </dd>

              <dt>Gaps</dt>
              <dd>WoT does not define a way to describe the behavior of a thing to use for a simulation.</dd>
            </dl>
          </dd>
        </dl>
      </section>

      <section id="UC-digital-twin-2"><div class="header-wrapper"><h4 id="x4-4-2-digital-twin-2"><bdi class="secno">4.4.2 </bdi>Digital Twin (2)</h4><a class="self-link" href="#UC-digital-twin-2" aria-label="Permalink for Section 4.4.2"></a></div> 
        
        <dl>
          <dt>Submitter(s)</dt>
          <dd>
            Qing An
          </dd>
          <dt>Category</dt>
          <dd>
            horizontal
          </dd>
          <dt>Target Users</dt>
          <dd>
            Digital twin involves managing a physical device or a group of connected physical devices which needs to be
            virtually represented, and whose data needs to be understood.
            Stakeholders include:
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-29">Device Owners</a>: need to make data from devices available to digital twin system.</li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-28">Device User</a>: users of the digital twin system are indirectly using the devices by accessing their data
                generated by the devices and sent to the digital twin, and also, by sending commands to the digital twin
                and corresponding actions can be automatically invoked on the device.</li>
              <li>cloud or edge provider: the digital twin system may be hosted in the cloud or in the edge.</li>
            </ul>
          </dd>
          <dt>Motivation</dt>
          <dd>
            A digital twin is a virtual and digital representation, located in the cloud or in the edge, of a real-world
            entity or system that mirrors a unique physical object, or a group of connected physical devices.
            Simply by describing a single device’s functionalities is not enough to support the accurate virtual
            representation in the cloud or edge. To accurately simulate the physical entity or system, the real-time
            status of device, the relation and rules among a collection of connected devices need be standardized.
          </dd>
          <dt>Expected Devices</dt>
          <dd>
            Devices can include sensors, actuators, machines, vehicles, production lines, industry robots.
            Cloud or edge, to host the digital twin.
          </dd>
          <dt>Expected Data</dt>
          <dd>
            Device status information, discrete sensor data.
            Device relation information, indicating one device’s relation with other devices in a group of connected
            devices, and what-if rules.
          </dd>
          <dt>Dependencies - Affected WoT deliverables and/or work items</dt>
          <dd>
            WoT Thing Description and Thing Model, WoT Architecture
          </dd>
          <dt>Description</dt>
          <dd>
            By virtually represent the devices and understand their data in context, a digital twin can reflect, in a
            timely manner across life cycle, the state of the devices based on the historical data and real-time device
            data.
            Based on the virtual representation, further services can be provided, like real-time troubleshooting,
            simulation and prediction.
          </dd>
          <dt>Gaps</dt>
          <dd>
            WoT does not define a way to describe the relationship and behavior of connected things to use for a
            simulation.
          </dd>
        </dl>
      </section>
    </section>

    <section id="UC-cross-protocol-interworking-1"><div class="header-wrapper"><h3 id="x4-5-cross-protocol-interworking"><bdi class="secno">4.5 </bdi>Cross Protocol Interworking</h3><a class="self-link" href="#UC-cross-protocol-interworking-1" aria-label="Permalink for Section 4.5"></a></div> 
      
      <dl>
        <dt>Submitter(s)</dt>
        <dd>

          Michael Lagally

        </dd>
        <dt>Target Users</dt>
        <dd>

          <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-30">Device Owners</a>, <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-16">Cloud Providers</a>.

        </dd>
        <dt>Motivation</dt>
        <dd>

          In smart city, home and industrial scenarios various devices are connected to a common network. These
          devices implement different protocols. To enable interoperability, an "agent" needs to communicate across
          different protocols. Platforms for this agent can be edge devices, gateways or cloud services.

          Interoperability across protocols is a must for all user scenarios that integrate devices from more than
          one protocol.

        </dd>
        <dt>Expected Devices</dt>
        <dd>

          Various sensors, e.g. temperature, light, humidity, vibration, noise, air quality, edge devices, gateways,
          cloud servers and services.

        </dd>
        <dt>Expected Data</dt>
        <dd>

          Discrete sensor values, such as temperature, light, humidity, vibration, noise, air quality readings.
          A/V streams.
          The data can be delivered periodically or on demand.

        </dd>
        <dt>Dependencies</dt>
        <dd>

          WoT Profiles.

        </dd>
        <dt>Description</dt>
        <dd>
          <p>
            There are multiple user scenarios that are addressed by this use case.
          </p>
          <p>
            An example in the smart home environment is an automatic control lamps, air conditioners, heating, window
            blinds in a household
            based on sensor data, e.g. sunlight, human presence, calendar and clock, etc.
          </p>
          <p>
            In an industrial environment individual actuators and production devices use different protocols.
            Examples include MQTT [<cite><a class="bibref" data-link-type="biblio" href="#bib-mqtt" title="MQTT Version 3.1.1 Plus Errata 01">MQTT</a></cite>], OPC UA [<cite><a class="bibref" data-link-type="biblio" href="#bib-opc ua" title="OPC Unified Architecture">OPC UA</a></cite>], Modbus [<cite><a class="bibref" data-link-type="biblio" href="#bib-modbus" title="Modbus">Modbus</a></cite>], Fieldbus, and others.
            Gathering data from these devices, e.g. to support digital twins or big data use cases requires an "Agent"
            to bridge across these protocols.
            To provide interoperability and to reduce implementation complexity of this agent a common set of (minimum
            and maximum)
            requirements need to be supported by all interoperating devices.
          </p>
          <p>
            A smart city environment is similar to the industrial scenario in terms of device interoperability.
            Devices differ however,
            they include smart traffic lights, traffic monitoring, people counters, cameras.
          </p>
        </dd>
        

        <dt>Gaps</dt>
        <dd>

          A common profile across protocols is required to address this use case.

        </dd>
        <dt>Existing Standards</dt>
        <dd>

          MQTT [<cite><a class="bibref" data-link-type="biblio" href="#bib-mqtt" title="MQTT Version 3.1.1 Plus Errata 01">MQTT</a></cite>], OPC-UA [OPC UA], BACNet [<cite><a class="bibref" data-link-type="biblio" href="#bib-bacnet" title="BACnet">BACnet</a></cite>], CoAP [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc7252" title="The Constrained Application Protocol (CoAP)">rfc7252</a></cite>], various other home and industrial protocols.
        </dd>
        
      </dl>
    </section>

    <section id="multimodal"><div class="header-wrapper"><h3 id="x4-6-multimodal-system-integration"><bdi class="secno">4.6 </bdi>Multimodal System Integration</h3><a class="self-link" href="#multimodal" aria-label="Permalink for Section 4.6"></a></div>
      
      <section id="UC-multimodal-recognition-support-1"><div class="header-wrapper"><h4 id="x4-6-1-multimodal-recognition-support"><bdi class="secno">4.6.1 </bdi>Multimodal Recognition Support</h4><a class="self-link" href="#UC-multimodal-recognition-support-1" aria-label="Permalink for Section 4.6.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael McCool
          </dd><dt>Category</dt>
          <dd>
            Accessibility
          </dd>
          <dt>Motivation</dt>
          <dd>

            Recognizer system development has arrived at a point of maturity where
            if we want to dramatically enhance recognition performance,
            sensor fusion from multiple modalities is needed.
            In order to achieve this,
            an image recognizer should incorporate results coming from other
            kinds of recognizers (e.g. audio recognizer) within the network
            engaged in the same interaction cycle.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Audio sensing device (microphone).

            Video sensing device (camera).

            Audio recognition service.

            Video recognition service.

            Devices capable of presenting alerts in various modalities.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Command and status information transferred between the sensing devices,
            the recognition services, and the alert devices.

            Profile data for user preferences.

          </dd>
          <dt>Dependencies</dt>
          <dd>

            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
              <li>Optional: WoT Scripting API in application on mobile personal device and possibly
                in IoT orchestration services.</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>

            An audio recognizer has been trained with the more common sounds in the house,
            in order to provide alerts in case of an emergency.
            In the same house a security system uses a video recognizer to identify people
            at the front door.
            These two systems need to cooperate with a remote home management system
            to provide integrated services.

          </dd>
          

          
          <dt>Gaps</dt>
          <dd>

            Support for video and audio recognition services.

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            This use case is based on MMI UC 5.1 [<cite><a class="bibref" data-link-type="biblio" href="#bib-mmi-use-cases" title="Multimodal Interaction Use Cases">mmi-use-cases</a></cite>].

          </dd>
          <dt>Comments</dt>
          <dd>

            Does not include Requirements section from original MMI use case.
          </dd>
        </dl>
      </section>
      <section id="UC-enhancement-of-synergistic-interactions-1"><div class="header-wrapper"><h4 id="x4-6-2-enhancement-of-synergistic-interactions"><bdi class="secno">4.6.2 </bdi>Enhancement of Synergistic Interactions</h4><a class="self-link" href="#UC-enhancement-of-synergistic-interactions-1" aria-label="Permalink for Section 4.6.2"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael McCool

          </dd>

          <dt>Category</dt>
          <dd>

            Accessibility

          </dd>
          <dt>Motivation</dt>
          <dd>

            One of the main indicators concerning the usability of a system
            is the corresponding level of accessibility provided by it.
            The opportunity for all the users to receive and to deliver all kinds of information,
            regardless of the information format or the type of user profile,
            state or impairment is a recurrent need in web applications.
            One of the means to achieve accessibility is the design of a more
            synergic interaction based on the discovery of multimodal Modality Components.

            Synergy is two or more entities functioning together to produce a result
            that is not obtainable independently.
            It means "working together".
            For example,
            how to avoid disruptive interactions
            in nomadic systems (always affected by the changing context)
            is an important issue.
            In these applications,
            user interaction is difficult,
            distracted and less precise.
            Discovery and use of alternative input and output devices
            can increase synergic interaction offering new possibilities
            more adapted to the current context.
            Such a system can also enhance the fusion process for target groups of
            users experiencing permanent or temporary learning difficulties or with sensorial,
            emotional or social impairments.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            A normal client computer with I/O devices that need to be emulated.

            Alternative I/O devices that need to be interfaced to the client system.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Command and status information transferred between the client computer
            and the alternative I/O devices.

            Profile data for user preferences.

          </dd>
          <dt>Dependencies</dt>
          <dd>

            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
              <li>Optional: WoT Scripting API in application on mobile personal device and possibly
                in IoT orchestration services.</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>
            A person working mostly with a PC is having a problem with their right arm and hands.
            They are unable to use a mouse or a keyboard for a few months.
            They can point at things, sketch, clap, make gestures, but they can not make any precise movements.
            A generic interface allows this person to perform their most important tasks in their
            personal devices:
            to call someone, open a mailbox, access his agenda or navigate over some Web pages.
            The generic interface can propose child-oriented intuitive interfaces like a
            clapping-based interface,
            a very articulated TTS component, or reduced gesture input widgets.
            Other specialized devices might include phones with very big numbers,
            very simple remote controls,
            screens displaying text at high resolution,
            or voice command devices.
          </dd>
          

          
          <dt>Existing Standards</dt>
          <dd>

            This use case is based on MMI UC 5.2 [<cite><a class="bibref" data-link-type="biblio" href="#bib-mmi-use-cases" title="Multimodal Interaction Use Cases">mmi-use-cases</a></cite>].

          </dd>
          <dt>Comments</dt>
          <dd>

            Does not include Requirements section from original MMI use case.
          </dd>
        </dl>
      </section>
    </section>

    <section id="accessibility"><div class="header-wrapper"><h3 id="x4-7-accessibility"><bdi class="secno">4.7 </bdi>Accessibility</h3><a class="self-link" href="#accessibility" aria-label="Permalink for Section 4.7"></a></div>
      
      <section id="UC-audiovisual-devices-acting-as-smartphone-extensions-1"><div class="header-wrapper"><h4 id="x4-7-1-audiovisual-devices-acting-as-smartphone-extensions"><bdi class="secno">4.7.1 </bdi>Audiovisual Devices Acting as Smartphone Extensions</h4><a class="self-link" href="#UC-audiovisual-devices-acting-as-smartphone-extensions-1" aria-label="Permalink for Section 4.7.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael McCool

          </dd>
          <dt>Category</dt>
          <dd>
            Accessibility
          </dd>
          <dt>Motivation</dt>
          <dd>
            <p>
              Many of today's home IoT-enabled devices can provide similar functionality
              (e.g. audio/video playback),
              differing only in certain aspects of the user interface.
              This use case would allow continuous interaction with a specific
              application as the user moves from room to room,
              with the user interface switched automatically to the set of
              devices available in the user's present location.
            </p>
            <p>
              On the other hand,
              some devices can have specific capabilities
              and user interfaces that can be used to add information to a larger context
              that can be reused by other applications and devices.
              This drives the need to spread an application across different devices
              to achieve a more user-adapted and meaningful interaction according to the
              context of use.
              Both aspects provide arguments for exploring use cases where
              applications use distributed multimodal interfaces.
            </p>
          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Mobile phone or other client running an application requiring a extended and
            more accessible user interface.

            IoT-enabled audio-visual devices providing audio and visual information
            display capabilities that can be used to augment the user interface of the
            application.

            Possible edge computation services providing speech-to-text or described video
            (e.g. object detection) capabilities.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Visual display information mapping information from audio to visual modalities,
            for example text generated from voice recognition.

            Text from an application that needs to be displayed at a larger size.

            Visual alerts corresponding to audio stimuli, e.g. sound effects in a game mapped
            to visual icons.

            Visual information mapped to audio information, for example,
            described video based on an AI service providing object recognition.

          </dd>
          <dt>Dependencies</dt>
          <dd>

            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
              <li>Optional: WoT Scripting API accessible from application for interacting
                with devices.</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>

            A home entertainment system is adapted by a mobile device
            as a set of user interface components.

            In addition to media rendering and playback,
            these Devices also act as input or output modalities for
            an application, for example an application running on a smartphone.
            The native user interface on the application
            does not have to be manipulated directly at all.
            A wall-mounted touch-sensitive TV could be used to navigate applications,
            and a wide-range microphone can handle speech input.
            Spatial (Kinect-style) gestures may also be used to control
            application behavior.

            Accessibility support software on the smartphone
            discovers available modalities and arranges them to best
            serve the user's purpose.
            One display can be used to show photos and movies,
            another for navigation.
            As the user walks into another room,
            this configuration is adapted dynamically to the new location.
            User intervention may be sometimes required to decide on
            the most convenient modality configuration.
            The state of the interaction is maintained
            while switching between modality sets.
            For example,
            if the user was navigating a GUI menu in the living room,
            it is carried over to another screen when they switch rooms,
            or replaced with a different modality such as voice
            if there are no displays in the new location.

          </dd>
          <dt>Variants</dt>
          <dd>

            Modalities may be translated from one form to another to accommodate
            accessibility issues, for example, visual cues into audio cues and
            vice-versa, as appropriate.

          </dd>
          <dt>Gaps</dt>
          <dd>

            An AI service may be require to perform modality mapping, for example,
            object recognition.

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            This use case is based on MMI UC 1.1 [<cite><a class="bibref" data-link-type="biblio" href="#bib-mmi-use-cases" title="Multimodal Interaction Use Cases">mmi-use-cases</a></cite>].

          </dd>
          <dt>Comments</dt>
          <dd>

            Does not include Requirements section from original MMI use case.
            Variant supporting
            modality conversion is not included in the original MMI use case.
          </dd>
        </dl>
      </section>
      <section id="UC-unified-smart-home-control-and-status-interface-1"> 

          
          <dt>Motivation</dt>
          <dd>
            <p>
            The increase in the number of controllable devices in an
            intelligent home creates a problem with controlling all available services
            in a coherent and useful manner.
            Having a shared context,
            built from information collected through sensors and direct user input,
            would improve recognition of user intent, and thus simplify interactions.
          </p><p>
            In addition,
            multiple input mechanisms could be selected by the user based on device type,
            level of trust and the type of interaction required for a particular task.
            </p>
          </dd>
          <dt>Expected Devices</dt>
          <dd>

            Mobile phone or other client running an application providing command
            mediation capabilities.

            IoT-enabled smart home devices supporting
            remote sensing and actuation functionality.

          </dd>
          <dt>Expected Data</dt>
          <dd>

            Command and status information transferred between the command mediation
            application and one or more devices.

          </dd>
          <dt>Dependencies</dt>
          <dd>

            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Discovery</li>
              <li>Optional: WoT Scripting API accessible from application for interacting
                with devices.</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>
            <p>
              Smart home functionality (window blinds, lights, air conditioning etc.)
              is controlled through a multimodal interface,
              composed from modalities built into the house itself
              (e.g. speech and gesture recognition)
              and those available on the user's personal devices
              (e.g. smartphone touchscreen).
              The system may automatically adapt to the preferences of a specific user,
              or enter a more complex interaction if multiple people are present.
            </p>
            <p>
              Sensors built into various devices around the house can act as input
              modalities that feed information to the home and affect its behavior.
              For example,
              lights and temperature in the gym room can be adapted dynamically
              as workout intensity recorded by the fitness equipment increases.
              The same data can also increase or decrease volume and tempo of music tracks
              played by the user's mobile device or the home's media system.
            </p>
          </dd>
          <dt>Variants</dt>
          <dd>

            The intelligent home in tandem with the user's personal
            devices can additionally monitor user behavior for emotional patterns
            such as 'tired' or 'busy' and adapt further.

          </dd>
          <dt>Gaps</dt>
          <dd>

            A service may be needed to recognize gestures and emotional states.

          </dd>
          <dt>Existing Standards</dt>
          <dd>

            This use case is based on MMI UC 1.2 [<cite><a class="bibref" data-link-type="biblio" href="#bib-mmi-use-cases" title="Multimodal Interaction Use Cases">mmi-use-cases</a></cite>]; original title was Intelligent Home Apparatus.

          </dd>
          <dt>Comments</dt>
          <dd>

            Does not include Requirements section from original MMI use case.
          </dd>
        
      </section>
    </section>

    <section id="Security"><div class="header-wrapper"><h3 id="x4-8-security"><bdi class="secno">4.8 </bdi>Security</h3><a class="self-link" href="#Security" aria-label="Permalink for Section 4.8"></a></div>
      
      <section id="UC-oauth2-flows-1"><div class="header-wrapper"><h4 id="x4-8-1-oauth2-flows"><bdi class="secno">4.8.1 </bdi>OAuth2 Flows</h4><a class="self-link" href="#UC-oauth2-flows-1" aria-label="Permalink for Section 4.8.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael McCool, Cristiano Aguzzi

          </dd>
          <dt>Target Users</dt>
          <dd>

            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-31">Device Owner</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-29">Device User</a></li>
              <li>device application</li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-23">Service Provider</a></li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-15">Identity Provider</a></li>
              <li>directory service</li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>
            <p>OAuth 2.0 is an authorization protocol widely known for its usage across several web services.
              It enables third-party applications to obtain limited access to HTTP services on behalf of the resource
              owner
              or of itself.
              The protocol defines the following actors:</p>

            <ul>
              <li>Client: an application that wants to use a resource owned by the resource owner. </li>
              <li>Authorization Server: An intermediary that authorizes the client for a particular <code>scope</code>. </li>
              <li>Resource: a web resource </li>
              <li>Resource Server: the server where the resource is stored</li>
              <li>Resource Owner: the owner of a particular web resource. If it is a human is usually referred to as an
                end-user. More specifically from the RFC:
                <ul>
                  <li>An entity capable of granting access to a protected resource.</li>
                </ul>
              </li>
            </ul>
            <p>These actors can be mapped to WoT entities:</p>
            <ul>
              <li>Client is a WoT Consumer</li>
              <li>Authorization Server is a third-party service</li>
              <li>Resource is an interaction affordance</li>
              <li>Resource Server is a Thing described by a Thing Description acting as a server.
                May be a device or a service.</li>
              <li>Resource Owner might be different in each use case.
                A Thing Description may also combine resources from different owners or web server.</li>
            </ul>
            <p>TO DO: Check the OAuth 2.0 spec to determine exactly how Resource Owner is defined.
              Is it the actual owner of the resource (e.g. running the web server) or simply someone
              with the rights to access that resource?</p>
            <p>The OAuth 2.0 protocol specifies an authorization layer that separates the client from the resource
              owner.
              The basic steps of this protocol are summarized in the following diagram:</p>
            <pre aria-busy="false"><code class="hljs">+--------+                               +---------------+
|        |--(A)- Authorization Request -&gt;|   Resource    |
|        |                               |     Owner     |
|        |&lt;-(B)-- Authorization Grant ---|               |
|        |                               +---------------+
|        |
|        |                               +---------------+
|        |--(C)-- Authorization Grant --&gt;| Authorization |
| Client |                               |     Server    |
|        |&lt;-(D)----- Access Token -------|               |
|        |                               +---------------+
|        |
|        |                               +---------------+
|        |--(E)----- Access Token ------&gt;|    Resource   |
|        |                               |     Server    |
|        |&lt;-(F)--- Protected Resource ---|               |
+--------+                               +---------------+</code></pre>
            <p>Steps A and B defines what is known as authorization grant type or flow.
              What is important to realize here is that not all of these interactions
              are meant to take place over a network protocol.
              In some cases,
              interaction with with a human through a user interface may be intended.

              OAuth2.0 defines 4 basic flows plus an extension mechanism.
              The most common of which are:</p>
            <ul>
              <li><code>code</code></li>
              <li><code>implicit</code></li>
              <li><code>password</code> (of resource owner)</li>
              <li><code>client</code> (credentials of the client)</li>
            </ul>

            <p>In addition, a particular extension which is of interest to IoT is the <code>device</code> flow.

              Further information about the OAuth 2.0 protocol can be found in
              <a href="https://tools.ietf.org/html/rfc6749#section-1">IETF RFC6749</a>.
              In addition to the flows, OAuth 2.0 also supports scopes.
              Scopes are identifiers which can be attached to tokens.
              These can be used to limit authorizations to
              particular roles or actions in an API.
              Each token carries a set of scopes and these can be checked when an interaction
              is attempted and access can be denied if the token does not include a scope
              required by the interaction.

              This document describes relevant use cases for each of the OAuth 2.0 authorization flows.
            </p>
          </dd>

          <dt>Expected Devices</dt>
          <dd>
            To support OAuth 2.0, all devices must have the capability of:
            <ul>
              <li>Both the producer and consumer must be able to create and participate in a TLS connection.</li>
              <li>The producer must be able to verify an access (bearer) token (i.e. have sufficient computational
                power/connectivity). </li>
            </ul>
          </dd>
          <dd>
            Constrained devices can be covered by this use-case by implementing
            the authentication and authorization framework ACE-OAuth specified
            in [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc9200" title="Authentication and Authorization for Constrained Environments Using the OAuth 2.0 Framework (ACE-OAuth)">RFC9200</a></cite>].
            ACE-OAuth adapts OAuth 2.0 concepts to constrained environments with
            the help of so-called profiles, which, for instance, enable the use
            of CoAP with DTLS [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc9202" title="Datagram Transport Layer Security (DTLS) Profile for Authentication and Authorization for Constrained Environments (ACE)">RFC9202</a></cite>] or OSCORE [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc9203" title="The Object Security for Constrained RESTful Environments (OSCORE) Profile of the Authentication and Authorization for Constrained Environments (ACE) Framework">RFC9203</a></cite>].
            However, the framework is also adaptable to other protocols such as
            MQTT [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc9431" title="Message Queuing Telemetry Transport (MQTT) and Transport Layer Security (TLS) Profile of Authentication and Authorization for Constrained Environments (ACE) Framework">RFC9431</a></cite>] by using a dedicated profile.
          </dd>
          <dt>Expected Data</dt>
          <dd>
            Depending on the OAuth 2.0 flow specified, various URLs and elements need to be specified,
            for example, the location of an authorization token server.
            OAuth 2.0 is also based on bearer tokens and so
            needs to include the same data as those, for example, expected encryption suite.
            Finally,
            OAuth 2.0 supports scopes so these need to be defined in the security scheme and specified in
            the form.

          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            Thing Description, Scripting API, Discovery, and Security.

          </dd>
          <dt>Description</dt>
          <dd>

            A general use case for OAuth 2.0 is when a WoT consumer wants to access restricted interaction
            affordances.
            In particular, when those affordances have a specific resource owner which
            may grant some temporary permissions to the consumer.

            The WoT consumer can either be hosted in a remote device or interact directly with the end-user inside an
            application.

          </dd>
          <dt>Variants</dt>
          <dd>
            <p>For each OAuth 2.0 flow, there is a corresponding use case variant.
              We also include the experimental "device" flow for consideration.</p>

            <p><strong>code</strong></p>
            <p>A natural application of this protocol is when the end-user wants to interact directly with the consumed
              thing or to grant their authorization to a remote device. In fact from the <a href="https://tools.ietf.org/html/rfc6749#section-4.1">RFC6749</a></p>
            <ul>
              <li>
                Since this is a redirection-based flow, the client must be capable of
                interacting with the resource owner's user-agent (typically a web
                browser) and capable of receiving incoming requests (via redirection)
                from the authorization server.
              </li>
            </ul>

            <p>This implies that the code flow can be only used when the resource owner interacts directly with the WoT
              consumer at least once. Typical scenarios are:</p>
            <ul>
              <li>In a home automation context, a <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-32">Device Owner</a> uses a third party software to interact
                with/orchestrate one or more devices</li>
              <li>Similarly, in a smart farm, the <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-33">Device Owner</a> might delegate its authorization to third party
                services.</li>
              <li>In a smart home scenario, Thing Description Directories might be deployed using this authorization
                mechanism. In particular, the list of the registered TDs might require an explicit read authorization
                request to the <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-34">Device Owner</a> (i.e. an human who has bought the device and installed it). </li>
              <li>... </li>
            </ul>

            <p>The following diagram shows the steps of the protocol adapted to WoT idioms and entities. In this
              scenario, the WoT Consumer has read the Thing Description of a Remote Device and want to access one of its
              WoT Affordances protected with OAuth 2.0 code flow.</p>
            <pre aria-busy="false"><code class="hljs yaml">                                                 <span class="hljs-string">+-----------+</span>
  <span class="hljs-string">+----------+</span>                                   <span class="hljs-string">|</span>           <span class="hljs-string">|
  | Resource |                                   |  Remote   |
  |   Owner  |                                   |  Device   +&lt;-------+
  |          |                                   |           |        |
  +----+-----+                                   +-----------+        |
       ^                                                              |
       |                                                              |
      (B)                                                             |
</span><span class="hljs-string">+------------+</span>          <span class="hljs-string">Client</span> <span class="hljs-string">Identifier</span>      <span class="hljs-string">+---------------+</span>      <span class="hljs-string">|</span>
<span class="hljs-string">|</span>           <span class="hljs-string">------(A)--</span> <span class="hljs-string">&amp;</span> <span class="hljs-string">Redirection</span> <span class="hljs-string">URI</span> <span class="hljs-string">----&gt;+</span>               <span class="hljs-string">|</span>      <span class="hljs-string">|</span>
<span class="hljs-string">|</span>   <span class="hljs-string">User-</span>    <span class="hljs-string">|</span>                                 <span class="hljs-string">|</span> <span class="hljs-string">Authorization</span> <span class="hljs-string">|</span>      <span class="hljs-string">|</span>
<span class="hljs-string">|</span>   <span class="hljs-string">Agent</span>   <span class="hljs-string">------(B)--</span> <span class="hljs-string">User</span> <span class="hljs-string">authenticates</span> <span class="hljs-string">---&gt;+</span>     <span class="hljs-string">Server</span>    <span class="hljs-string">|</span>      <span class="hljs-string">|</span>
<span class="hljs-string">|</span>            <span class="hljs-string">|</span>                                 <span class="hljs-string">|</span>               <span class="hljs-string">|</span>      <span class="hljs-string">|</span>
<span class="hljs-string">|</span>           <span class="hljs-string">------(C)--</span> <span class="hljs-string">Authorization</span> <span class="hljs-string">Code</span> <span class="hljs-string">---&lt;+</span>               <span class="hljs-string">|</span>      <span class="hljs-string">|</span>
<span class="hljs-string">+---+----+---+</span>                                 <span class="hljs-string">+---+------+----+</span>      <span class="hljs-string">|
    |    |                                         ^      v           |
</span>   <span class="hljs-string">(A)</span>  <span class="hljs-string">(C)</span>                                        <span class="hljs-string">|</span>      <span class="hljs-string">|</span>           <span class="hljs-string">|
    |    |                                         |      |           |
    ^    v                                         |      |           |
</span><span class="hljs-string">+---+----+---+</span>                                     <span class="hljs-string">|</span>      <span class="hljs-string">|</span>           <span class="hljs-string">|</span>
<span class="hljs-string">|</span>            <span class="hljs-string">|&gt;-+(D)--</span> <span class="hljs-string">Authorization</span> <span class="hljs-string">Code</span> <span class="hljs-string">---------'</span>      <span class="hljs-string">|</span>           <span class="hljs-string">|</span>
<span class="hljs-string">|</span>    <span class="hljs-string">WoT</span>     <span class="hljs-string">|</span>         <span class="hljs-string">&amp;</span> <span class="hljs-string">Redirection</span> <span class="hljs-string">URI</span>                  <span class="hljs-string">|</span>           <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">Consumer</span>  <span class="hljs-string">|</span>                                            <span class="hljs-string">|</span>           <span class="hljs-string">|</span>
<span class="hljs-string">|</span>            <span class="hljs-string">|&lt;-+(E)-----</span> <span class="hljs-string">Access</span> <span class="hljs-string">Token</span> <span class="hljs-string">-------------------'</span>           <span class="hljs-string">|</span>
<span class="hljs-string">+-----+------+</span>      <span class="hljs-string">(w/</span> <span class="hljs-string">Optional</span> <span class="hljs-string">Refresh</span> <span class="hljs-string">Token)</span>                       <span class="hljs-string">|
      v                                                               |
      |                                                               |
      +-----------(F)----- Access WoT --------------------------------+
                           Affordance</span></code></pre>
            <p>Notice that steps (A), (B) and (C) are broken in two parts as they pass through the User-Agent.</p>

            <p><strong>device</strong></p>
            <p>The device flow (IETF <a href="https://tools.ietf.org/html/rfc8628">RFC 8628</a>) is a variant of the
              code
              flow for browserless and
              input-constrained devices. Similarly, to its <i>parent</i> flow, it requires a close interaction between
              the
              resource owner and the WoT consumer. Therefore, the use cases for this flow are the same as the code
              authorization grant but restricted to all devices that do not have a rich means to interact with the
              resource owner. However, differently from <code>code</code>, RFC 8628 states explicitly that one of the actors of
              the protocol is an <b>end-user</b> interacting with a <b>browser</b> (even if <a href="https://tools.ietf.org/html/rfc8628#section-6.2">section-6.2</a>
              briefly describes an authentication using a companion app and BLE), as shown in the following (slightly
              adapted) diagram:</p>p&gt;

            <pre aria-busy="false"><code class="hljs yaml"><span class="hljs-string">+----------+</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">Remote</span>  <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">Device</span>  <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>
<span class="hljs-string">+----^-----+</span>
     <span class="hljs-string">|
     | (G) Access WoT Affordance
     |
</span><span class="hljs-string">+----+-----+</span>                                <span class="hljs-string">+----------------+</span>
<span class="hljs-string">|</span>          <span class="hljs-string">+&gt;---(A)--</span> <span class="hljs-string">Client</span> <span class="hljs-string">Identifier</span> <span class="hljs-string">---v+</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">+&lt;---(B)--</span> <span class="hljs-string">Device</span> <span class="hljs-string">Code,</span>      <span class="hljs-string">---&lt;+</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>          <span class="hljs-string">User</span> <span class="hljs-string">Code,</span>            <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>   <span class="hljs-string">WoT</span>    <span class="hljs-string">|</span>          <span class="hljs-string">&amp;</span> <span class="hljs-string">Verification</span> <span class="hljs-string">URI</span>    <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span> <span class="hljs-string">Consumer</span> <span class="hljs-string">|</span>                                <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>  [<span class="hljs-string">polling</span>]                     <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">+&gt;---(E)--</span> <span class="hljs-string">Device</span> <span class="hljs-string">Code</span>       <span class="hljs-string">---&gt;+</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>          <span class="hljs-string">&amp;</span> <span class="hljs-string">Client</span> <span class="hljs-string">Identifier</span>   <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                <span class="hljs-string">|</span>  <span class="hljs-string">Authorization</span> <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">+&lt;---(F)--</span> <span class="hljs-string">Access</span> <span class="hljs-string">Token</span>      <span class="hljs-string">---&lt;+</span>     <span class="hljs-string">Server</span>     <span class="hljs-string">|</span>
<span class="hljs-string">+-----+----+</span>   <span class="hljs-string">(&amp;</span> <span class="hljs-string">Optional</span> <span class="hljs-string">Refresh</span> <span class="hljs-string">Token)</span>   <span class="hljs-string">|</span>                <span class="hljs-string">|
      v                                     |                |
      :                                     |                |
</span>     <span class="hljs-string">(C)</span> <span class="hljs-string">User</span> <span class="hljs-string">Code</span> <span class="hljs-string">&amp;</span> <span class="hljs-string">Verification</span> <span class="hljs-string">URI</span>       <span class="hljs-string">|</span>                <span class="hljs-string">|
      :                                     |                |
      ^                                     |                |
</span><span class="hljs-string">+-----+----+</span>                                <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span> <span class="hljs-string">End</span> <span class="hljs-string">User</span> <span class="hljs-string">|</span>                                <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>    <span class="hljs-string">at</span>    <span class="hljs-string">+&lt;---(D)--</span> <span class="hljs-string">End</span> <span class="hljs-string">user</span> <span class="hljs-string">reviews</span>  <span class="hljs-string">---&gt;+</span>                <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">Browser</span> <span class="hljs-string">|</span>          <span class="hljs-string">authorization</span> <span class="hljs-string">request</span> <span class="hljs-string">|</span>                <span class="hljs-string">|</span>
<span class="hljs-string">+----------+</span>                                <span class="hljs-string">+----------------+</span></code></pre>
            <p>Notable mentions:</p>
            <ul>
              <li>the protocol is heavily end-user oriented. In fact, the RFC states the following
                <ul>
                  <li>Due to the polling nature of this protocol (as specified in Section 3.4), care is needed to avoid
                    overloading the capacity of the token endpoint. To avoid unneeded requests on the token endpoint,
                    the
                    client should only commence a device authorization request when <b>prompted by the user and not
                      automatically</b>, such as when the app starts or when the previous authorization session expires
                    or
                    fails.</li>
                </ul>
              </li>
              <li>TLS is required both between WoT Consumer/Authorization Server and between Browser/Authorization
                Server</li>
              <li>Other user interactions methods may be used but are left out of scope</li>
            </ul>

            <p><strong>client credential</strong></p>
            <p>The Client Credentials grant type is used by clients to obtain an access token outside of the context of
              an end-user. From <a href="https://tools.ietf.org/html/rfc6749#section-4.4">RFC6749</a>:</p>
            <ul>
              <li>The client can request an access token using only its client
                credentials (or other supported means of authentication) when
                the client is requesting access to the protected resources under its
                control, or <b>those of another resource owner that has been previously
                  arranged with the authorization server</b> (the method of which is beyond
                the scope of this specification).</li>
            </ul>

            <p>Therefore the client credential grant can be used:</p>
            <ul>
              <li>When the resource owner is a public authority. For example, in a smart city context, the authority
                provides a web service where to register an application id.</li>
              <li>Companion application</li>
              <li>Industrial IoT. Consider a smart factory where the devices or services are provisioned with client
                credentials. </li>
              <li>...</li>
            </ul>

            <p>The Client Credentials flow is illustrated in the following diagram. Notice how the Resource Owner is not
              present.</p>

            <pre aria-busy="false"><code class="hljs yaml"><span class="hljs-string">+----------+</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">Remote</span>  <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">Device</span>  <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>
<span class="hljs-string">+----^-----+</span>
     <span class="hljs-string">|
     |  (C) Access WoT Affordance
     ^
</span><span class="hljs-string">+----+-----+</span>                                  <span class="hljs-string">+---------------+</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                  <span class="hljs-string">|</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">+&gt;--(A)-</span> <span class="hljs-string">Client</span> <span class="hljs-string">Authentication</span> <span class="hljs-string">---&gt;+</span> <span class="hljs-string">Authorization</span> <span class="hljs-string">|</span>
<span class="hljs-string">|</span>   <span class="hljs-string">WoT</span>    <span class="hljs-string">|</span>                                  <span class="hljs-string">|</span>     <span class="hljs-string">Server</span>    <span class="hljs-string">|</span>
<span class="hljs-string">|</span> <span class="hljs-string">Consumer</span> <span class="hljs-string">+&lt;--(B)----</span> <span class="hljs-string">Access</span> <span class="hljs-string">Token</span> <span class="hljs-string">---------&lt;+</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                  <span class="hljs-string">|</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                  <span class="hljs-string">+---------------+</span>
<span class="hljs-string">+----------+</span></code></pre>
            <p>Comment: Usually client credentials are distributed using an external service which is used by humans to
              register a particular application. For example, the <code>npm</code> cli has a companion dashboard where a developer
              requests the generation of a token that is then passed to the cli. The token is used to verify the
              publishing process of <code>npm</code> packages in the registry. Further examples are Docker cli and OpenId Connect
              Client Credentials.</p>

            <p><strong>implicit</strong></p>
            <p><b>Deprecated</b>
              From <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-15#section-2.1.2">OAuth 2.0
                Security Best Current Practice</a>:</p>
            <ul>
              <li>
                In order to avoid these issues, clients should not use the implicit
                grant (response type "token") or other response types issuing access
                tokens in the authorization response, unless access token injection
                in the authorization, response is prevented and the aforementioned
                token leakage vectors are mitigated.
              </li>
            </ul>

            <p>The RFC above suggests using <code>code</code> flow with Proof Key for Code Exchange (PKCE) instead.</p>
            <p>The implicit flow was designed for public clients typically implemented inside a browser (i.e. javascript
              clients). As the <code>code</code> is a redirection-based flow and it requires direct interaction with the resource's
              owner user-agent. However, it requires one less step to obtain a token as it is returned directly in the
              authentication request (see the diagram below).</p>
            <p>Considering the WoT context this flow is not particularly different from <code>code</code> grant and it can be used
              in the same scenarios.</p>
            <p>Comment: even if the <code>implicit</code> flow is deprecated existing services may still using it.</p>

            <pre aria-busy="false"><code class="hljs yaml"><span class="hljs-string">+----------+</span>
<span class="hljs-string">|</span> <span class="hljs-string">Resource</span> <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">Owner</span>   <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>
<span class="hljs-string">+----+-----+</span>
     <span class="hljs-string">^</span>
     <span class="hljs-string">|
    (B)
</span><span class="hljs-string">+----------+</span>          <span class="hljs-string">Client</span> <span class="hljs-string">Identifier</span>     <span class="hljs-string">+---------------+</span>
<span class="hljs-string">|</span>         <span class="hljs-string">------(A)--</span> <span class="hljs-string">&amp;</span> <span class="hljs-string">Redirection</span> <span class="hljs-string">URI</span> <span class="hljs-string">---&gt;+</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">User-</span>   <span class="hljs-string">|</span>                                <span class="hljs-string">|</span> <span class="hljs-string">Authorization</span> <span class="hljs-string">|</span>
<span class="hljs-string">|</span>  <span class="hljs-string">Agent</span>  <span class="hljs-string">------(B)--</span> <span class="hljs-string">User</span> <span class="hljs-string">authenticates</span> <span class="hljs-string">--&gt;+</span>     <span class="hljs-string">Server</span>    <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                <span class="hljs-string">|</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">+&lt;---(C)---</span> <span class="hljs-string">Redirection</span> <span class="hljs-string">URI</span> <span class="hljs-string">----&lt;+</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>          <span class="hljs-string">with</span> <span class="hljs-string">Access</span> <span class="hljs-string">Token</span>     <span class="hljs-string">+---------------+</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>            <span class="hljs-string">in</span> <span class="hljs-string">Fragment</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                <span class="hljs-string">+---------------+</span>
<span class="hljs-string">|</span>          <span class="hljs-string">+----(D)---</span> <span class="hljs-string">Redirection</span> <span class="hljs-string">URI</span> <span class="hljs-string">----&gt;+</span>   <span class="hljs-string">Web-Hosted</span>  <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>          <span class="hljs-string">without</span> <span class="hljs-string">Fragment</span>      <span class="hljs-string">|</span>     <span class="hljs-string">Client</span>    <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                <span class="hljs-string">|</span>    <span class="hljs-string">Resource</span>   <span class="hljs-string">|</span>
<span class="hljs-string">|</span>     <span class="hljs-string">(F)</span>  <span class="hljs-string">+&lt;---(E)-------</span> <span class="hljs-string">Script</span> <span class="hljs-string">---------&lt;+</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                <span class="hljs-string">+---------------+</span>
<span class="hljs-string">+-+----+---+</span>
  <span class="hljs-string">|</span>    <span class="hljs-string">|
 (A)  (G) Access Token
  |    |
  ^    v
</span><span class="hljs-string">+-+----+---+</span>                                   <span class="hljs-string">+----------+</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                   <span class="hljs-string">|</span>  <span class="hljs-string">Remote</span>  <span class="hljs-string">|</span>
<span class="hljs-string">|</span>   <span class="hljs-string">WoT</span>    <span class="hljs-string">+&gt;---------(H)--Access</span> <span class="hljs-string">WoT---------&gt;+</span>  <span class="hljs-string">Device</span>  <span class="hljs-string">|</span>
<span class="hljs-string">|</span> <span class="hljs-string">Consumer</span> <span class="hljs-string">|</span>               <span class="hljs-string">Affordance</span>          <span class="hljs-string">|</span>          <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>                                   <span class="hljs-string">+----------+</span>
<span class="hljs-string">+----------+</span></code></pre>

            <p><strong>resource owner password</strong></p>
            <p><b>Deprecated</b> From <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-15#section-2.1.2">OAuth 2.0 Security
                Best Current Practice</a>:</p>
            <ul>
              <li>The resource owner password credentials grant must not be used. This
                grant type insecurely exposes the credentials of the resource owner
                to the client. Even if the client is benign, this results in an
                increased attack surface (credentials can leak in more places than
                just the AS) and users are trained to enter their credentials in
                places other than the AS.</li>
            </ul>

            <p>For completeness the diagram flow is reported below.</p>

            <pre aria-busy="false"><code class="hljs yaml"> <span class="hljs-string">+----------+</span>
 <span class="hljs-string">|</span> <span class="hljs-string">Resource</span> <span class="hljs-string">|
 |  Owner   |
 |          |
 +----+-----+
      v
      |    Resource Owner
     (A) Password Credentials
      |
      v
</span><span class="hljs-string">+-----+----+</span>                                  <span class="hljs-string">+---------------+</span>
<span class="hljs-string">|</span>          <span class="hljs-string">+&gt;--(B)----</span> <span class="hljs-string">Resource</span> <span class="hljs-string">Owner</span> <span class="hljs-string">-------&gt;+</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>         <span class="hljs-string">Password</span> <span class="hljs-string">Credentials</span>     <span class="hljs-string">|</span> <span class="hljs-string">Authorization</span> <span class="hljs-string">|</span>
<span class="hljs-string">|</span>   <span class="hljs-string">WoT</span>    <span class="hljs-string">|</span>                                  <span class="hljs-string">|</span>     <span class="hljs-string">Server</span>    <span class="hljs-string">|</span>
<span class="hljs-string">|</span> <span class="hljs-string">Consumer</span> <span class="hljs-string">+&lt;--(C)----</span> <span class="hljs-string">Access</span> <span class="hljs-string">Token</span> <span class="hljs-string">---------&lt;+</span>               <span class="hljs-string">|</span>
<span class="hljs-string">|</span>          <span class="hljs-string">|</span>    <span class="hljs-string">(w/</span> <span class="hljs-string">Optional</span> <span class="hljs-string">Refresh</span> <span class="hljs-string">Token)</span>   <span class="hljs-string">|</span>               <span class="hljs-string">|</span>
<span class="hljs-string">+-----+----+</span>                                  <span class="hljs-string">+---------------+</span>
      <span class="hljs-string">|
      | (D) Access WoT Affordance
      |
</span> <span class="hljs-string">+----v-----+</span>
 <span class="hljs-string">|</span>  <span class="hljs-string">Remote</span>  <span class="hljs-string">|
 |  Device  |
 |          |
 +----------+</span></code></pre>

          </dd>
          <dt>Security Considerations</dt>
          <dd>

            See OAuth 2.0 security considerations in <a href="https://tools.ietf.org/html/rfc6749#section-10">RFC6749</a>.
            See also <a href="https://tools.ietf.org/html/rfc8628#section-5">RFC 8628 section 5</a> for <code>device</code> flow.

          </dd>
          
          <dt>Comments</dt>
          <dd>
            Notice that the OAuth 2.0 protocol is not an authentication protocol, however <a href="https://openid.net/connect/">OpenID</a> defines an authentication layer on top of OAuth 2.0.
          </dd>
        </dl>
      </section>
    </section>

    <section id="lifecycle"><div class="header-wrapper"><h3 id="x4-9-lifecycle"><bdi class="secno">4.9 </bdi>Lifecycle</h3><a class="self-link" href="#lifecycle" aria-label="Permalink for Section 4.9"></a></div>
      
      <section id="UC-device-lifecycle-1"><div class="header-wrapper"><h4 id="x4-9-1-device-lifecycle"><bdi class="secno">4.9.1 </bdi>Device Lifecycle</h4><a class="self-link" href="#UC-device-lifecycle-1" aria-label="Permalink for Section 4.9.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            Michael Lagally

          </dd>
          <dt>Target Users</dt>
          <dd>

            <a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-27">Device Manufacturer</a>, <a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-17">Gateway Manufacturer</a>, <a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-17">Cloud Provider</a>

          </dd>
          <dt>Motivation</dt>
          <dd>

            The architecture specification currently does not address lifecycle.

          </dd>
          
          
          <dt>Description</dt>
          <dd>

            Handle the entire device lifecycle:
            Define terminology for lifecycle states and transitions.

            <p>Actors (represent a physical person or group of persons (company))</p>
            Manufacturer
            <a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-24">Service Provider</a>
            Network Provider (potentially transparent for WoT use cases)
            <a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-35">Device Owner</a> (User)
            Others?

            <p>Roles:</p>
            Depending on the use case, an actor can have multiple roles,
            e.g. security maintainer.
            Roles can be delegated.

          </dd>
          <dt>Variants</dt>
          <dd>

            There are (at least) two different entities to consider:
            <ul>
              <li>Things / Devices</li>
              <li>Consumers, e.g. cloud services or gateways</li>
            </ul>

            In more complex use cases there are additional entities:
            <ul>
              <li>Intermediates</li>
              <li>Directories</li>
            </ul>

          </dd>
          <dt>Gaps</dt>
          <dd>

            The current architecture spec does not describe device lifecycle in detail.
            A common lifecycle model helps to clarify terminology and structures the discussion
            in different groups.
            Interaction of a device with other entities such as directories may introduce
            additional states and transitions.

          </dd>
          <dt>Existing Standards</dt>
          <dd>
            <ul>
              <li>WoT Security</li>
              <li>ETSI OneM2M</li>
              <li>OMA LwM2M</li>
              <li>OCF</li>
              <li>IEEE</li>
              <li>SIM cards / GSMA</li>
              <li>IETF</li>
              <li>Application Lifecycle (<abbr title="World Wide Web Consortium">W3C</abbr> Multimodal Interaction WG)</li>
            </ul>
          </dd>
          <dt>Comments</dt>
          <dd>
            All lifecycle contributions and discussion documents are available at:
            <a href="https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle">https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle</a>
            <br>
            <br>
            Documents that were created / discussed in the architecture TF.
            <ul>
              <li>Lifecycle comparisons:
                <a href="https://github.com/w3c/wot-architecture/blob/main/proposals/Device-lifecycle-comparisons.pdf">https://github.com/w3c/wot-architecture/blob/main/proposals/Device-lifecycle-comparisons.pdf</a>
              </li>
              <li>Lifecycle states:
                <a href="https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle/lifecycle-states.md">https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle/lifecycle-states.md</a>
              </li>
              <li>Draft lifecycle diagram:
                <a href="https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle/WoT-lifecycle-diagram.svg">
                  https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle/WoT-lifecycle-diagram.svg</a>
              </li>
              <li>Layered lifecycle:
                <a href="https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle/WoT-layered-lifecycle-diagram.svg">
                  https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle/WoT-layered-lifecycle-diagram.svg</a>
              </li>
              <li>System lifecycle:
                <a href="https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle/unified%20device%20lifecycle.svg">
                  https://github.com/w3c/wot-architecture/blob/main/proposals/lifecycle/unified%20device%20lifecycle.svg</a>
              </li>
              <li>IoT Security Bootstrapping:
                <a href="https://github.com/w3c/wot-security/blob/main/presentations/2020-03-16-Bootstrapping%20IoT%20Security%20-%20The%20IETF%20Anima%20and%20OPC-UA%20Recipes.pdf">https://github.com/w3c/wot-security/blob/main/presentations/2020-03-16-Bootstrapping%20IoT%20Security%20-%20The%20IETF%20Anima%20and%20OPC-UA%20Recipes.pdf</a>
              </li>
          </ul></dd>
        </dl>
      </section>
    </section>

    <section id="vr-ar"><div class="header-wrapper"><h3 id="x4-10-vr-ar"><bdi class="secno">4.10 </bdi>VR/AR</h3><a class="self-link" href="#vr-ar" aria-label="Permalink for Section 4.10"></a></div> 
      

      <section id="UC-ar-virtual-guide-1"><div class="header-wrapper"><h4 id="x4-10-1-ar-virtual-guide"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</h4><a class="self-link" href="#UC-ar-virtual-guide-1" aria-label="Permalink for Section 4.10.1"></a></div> 
        
        <dl>

          <dt>Submitter(s)</dt>
          <dd>

            <ul>
              <li>Rob Smith</li>
              <li>Kaz Ashimura</li>
            </ul>

          </dd>
          <dt>Target Users</dt>
          <dd>
            <ul>
              <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-36">Device Owners</a></li>
              <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-30">Device User</a></li>
              <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-18">Cloud Provider</a></li>
              <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-25">Service Provider</a></li>
              <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-28">Device Manufacturer</a></li>
              <li>network operator (potentially transparent for WoT use cases)</li>
              <li><a href="#dfn-stakeholder-identity-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-identity-provider-16">Identity Provider</a></li>
              <li>directory service operator</li>
            </ul>

          </dd>
          <dt>Motivation</dt>
          <dd>

            Using a wearable semi-transparent display,
            users can be guided by a virtual assistant through a physical area of interest with
            a rendered overlay to visualize events, annotate structures and other physical features,
            or visualize live and historical data associated with features of interest (which may or
            may not be at the same physical location as the sensor generating the data).
            An annotated map may provide additional geospatial guidance, including
            identification of landmarks, locations of devices. The system may also guide the
            user along a specific trajectory.

          </dd>
          <dt>Expected Devices</dt>
          <dd>

            <ul>
              <li>Wearable, semi-transparent head-mounted display</li>
              <li>Headphones for speakers for audio output</li>
              <li>Geopose and motion estimator (various technologies can be used)</li>
              
              <li>Data processor to integrate all data (including live an historical data and geopose),
                generate annotations for the display, and record/play scenes</li>
            </ul>

          </dd>
          <dt>Expected Data</dt>
          <dd>

            <ul>
              <li>3D Position, orientation, velocity, and acceleration of the user</li>
              <li>Corresponding geolocation information (latitude, longitude, altitude) for all features of interest,
                including
                but not limited to physical landmarks, roads and paths, and locations of sensor's measurement points.
              </li>
              <li>Timestamps to allow synchronization between the annotations and data streams and the user's movement
              </li>
            </ul>

          </dd>
          <dt>Affected WoT deliverables and/or work items</dt>
          <dd>

            <ul>
              <li>WoT Thing Description</li>
              <li>WoT Binding Templates</li>
              <li>WoT Discovery</li>
              <li>Optional: WoT Scripting API accessible from application for interacting with devices.</li>
            </ul>

          </dd>
          <dt>Description</dt>
          <dd>

            <ul>
              <li>The user can travel around a real space with guidance from virtually defined geospatial
                data projected on a head-mounted wearable display synchronized with the view of the physical
                environment.</li>
              <li>The wearable display can generate position and orientation (geopose) data so that the user's
                movement will be traced through the physical environment and can synchronized with virtual features.
              </li>
              <li>The user can control the video images provided by the system, based
                sensors attached the display system or other means of control (gestures, voice input, etc.)</li>
              <li>The technology should include synchronization of playback of stored video media and related
                sensors, displays, and devices as well as the display of geolocation information from the virtual map.
              </li>
              <li>Discovery of sensors should take into account the position and field of view of the user
                so that data can be retrieved only for the relevant features of interest.</li>
              <li>Discovery may additionally want to consider the motion (e.g. velocity) of the user to that
                data soon to come into view can be prefetched.</li>
              <li>Metadata for sensors needs to distinguish between the location of the device itself and the
                feature of interest it is measuring. For example, a camera might monitor traffic on a highway.
                The feature of interest is the location on the highway being monitored, while the location of the
                camera might be quite far away (e.g. mounted on top of a building).</li>
            </ul>

            See also the <a href="https://w3c.github.io/sdw/proposals/geotagging/webvmt/#virtualguide">Use Case
              description from the WebVMT Editor's draft</a>

          </dd>
          <dt>Variants</dt>
          <dd>
            <ul>
              <li>Two synchronized displays (for example, a phone and a headset) can offer greater insight and provide
                clearer
                guidance to the user by showing different views of the same location, e.g. a top-view map on the phone.
              </li>
              <li>A VR (virtual-only) implementation may also be used, with a rendered scene replacing the real scene.
                This may be applicable to contexts such as a Smart City dashboard where sensor information from data
                needs to be viewed in context without having to actually visit the site.</li>
              <li>The head-mounted semi-transparent display might be replaced in some contexts with a handheld display
                e.g. a phone or tablet. To be useful for AR however, such a device needs a back camera to simulate
                transparency
                and capture images of the real environment (optional for VR), and a way to determine its geolocation and
                orientation (geopose) relative to the environment.</li>
              <li>The head-mounted display may use a camera rather than being physically transparent.</li>
              <li>A microphone may be added for voice input, including voice commands. This avoid having to clutter the
                view with controls.</li>
              <li>A 3D camera (e.g. LIDAR) may be used to capture a view of the environment, which can be helpful to
                establish geopose and align annotations with real features of the environment.</li>
              <li>A virtual guide for a particular geographic location, e.g. a historical site, which visualises past
                events and buildings in AR, or allows remote users to explore in VR.</li>
              <li>A medical tool which allows a patient to describe their symptoms using AR, e.g. identify a painful
                area
                on their own body, which is also modelled as a 'map' to show internal features and display a treatment
                guide, including any WoT medical devices.</li>
              <li>A virtual controller for a city engineer to visualize utilities, e.g. electrical cables or water
                pipes,
                and control them. For example, a maintenance engineer could switch off an individual street lamp in
                order
                to replace the bulb using an AR menu displayed on that WoT-enabled lamppost.</li>
              <li>These mechanisms can also be used for video overlay in general. The technologies are related
                to the recording, playing, and distribution of video content when the data is stored.
                Playback of stored data and movements would be useful for simulation and debugging.</li>
            </ul>

          </dd>
          <dt>Security Considerations</dt>
          <dd>

            <ul>
              <li>If an AR systems is compromised it could be used to guide a user into a dangerous
                situation while hiding that fact from them, e.g. encouraging them to step over a drop.</li>
              <li>For the above reason the system should "fail gracefully" if there is any sign its integrity is
                compromised, and should implement mechanisms (e.g. signing) to detect tampering.
                Standards should be similar to other systems than can cause physical harm, e.g. automobiles.</li>
              <li>For a "simulated" transparent head-mounted display using a camera, the system should
                have a fail-safe supporting an unfiltered view, which should be automatic even if the processor
                crashes.</li>
              <li>For all systems the user should have a simple
                way (e.g. a single button push) of viewing "baseline reality".</li>
            </ul>

          </dd>
          <dt>Privacy Considerations</dt>
          <dd>

            <ul>
              <li>Systems that handle or display private data, e.g. medical applications, should respect the
                relevant regulations.</li>
              <li>Private data should not be retained by the device or used for purposes other than which it
                was provided. This includes the location of personal devices. To display information from another's
                personal device, permission needs to be explicitly granted by that person and this permission should
                be time and possibly space-limited.
              </li>
            </ul>

          </dd>
          <dt>Requirements</dt>
          <dd>
            <ul>
              <li>Geospatially aware discovery mechanisms that can discover features of interest close to the
                user.</li>
              <li>Geospatial filters for discovery that include a pyramid-shaped region representing the field of view
                of the user.
                Note: a basic cylindrical, spherical, or rectangular filter region can be used instead and then the
                irrelevant results filtered out, but this is less efficient than the filter itself supporting
                field-of-view
                queries.
              </li>
              <li>Geospatial data associate with the metadata for devices. Note that mobile devices may update their
                position more rapidly than a discovery service may be able to support. In this case the discovery
                service
                needs to take the velocity and last known position of the data source into account and compute
                a zone of uncertainty and return the metadata for sources that might possibly be in the field of view.
                For sources such as this with dynamic positions, the AR system may also communicate with data sources
                directly to determine their most recent geolocation.
              </li>
            </ul>

          </dd>
          <dt>Gaps</dt>
          <dd>
            <ul>
              <li>Geospatial queries for discovery.</li>
              <li>Standardized encodings of geospatial metadata in TDs.</li>
            </ul>

          </dd>
          
        </dl>
      </section>
    </section>

    <section id="UC-edge-computing-1"><div class="header-wrapper"><h3 id="x4-11-edge-computing"><bdi class="secno">4.11 </bdi>Edge Computing</h3><a class="self-link" href="#UC-edge-computing-1" aria-label="Permalink for Section 4.11"></a></div> 
      
      <dl>

        <dt>Submitter(s)</dt>
        <dd>

          Michael McCool

        </dd>
        <dt>Target Users</dt>
        <dd>
          Note: User should be "Stakeholder"
          <ul>
            <li><a href="#dfn-stakeholder-device-owner" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-owner-37">Device Owners</a> - may benefit from using edge computing for iot orchestration and compute offload</li>
            <li><a href="#dfn-stakeholder-device-user" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-user-31">Device User</a> - may benefit from reduced cost of devices that can use compute offload</li>
            <li><a href="#dfn-stakeholder-cloud-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-cloud-provider-19">Cloud Provider</a> - may provide fallback for local edge compute services</li>
            <li><a href="#dfn-stakeholder-service-provider" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-service-provider-26">Service Provider</a> - may provide edge computing service</li>
            <li><a href="#dfn-stakeholder-device-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-device-manufacturer-29">Device Manufacturer</a> - may lower cost of device by depending on compute offload</li>
            <li><a href="#dfn-stakeholder-gateway-manufacturer" class="internalDFN" data-link-type="dfn" id="ref-for-dfn-stakeholder-gateway-manufacturer-18">Gateway Manufacturer</a> - may provide edge computing host hardware</li>
            <li>network operator - may provide edge computing nodes</li>
            <li>directory service operator - provides means to discover edge computing nodes</li>
          </ul>
        </dd>
        <dt>Motivation</dt>
        <dd>

          <ul>
            <li>IoT devices are often designed to be inexpensive (so they can be used at scale),
              small (for ease of installation) and are often power-limited, for example needing to
              run off a battery. For all these reasons, they usually have severely limited on-board
              computational capabilities.</li>
            <li>For applications that require significant computation and/or memory, for example
              computer vision, machine learning, or autonomous navigation, offloading work to
              another computer on the network may be advantageous.</li>
            <li>Offloading to the cloud typically involves relatively long latencies and may also
              have privacy implications. Edge computing implies offloading to a more "local" compute
              node with lower latency and optionally under more direct control of the user (improving
              privacy). This can be important for control applications (e.g. in robotics), computer
              graphics (e.g., gaming), and for applications processing imagery (e.g., facial recognition).</li>

	    <li>For edge computing, "locality" is about network latency (and perhaps other properties,
	      such as connection reliability or bandwidth), but there may also be requirements
	      directly related to physical location, for example to satisfy regional privacy requirements.
	      In such cases, the geolocation of both the edge computer and the device using it
	      may be relevant.</li>

            <li>An edge computer is also a convenient place to run persistent computations such as
              IoT orchestration rules that need to be "always on". Such an IoT orchestration system,
              in addition to needing to read from sensors and send commands to actuators over the
              network, may also invoke computationally-intensive services (e.g. image recognition). An
              example would be a security system that when a motion sensor is tripped, runs a person
              detection computation, and if a person is detected when and where they should not be,
              sounds an alarm. The motion sensor and alarm can be IoT devices while the person
              detection is a computationally-intensive service.</li>
          </ul>

        </dd>
        <dt>Expected Devices</dt>
        <dd>
          <ul>
            <li>IoT devices with Thing Descriptions for use in IoT orchestrations.</li>
            <li>An edge computer providing one or more fixed or generic compute services.</li>
            <li>A directory or other discovery mechanism that allows IoT devices and edge computers to advertize their
              availability.</li>
          </ul>

        </dd>
        <dt>Expected Data</dt>
        <dd>

          <ul>
            <li>Thing descriptions for IoT devices</li>
            <li>Thing descriptions for compute services</li>
            <li>Compute service configurations, e.g container images, WASM code, scripts, ONNX files, etc.</li>
          </ul>

        </dd>
        <dt>Affected WoT deliverables and/or work items</dt>
        <dd>
          <ul>
            <li>WoT Discovery - needs to be designed to support services, not just physical devices.  May need to support geolocation.</li>
            <li>WoT Architecture - concept of Thing needs to be expanded to include computational services.</li>
            <li>WoT Scripting API - essential for programming IoT orchestrations.</li>
          </ul>
        </dd>
        <dt>Description</dt>
        <dd>

          The WoT architecture can provide an interesting approach to edge computing:
          <ul>
            <li>An IoT orchestration running in an edge computer can consume WoT Thing Descriptions
              in order to determine how to connect to IoT devices.</li>
            <li>Fixed services (e.g. person detection) and generic compute nodes (a service that would
              allow an arbitrary computation to be loaded onto it) can also advertise themselves using
              Thing Descriptions, allowing an IoT orchestrator to interface to devices and services
              in a uniform way. This also facilitates support for "virtual devices", e.g. using
              computer vision, audio recognition, or other forms of analytics in place of a physical sensor.</li>
            <li>WoT discovery can be used to find appropriate compute services for IoT devices to offload
              computationally demanding tasks to, assuming those services describe themselves with
              TDs and advertise their availability via WoT discovery mechanisms.</li>
          </ul>
        </dd>

        <dt>Variants</dt>

        <dd>
          <ul>
            <li>An edge computer can provide facilities either for general-purpose computation (e.g.
              loading and running a container image, script, etc.) or special-purpose fixed computations
              (e.g. object detection and tracking, person detection, etc.). General-purpose computation
              is more powerful but also is more difficult to make fully secure.</li>
            <li>An edge computation can be stateless (function as a service, FaaS) or stateful. It is easier
              to migrate stateless computations transparently to new compute hardware but state then
              needs to be provided by a separate service, e.g. a database, and it is harder to program.</li>
            <li>Edge computers may provide just IoT orchestration without significant computational
              ability, just compute offload, or both. Many more use cases can be unlocked by providing both.</li>
            <li>Persistent computation can be provided in various ways. Rather than actually running
              continuously, an edge computation might be event-driven, for example.</li>
            <li>Under discussion are various ways to integrate edge computation with the web execution environment,
              for example by extending web and service workers.</li>
          </ul>
        </dd>
        <dt>Security Considerations</dt>

        <dd>

          Edge compute services supporting the specification of generic computation has many security
          challenges. In addition to the challenges common to cloud computing, e.g. protecting "tenants"
          from seeing each other's activity, additional challenges arise if the edge computer is offering
          computation as an ad-hoc service. For example, there needs to be a way to project the edge
          computer from denial-of-service attacks.

          An edge computer may also need to be protected from physical attacks. There is also the
          possibility that an edge computer might be physically compromised so approaches such as
          isolated containers (protecting the contents from the edge computer's hypervisor), and/or
          validated boot, might be necessary in some circumstances.

        </dd>
        <dt>Privacy Considerations</dt>

        <dd>

          Edge computers can theoretically improve privacy since sensitive data can be processed "locally"
          without having to be transmitted to a remote site. This however is tempered by edge computer's
          greater vulnerability to physical attacks. To avoid offloading work to a malicious edge computer,
          some means of evaluating the trustworthiness of edge computers is needed.
        </dd>
        <dt>Gaps</dt>

        <dd>

          <ul>
            <li>Explicit support for WoT Things that are services.</li>
            <li>Sufficient abstraction capability (e.g. "interfaces") to support virtual devices.</li>
            <li>A mechanism to package and install edge computations that can use the WoT scripting API for
              orchestration.
            </li>
            <li>A general means to manage compute nodes to provide offload targets (e.g. a standardized
              TD template for compute services).</li>
          </ul>

        </dd>
        <dt>Existing Standards</dt>
        <dd>

          <ul>
            <li><a href="https://datatracker.ietf.org/doc/html/draft-irtf-t2trg-iot-edge-10">IoT Edge Challenges and
                Functions</a>, IETF Internet-Draft, Network Working Group, version 10, expires 18 March 2024.</li>
            <li><a href="https://www.iiconsortium.org/fog-and-edge-white-papers.htm">IIC/OpenFog</a>, Fog and Edge
              Computing White Papers</li>
            <li><a href="https://www.etsi.org/technologies/multi-access-edge-computing">ETSI MEC</a>, ETSI standards for
              Multiaccess Edge Computing </li>
          </ul>
        </dd>
        
      </dl>
    </section>

  
	  
  </section> 
    <section id="sec-use-case-categories"><div class="header-wrapper"><h2 id="x5-use-case-categories"><bdi class="secno">5. </bdi>Use Case Categories</h2><a class="self-link" href="#sec-use-case-categories" aria-label="Permalink for Section 5."></a></div>
      
      <p>The following categories group Use Cases that share a common property.
      In the definition of a User Story, use case categories can be cited as  
      motivations rather than (or in addition to) specific use cases.</p>


      <section id="CAT-Security-Public-Service"><div class="header-wrapper"><h3 id="x5-1-security-public-service"><bdi class="secno">5.1 </bdi>Security Public Service</h3><a class="self-link" href="#CAT-Security-Public-Service" aria-label="Permalink for Section 5.1"></a></div>
      
	<p>Provides a public service. Misuse can result in lack of support to other users.</p>
	<ul>  
      <li>
        Supporting Use Cases:
        <ul>
          <li>
            <a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a>
          </li>
          <li>
            <a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a>
          </li>
          <li>
            <a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a>
          </li>
        </ul>
      </li>
    </ul>
      </section>
	
	<section id="CAT-Security-Private-Information"><div class="header-wrapper"><h3 id="x5-2-security-private-information"><bdi class="secno">5.2 </bdi>Security Private Information</h3><a class="self-link" href="#CAT-Security-Private-Information" aria-label="Permalink for Section 5.2"></a></div>
	
	<p>Handles personal or confidential information. Misuse could disclose privately identifiable information (PII) or sensitive business information.</p> 
    <ul>  
      <li>
        Supporting Use Cases:
        <ul>
          <li>
            <a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a>
          </li>
          <li>
            <a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a>
          </li>
          <li>
            <a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a>
          </li>
        </ul>
      </li>
    </ul>
	</section>
	<section id="CAT-Security-Safety-Critical"><div class="header-wrapper"><h3 id="x5-3-security-safety-critical"><bdi class="secno">5.3 </bdi>Security Safety Critical</h3><a class="self-link" href="#CAT-Security-Safety-Critical" aria-label="Permalink for Section 5.3"></a></div>
	
	<p>Misuse has the potential to cause personal injury.</p> 
	  <ul>  
      <li>
        Supporting Use Cases:
        <ul>
          <li>
            <a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a>
          </li>
          <li>
            <a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a>
          </li>
          <li>
            <a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a>
          </li>
        </ul>
      </li>
    </ul>
	</section>
	<section id="CAT-Security-Business-Critical"><div class="header-wrapper"><h3 id="x5-4-security-business-critical"><bdi class="secno">5.4 </bdi>Security Business Critical</h3><a class="self-link" href="#CAT-Security-Business-Critical" aria-label="Permalink for Section 5.4"></a></div>
		
	<p>Misuse has the potential to cause financial injury or damage to business operations or reputation.</p> 
  <ul>  
    <li>
      Supporting Use Cases:
      <ul>
        <li>
          <a href="#UC-interactive-public-spaces-1" data-matched-text="[[[#UC-interactive-public-spaces-1]]]" class="sec-ref"><bdi class="secno">3.2.3 </bdi>Interactive Public Spaces</a>
        </li>
        <li>
          <a href="#UC-edge-computing-1" data-matched-text="[[[#UC-edge-computing-1]]]" class="sec-ref"><bdi class="secno">4.11 </bdi>Edge Computing</a>
        </li>
        <li>
          <a href="#UC-ar-virtual-guide-1" data-matched-text="[[[#UC-ar-virtual-guide-1]]]" class="sec-ref"><bdi class="secno">4.10.1 </bdi>AR Virtual Guide</a>
        </li>
      </ul>
    </li>
  </ul>
	</section>
	      	<section id="CAT-TD-Creation-Simplification"><div class="header-wrapper"><h3 id="x5-5-td-creation-simplification"><bdi class="secno">5.5 </bdi>TD Creation Simplification</h3><a class="self-link" href="#CAT-TD-Creation-Simplification" aria-label="Permalink for Section 5.5"></a></div>
			
	<p>Simplifying the process of TD construction is helpful to ease the task of TD writers and generators.</p> 
  <ul>  
    <li>
      Supporting Use Cases: All.
    </li>
  </ul>
	</section>
</section>
		

	  
    

    <section id="acknowledgements" class="appendix normative"><div class="header-wrapper"><h2 id="a-acknowledgments"><bdi class="secno">A. </bdi>Acknowledgments</h2><a class="self-link" href="#acknowledgements" aria-label="Permalink for Appendix A."></a></div>
      

      <p>
        Many thanks to the <abbr title="World Wide Web Consortium">W3C</abbr> staff and all other active Participants of the <abbr title="World Wide Web Consortium">W3C</abbr> Web
        of Things Interest Group (WoT IG) and Working Group (WoT WG) for their
        support, technical input and suggestions that led to improvements to
        this document.
      </p>

    <p>Special thanks to all authors of use case descriptions (in alphabetical order) for their contributions to this
      document:
    </p><ul>
      <li>Shinya Abe (NHK)</li>
      <li>Quing An (Alibaba)</li>
      <li>Cristiano Aguzzi (University of Bologna)</li>
      <li>Kaz Ashimura (<abbr title="World Wide Web Consortium">W3C</abbr>)</li>
      <li>Raúl García Castro (Universidad Politécnica de Madrid)</li>
      <li>Jean-Pierre Chanet (INRAE, France)</li>
      <li>Edison Chung (MINES St. Etienne)</li>
      <li>Andrea Cimmino (Universidad Politécnica de Madrid)</li>
      <li>Jack Dickinson, Conexxus (Dover Fueling Solutions)</li>
      <li>A. Dimara (University of the Aegean)</li>
      <li>Hiroki Endo (NHK)</li>
      <li>David Ezell (Conexxus)</li>
      <li>Hiroshi Fujisawa (NHK)</li>
      <li>Christian Glomb (Siemens)</li>
      <li>Morio Hirahara (ECHONET Consortium)</li>
      <li>Masaya Ikeo (NHK)</li>
      <li>Sebastian Käbisch (Siemens)</li>
      <li>Takuki Kamiya (Fujitsu)</li>
      <li>Zoltan Kis (Intel)</li>
      <li>Ege Korkan (Siemens)</li>
      <li>Konstantinos Kotis (University of the Aegean)</li>
      <li>Michael Lagally (Oracle)</li>
      <li>Jennifer Lin (GovTech Singapore)</li>
      <li>Tetsushi Matsuda (ECHONET Consortium)</li>
      <li>Ryuichi Matsukura (Fujitsu)</li>
      <li>Michael McCool (Intel)</li>
      <li>Takashi Murakami (ECHONET Consortium)</li>
      <li>Hervé Pruvost (Fraunhofer IIS EAS)</li>
      <li>Catherine Roussey (INRAE, France)</li>
      <li>Georg Ferdinand Schneider (Schaeffler Technologies)</li>
      <li>Rob Smith (Awayteam)</li>
      <li>Farshid Tavakolizadeh (Fraunhofer)</li>
      <li>Keiichi Teramoto (ECHONET Consortium)</li>
      <li>K. Zachila (University of the Aegean)</li>
    </ul>
    <p>
      Special thanks to Dr. Kazuyuki Ashimura from the <abbr title="World Wide Web Consortium">W3C</abbr> for the continuous help and support
      of the work of the WoT Use Cases Task Force.
    </p>
  </section>

    <p style="display: none;">
    

    
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-iso-6709" title="ISO-6709:2008 : Standard representation of geographic point location by coordinates">ISO-6709</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-hybridcast" title="IPTVFJ STD-0013 Hybridcast Operational Guideline Version 2.8">Hybridcast</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-nmea-0183" title="NMEA 0183 Interface Standard">NMEA-0183</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-ogc" title="Open Geospatial Consortium">OGC</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-ogc-coords" title="OGC Abstract Specification Topic 2: Referencing by coordinates">OGC-coords</a></cite>]
      [[iso-19111-2019]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-iec 61850" title="IEC 61850:2022 - Communication networks and systems for power utility automation">IEC 61850</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-ieee 1547" title="IEEE 1547-2018 - Interconnection and Interoperability of Distributed Energy Resources with Associated Electric Power Systems Interfaces">IEEE 1547</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-ogc sensor things" title="OGC Sensor Things API">OGC Sensor Things</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-opc ua" title="OPC Unified Architecture">OPC UA</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-mqtt" title="MQTT Version 3.1.1 Plus Errata 01">MQTT</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-bacnet" title="BACnet">BACnet</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-knx" title="KNX">KNX</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-modbus" title="Modbus">Modbus</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-ice f2761-09(2013)" title="ICE F2761-09(2013)">ICE F2761-09(2013)</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-openice" title="OpenICE">OpenICE</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-mdira" title="MDIRA">MDIRA</a></cite>]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-onem2m" title="OneM2M">OneM2M</a></cite>] 
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-lwm2m" title="Lightweight Machine to Machine Technical Specification: Core">LWM2M</a></cite>] 
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-ocf" title="OCF Core Specification">OCF</a></cite>]

     
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-json-schema" title="JSON Schema: A Media Type for Describing JSON Documents">json-schema</a></cite>]

     
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-wgs84" title="World Geodetic System 1984 (WGS 84)">WGS84</a></cite>]
      [[w3c-basic-geo]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-geolocation-api" title="Geolocation API Specification 2nd Edition">geolocation-API</a></cite>]
      [[iso-19111-2007]
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-hr-time-3" title="High Resolution Time">hr-time-3</a></cite>] 
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc7252" title="The Constrained Application Protocol (CoAP)">rfc7252</a></cite>] 
      [<cite><a class="bibref" data-link-type="biblio" href="#bib-rfc8376" title="Low-Power Wide Area Network (LPWAN) Overview">rfc8376</a></cite>] 
    </p>


    








<section id="references" class="appendix"><div class="header-wrapper"><h2 id="b-references"><bdi class="secno">B. </bdi>References</h2><a class="self-link" href="#references" aria-label="Permalink for Appendix B."></a></div><section id="informative-references"><div class="header-wrapper"><h3 id="b-1-informative-references"><bdi class="secno">B.1 </bdi>Informative references</h3><a class="self-link" href="#informative-references" aria-label="Permalink for Appendix B.1"></a></div>
    
    <dl class="bibliography"><dt id="bib-bacnet">[BACnet]</dt><dd>
      <a href="http://www.bacnet.org"><cite>BACnet</cite></a>.  ASHRAE. URL: <a href="http://www.bacnet.org">http://www.bacnet.org</a>
    </dd><dt id="bib-bot">[BOT]</dt><dd>
      <a href="https://w3c-lbd-cg.github.io/bot/index.html"><cite>Building Topology Ontology</cite></a>. Mads Holten Rasmussen; Pieter Pauwels; Maxime Lefrançois; Georg Ferdinand Schneider.  W3C Linked Building Data Community Group. 28 June 2021. URL: <a href="https://w3c-lbd-cg.github.io/bot/index.html">https://w3c-lbd-cg.github.io/bot/index.html</a>
    </dd><dt id="bib-brick">[Brick]</dt><dd>
      <a href="https://brickschema.org/"><cite>Brick Schema</cite></a>.  The Brick Consortium, Inc. URL: <a href="https://brickschema.org/">https://brickschema.org/</a>
    </dd><dt id="bib-gdpr">[GDPR]</dt><dd>
      <a href="https://gdpr-info.eu/"><cite>General Data Protection Regulation (GDPR), EU Public Law 104-191</cite></a>.  European Union. 2018-05-23. URL: <a href="https://gdpr-info.eu/">https://gdpr-info.eu/</a>
    </dd><dt id="bib-geolocation-api">[geolocation-API]</dt><dd>
      <a href="https://www.w3.org/TR/geolocation-API/"><cite>Geolocation API Specification 2nd Edition</cite></a>. Andrei Popescu.  W3C. 8 November 2016. W3C Recommendation. URL: <a href="https://www.w3.org/TR/geolocation-API/">https://www.w3.org/TR/geolocation-API/</a>
    </dd><dt id="bib-hipaa">[HIPAA]</dt><dd>
      <a href="https://www.hhs.gov/hipaa/index.html"><cite>The Health Insurance Portability and Accountability Act of 1996 (HIPAA), Public Law 104-191</cite></a>.  U.S. Department of Health and Human Services (HHS). 1996-08-21. URL: <a href="https://www.hhs.gov/hipaa/index.html">https://www.hhs.gov/hipaa/index.html</a>
    </dd><dt id="bib-hr-time-3">[hr-time-3]</dt><dd>
      <a href="https://www.w3.org/TR/hr-time-3/"><cite>High Resolution Time</cite></a>. Yoav Weiss.  W3C. 7 November 2024. W3C Working Draft. URL: <a href="https://www.w3.org/TR/hr-time-3/">https://www.w3.org/TR/hr-time-3/</a>
    </dd><dt id="bib-hybridcast">[Hybridcast]</dt><dd>
      <a href="https://www.iptvforum.jp/en/hybridcast/specification.html"><cite>IPTVFJ STD-0013 Hybridcast Operational Guideline Version 2.8</cite></a>.  IPTVFJ. 19 September 2020. URL: <a href="https://www.iptvforum.jp/en/hybridcast/specification.html">https://www.iptvforum.jp/en/hybridcast/specification.html</a>
    </dd><dt id="bib-ice f2761-09(2013)">[ICE F2761-09(2013)]</dt><dd>
      <cite>ICE F2761-09(2013)</cite>.  IEC. 
    </dd><dt id="bib-iec 61850">[IEC 61850]</dt><dd>
      <a href="https://webstore.iec.ch/publication/6028"><cite>IEC 61850:2022 - Communication networks and systems for power utility automation</cite></a>.  IEC TC 57. 4 January 2022. URL: <a href="https://webstore.iec.ch/publication/6028">https://webstore.iec.ch/publication/6028</a>
    </dd><dt id="bib-ieee 1547">[IEEE 1547]</dt><dd>
      <a href="https://standards.ieee.org/standard/1547-2018.html"><cite>IEEE 1547-2018 - Interconnection and Interoperability of Distributed Energy Resources with Associated Electric Power Systems Interfaces</cite></a>.  IEEE. 15 February 2018. URL: <a href="https://standards.ieee.org/standard/1547-2018.html">https://standards.ieee.org/standard/1547-2018.html</a>
    </dd><dt id="bib-iso-19111-2007">[iso-19111-2007]</dt><dd>
      <a href="https://www.iso.org/standard/41126.html"><cite>Geographic information -- Spatial referencing by coordinates</cite></a>. ISO/TC 211.  ISO. 2007. International Standard. URL: <a href="https://www.iso.org/standard/41126.html">https://www.iso.org/standard/41126.html</a>
    </dd><dt id="bib-iso-19111-2019">[iso-19111-2019]</dt><dd>
      <a href="https://www.iso.org/standard/74039.html"><cite>ISOi 19111:2019 - Geographic information — Referencing by coordinates</cite></a>.  ISO. Jan 2019. Published. URL: <a href="https://www.iso.org/standard/74039.html">https://www.iso.org/standard/74039.html</a>
    </dd><dt id="bib-iso-6709">[ISO-6709]</dt><dd>
      <a href="https://www.iso.org/standard/39242.html"><cite>ISO-6709:2008 : Standard representation of geographic point location by coordinates</cite></a>.  ISO. 2008-07. Published. URL: <a href="https://www.iso.org/standard/39242.html">https://www.iso.org/standard/39242.html</a>
    </dd><dt id="bib-json-schema">[json-schema]</dt><dd>
      <a href="https://datatracker.ietf.org/doc/html/draft-bhutton-json-schema"><cite>JSON Schema: A Media Type for Describing JSON Documents</cite></a>. Austin Wright; Henry Andrews; Ben Hutton; Greg Dennis.  Internet Engineering Task Force (IETF). 10 June 2022. Internet-Draft. URL: <a href="https://datatracker.ietf.org/doc/html/draft-bhutton-json-schema">https://datatracker.ietf.org/doc/html/draft-bhutton-json-schema</a>
    </dd><dt id="bib-knx">[KNX]</dt><dd>
      <a href="https://www.knx.org/knx-en/for-professionals/index.php"><cite>KNX</cite></a>.  KNX. URL: <a href="https://www.knx.org/knx-en/for-professionals/index.php">https://www.knx.org/knx-en/for-professionals/index.php</a>
    </dd><dt id="bib-lwm2m">[LWM2M]</dt><dd>
      <a href="http://openmobilealliance.org/release/LightweightM2M/V1_1-20180710-A/OMA-TS-LightweightM2M_Core-V1_1-20180710-A.pdf"><cite>Lightweight Machine to Machine Technical Specification: Core</cite></a>.  OMA SpecWorks. Aug 2018. URL: <a href="http://openmobilealliance.org/release/LightweightM2M/V1_1-20180710-A/OMA-TS-LightweightM2M_Core-V1_1-20180710-A.pdf">http://openmobilealliance.org/release/LightweightM2M/V1_1-20180710-A/OMA-TS-LightweightM2M_Core-V1_1-20180710-A.pdf</a>
    </dd><dt id="bib-mdira">[MDIRA]</dt><dd>
      <a href="https://secwww.jhuapl.edu/mdira/documents"><cite>MDIRA</cite></a>. URL: <a href="https://secwww.jhuapl.edu/mdira/documents">https://secwww.jhuapl.edu/mdira/documents</a>
    </dd><dt id="bib-mmi-use-cases">[mmi-use-cases]</dt><dd>
      <a href="https://www.w3.org/TR/mmi-use-cases/"><cite>Multimodal Interaction Use Cases</cite></a>. Dave Raggett.  W3C. 4 December 2002. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/mmi-use-cases/">https://www.w3.org/TR/mmi-use-cases/</a>
    </dd><dt id="bib-modbus">[Modbus]</dt><dd>
      <a href="https://modbus.org"><cite>Modbus</cite></a>.  Modbus Organization. URL: <a href="https://modbus.org">https://modbus.org</a>
    </dd><dt id="bib-mqtt">[MQTT]</dt><dd>
      <a href="http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/mqtt-v3.1.1.html"><cite>MQTT Version 3.1.1 Plus Errata 01</cite></a>. Andrew Banks; Rahul Gupta.  OASIS Standard. December 2015. Published. URL: <a href="http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/mqtt-v3.1.1.html">http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/mqtt-v3.1.1.html</a>
    </dd><dt id="bib-nmea-0183">[NMEA-0183]</dt><dd>
      <a href="https://www.nmea.org/content/STANDARDS/NMEA_0183_Standard"><cite>NMEA 0183 Interface Standard</cite></a>.  National Marine Electronics Association. November 2018. URL: <a href="https://www.nmea.org/content/STANDARDS/NMEA_0183_Standard">https://www.nmea.org/content/STANDARDS/NMEA_0183_Standard</a>
    </dd><dt id="bib-ocf">[OCF]</dt><dd>
      <a href="https://openconnectivity.org/developer/specifications"><cite>OCF Core Specification</cite></a>.  Open Connectivity Foundation. April 2019. URL: <a href="https://openconnectivity.org/developer/specifications">https://openconnectivity.org/developer/specifications</a>
    </dd><dt id="bib-ogc">[OGC]</dt><dd>
      <a href="https://www.ogc.org/"><cite>Open Geospatial Consortium</cite></a>. URL: <a href="https://www.ogc.org/">https://www.ogc.org/</a>
    </dd><dt id="bib-ogc sensor things">[OGC Sensor Things]</dt><dd>
      <a href="https://www.ogc.org/standards/sensorthings"><cite>OGC Sensor Things API</cite></a>.  Open Geospatial Consortium. 4 August 2021. URL: <a href="https://www.ogc.org/standards/sensorthings">https://www.ogc.org/standards/sensorthings</a>
    </dd><dt id="bib-ogc-coords">[OGC-coords]</dt><dd>
      <a href="http://docs.opengeospatial.org/as/18-005r4/18-005r4.html"><cite>OGC Abstract Specification Topic 2: Referencing by coordinates</cite></a>.  Open Geospatial Consortium. 8 February 2019. URL: <a href="http://docs.opengeospatial.org/as/18-005r4/18-005r4.html">http://docs.opengeospatial.org/as/18-005r4/18-005r4.html</a>
    </dd><dt id="bib-onem2m">[OneM2M]</dt><dd>
      <a href="https://www.onem2m.org"><cite>OneM2M</cite></a>.  ETSI. URL: <a href="https://www.onem2m.org">https://www.onem2m.org</a>
    </dd><dt id="bib-opc ua">[OPC UA]</dt><dd>
      <a href="https://opcfoundation.org/about/opc-technologies/opc-ua/"><cite>OPC Unified Architecture</cite></a>.  OPC. URL: <a href="https://opcfoundation.org/about/opc-technologies/opc-ua/">https://opcfoundation.org/about/opc-technologies/opc-ua/</a>
    </dd><dt id="bib-openice">[OpenICE]</dt><dd>
      <a href="https://www.openice.info"><cite>OpenICE</cite></a>. URL: <a href="https://www.openice.info">https://www.openice.info</a>
    </dd><dt id="bib-pipeda">[PIPEDA]</dt><dd>
      <a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/"><cite>Personal Information Protection and Electronic Documents Act (PIPEDA)</cite></a>.  Government of Canada, Office of the Privacy Commissioner. 2000-04-13. URL: <a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/">https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/</a>
    </dd><dt id="bib-rfc7252">[rfc7252]</dt><dd>
      <a href="https://www.rfc-editor.org/rfc/rfc7252"><cite>The Constrained Application Protocol (CoAP)</cite></a>. Z. Shelby; K. Hartke; C. Bormann.  IETF. June 2014. Proposed Standard. URL: <a href="https://www.rfc-editor.org/rfc/rfc7252">https://www.rfc-editor.org/rfc/rfc7252</a>
    </dd><dt id="bib-rfc8376">[rfc8376]</dt><dd>
      <a href="https://www.rfc-editor.org/rfc/rfc8376"><cite>Low-Power Wide Area Network (LPWAN) Overview</cite></a>. S. Farrell, Ed. IETF. May 2018. Informational. URL: <a href="https://www.rfc-editor.org/rfc/rfc8376">https://www.rfc-editor.org/rfc/rfc8376</a>
    </dd><dt id="bib-rfc9200">[RFC9200]</dt><dd>
      <a href="https://www.rfc-editor.org/rfc/rfc9200"><cite>Authentication and Authorization for Constrained Environments Using the OAuth 2.0 Framework (ACE-OAuth)</cite></a>. L. Seitz; G. Selander; E. Wahlstroem; S. Erdtman; H. Tschofenig.  IETF. August 2022. Proposed Standard. URL: <a href="https://www.rfc-editor.org/rfc/rfc9200">https://www.rfc-editor.org/rfc/rfc9200</a>
    </dd><dt id="bib-rfc9202">[RFC9202]</dt><dd>
      <a href="https://www.rfc-editor.org/rfc/rfc9202"><cite>Datagram Transport Layer Security (DTLS) Profile for Authentication and Authorization for Constrained Environments (ACE)</cite></a>. S. Gerdes; O. Bergmann; C. Bormann; G. Selander; L. Seitz.  IETF. August 2022. Proposed Standard. URL: <a href="https://www.rfc-editor.org/rfc/rfc9202">https://www.rfc-editor.org/rfc/rfc9202</a>
    </dd><dt id="bib-rfc9203">[RFC9203]</dt><dd>
      <a href="https://www.rfc-editor.org/rfc/rfc9203"><cite>The Object Security for Constrained RESTful Environments (OSCORE) Profile of the Authentication and Authorization for Constrained Environments (ACE) Framework</cite></a>. F. Palombini; L. Seitz; G. Selander; M. Gunnarsson.  IETF. August 2022. Proposed Standard. URL: <a href="https://www.rfc-editor.org/rfc/rfc9203">https://www.rfc-editor.org/rfc/rfc9203</a>
    </dd><dt id="bib-rfc9431">[RFC9431]</dt><dd>
      <a href="https://www.rfc-editor.org/rfc/rfc9431"><cite>Message Queuing Telemetry Transport (MQTT) and Transport Layer Security (TLS) Profile of Authentication and Authorization for Constrained Environments (ACE) Framework</cite></a>. C. Sengul; A. Kirby.  IETF. July 2023. Proposed Standard. URL: <a href="https://www.rfc-editor.org/rfc/rfc9431">https://www.rfc-editor.org/rfc/rfc9431</a>
    </dd><dt id="bib-saref4agri">[SAREF4AGRI]</dt><dd>
      <a href="https://saref.etsi.org/saref4agri/"><cite>SAREF4AGRI: an extension of SAREF for the agriculture and food domain</cite></a>. Maria Poveda-Villalon; Raúl Garcia-Castro; Laura Daniele; Mike de Roode.  ETSI. 30 April 2019. URL: <a href="https://saref.etsi.org/saref4agri/">https://saref.etsi.org/saref4agri/</a>
    </dd><dt id="bib-saref4bldg">[SAREF4BLDG]</dt><dd>
      <a href="https://saref.etsi.org/saref4bldg/"><cite>SAREF extension for building</cite></a>. María Poveda-Villalón; Raúl Garcia-Castro.  ETSI. 13 April 2020. URL: <a href="https://saref.etsi.org/saref4bldg/">https://saref.etsi.org/saref4bldg/</a>
    </dd><dt id="bib-saref4ener">[SAREF4ENER]</dt><dd>
      <a href="https://saref.etsi.org/saref4ener/"><cite>SAREF4ENER: an extension of SAREF for the energy domain created in collaboration with Energy@Home and EEBus associations</cite></a>. Laura Daniele.  ETSI. 4 June 2020. URL: <a href="https://saref.etsi.org/saref4ener/">https://saref.etsi.org/saref4ener/</a>
    </dd><dt id="bib-saref4syst">[SAREF4SYST]</dt><dd>
      <a href="https://saref.etsi.org/saref4syst/"><cite>SAREF4SYST: an extension of SAREF for typology of systems and their inter-connections</cite></a>. Maxime Lefrançois.  ETSI. 6 June 2019. URL: <a href="https://saref.etsi.org/saref4syst/">https://saref.etsi.org/saref4syst/</a>
    </dd><dt id="bib-swebokv4">[SWEBOKv4]</dt><dd>
      <a href="https://www.computer.org/education/bodies-of-knowledge/software-engineering"><cite>Guide to the Software Engineering Body of Knowledge (SWEBOK Guide), Version 4.0</cite></a>. Hironori Washizaki.  IEEE Computer Society. 2024. Published. URL: <a href="https://www.computer.org/education/bodies-of-knowledge/software-engineering">https://www.computer.org/education/bodies-of-knowledge/software-engineering</a>
    </dd><dt id="bib-vocab-ssn">[vocab-ssn]</dt><dd>
      <a href="https://www.w3.org/TR/vocab-ssn-2017/"><cite>Semantic Sensor Network Ontology</cite></a>. Armin Haller; Krzysztof Janowicz; Simon Cox; Danh Le Phuoc; Kerry Taylor; Maxime Lefrançois.  W3C. 19 October 2017. W3C Recommendation. URL: <a href="https://www.w3.org/TR/vocab-ssn-2017/">https://www.w3.org/TR/vocab-ssn-2017/</a>
    </dd><dt id="bib-w3c-basic-geo">[w3c-basic-geo]</dt><dd>
      <a href="https://www.w3.org/2003/01/geo/"><cite>Basic Geo (WGS84 lat/long) Vocabulary</cite></a>. Dan Brickley.  W3C Semantic Web Interest Group. 1 February 2006. URL: <a href="https://www.w3.org/2003/01/geo/">https://www.w3.org/2003/01/geo/</a>
    </dd><dt id="bib-wgs84">[WGS84]</dt><dd>
      <a href="https://earth-info.nga.mil/index.php?dir=wgs84&amp;action=wgs84"><cite>World Geodetic System 1984 (WGS 84)</cite></a>.  Office of Geomatics, National Geospatial Intelligence Agency. 2008. URL: <a href="https://earth-info.nga.mil/index.php?dir=wgs84&amp;action=wgs84">https://earth-info.nga.mil/index.php?dir=wgs84&amp;action=wgs84</a>
    </dd><dt id="bib-wot-architecture">[wot-architecture]</dt><dd>
      <a href="https://www.w3.org/TR/wot-architecture/"><cite>Web of Things (WoT) Architecture</cite></a>. Matthias Kovatsch; Ryuichi Matsukura; Michael Lagally; Toru Kawaguchi; Kunihiko Toumura; Kazuo Kajimoto.  W3C. 9 April 2020. W3C Recommendation. URL: <a href="https://www.w3.org/TR/wot-architecture/">https://www.w3.org/TR/wot-architecture/</a>
    </dd><dt id="bib-wot-binding-templates">[wot-binding-templates]</dt><dd>
      <a href="https://www.w3.org/TR/wot-binding-templates/"><cite>Web of Things (WoT) Binding Templates</cite></a>. Michael Koster; Ege Korkan.  W3C. 28 May 2024. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/wot-binding-templates/">https://www.w3.org/TR/wot-binding-templates/</a>
    </dd><dt id="bib-wot-discovery">[wot-discovery]</dt><dd>
      <a href="https://www.w3.org/TR/wot-discovery/"><cite>Web of Things (WoT) Discovery</cite></a>. Kunihiko Toumura; Michael McCool; Andrea Cimmino; Farshid Tavakolizadeh.  W3C. 5 December 2023. W3C Recommendation. URL: <a href="https://www.w3.org/TR/wot-discovery/">https://www.w3.org/TR/wot-discovery/</a>
    </dd><dt id="bib-wot-geolocation-proposal">[wot-geolocation-proposal]</dt><dd>
      <a href="https://github.com/w3c/wot-discovery/blob/main/proposals/geolocation.md"><cite>WoT Discovery - Geolocation</cite></a>. Michael McCool. 8 March 2021. Proposal. URL: <a href="https://github.com/w3c/wot-discovery/blob/main/proposals/geolocation.md">https://github.com/w3c/wot-discovery/blob/main/proposals/geolocation.md</a>
    </dd><dt id="bib-wot-security">[wot-security]</dt><dd>
      <a href="https://www.w3.org/TR/wot-security/"><cite>Web of Things (WoT) Security and Privacy Guidelines</cite></a>. Elena Reshetova; Michael McCool.  W3C. 6 November 2019. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/wot-security/">https://www.w3.org/TR/wot-security/</a>
    </dd><dt id="bib-wot-thing-description">[wot-thing-description]</dt><dd>
      <a href="https://www.w3.org/TR/wot-thing-description/"><cite>Web of Things (WoT) Thing Description</cite></a>. Sebastian Käbisch; Takuki Kamiya; Michael McCool; Victor Charpenay; Matthias Kovatsch.  W3C. 9 April 2020. W3C Recommendation. URL: <a href="https://www.w3.org/TR/wot-thing-description/">https://www.w3.org/TR/wot-thing-description/</a>
    </dd></dl>
  </section></section><p role="navigation" id="back-to-top">
    <a href="#title"><abbr title="Back to Top">↑</abbr></a>
  </p><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-wot-use-case" aria-label="Links in this document to definition: Use Case">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-wot-use-case" aria-label="Permalink for definition: Use Case. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-wot-use-case-1" title="§ 1.1 Terminology">§ 1.1 Terminology</a> <a href="#ref-for-dfn-wot-use-case-2" title="Reference 2">(2)</a> <a href="#ref-for-dfn-wot-use-case-3" title="Reference 3">(3)</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-wot-use-case-category" aria-label="Links in this document to definition: Use Case Category">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-wot-use-case-category" aria-label="Permalink for definition: Use Case Category. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
      <li>Not referenced in this document.</li>
    </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-wot-requirement" aria-label="Links in this document to definition: Requirement">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-wot-requirement" aria-label="Permalink for definition: Requirement. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
      <li>Not referenced in this document.</li>
    </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-wot-user-story" aria-label="Links in this document to definition: User Story">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-wot-user-story" aria-label="Permalink for definition: User Story. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-wot-user-story-1" title="§ 1.1 Terminology">§ 1.1 Terminology</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-device-manufacturer" aria-label="Links in this document to definition: Device Manufacturer">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-device-manufacturer" aria-label="Permalink for definition: Device Manufacturer. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-1" title="§ 1.3 Stakeholders and Roles">§ 1.3 Stakeholders and Roles</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-2" title="§ 2.1.3 Byte Ordering for Binary Data Formats">§ 2.1.3 Byte Ordering for Binary Data Formats</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-3" title="§ 2.1.4 Polling Rate Limit">§ 2.1.4 Polling Rate Limit</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-4" title="§ 3.1.4 Automatic milking system for dairy farm">§ 3.1.4 Automatic milking system for dairy farm</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-5" title="§ 3.1.5 Pest control in Open-field">§ 3.1.5 Pest control in Open-field</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-6" title="§ 3.1.6 Livestock Health Management">§ 3.1.6 Livestock Health Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-7" title="§ 3.1.7 Agricultural Machinery Management">§ 3.1.7 Agricultural Machinery Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-8" title="§ 3.3.3 Automated Smart Building Management">§ 3.3.3 Automated Smart Building Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-9" title="§ 3.3.4 Portable Building Applications">§ 3.3.4 Portable Building Applications</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-10" title="§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios">§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-11" title="§ 3.5.2 Retail All Stop Button (Outdoor Emergency Stop Plunger)">§ 3.5.2 Retail All Stop Button (Outdoor Emergency Stop Plunger)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-12" title="§ 3.5.3 Retail Indoor Door Sensor">§ 3.5.3 Retail Indoor Door Sensor</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-13" title="§ 3.5.4 Retail Indoor and Outdoor Freezers">§ 3.5.4 Retail Indoor and Outdoor Freezers</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-14" title="§ 3.5.5 Retail Kitchen Refrigerator">§ 3.5.5 Retail Kitchen Refrigerator</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-15" title="§ 3.5.6 Retail Restroom Devices">§ 3.5.6 Retail Restroom Devices</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-16" title="§ 3.5.7 Retail Lighting Control">§ 3.5.7 Retail Lighting Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-17" title="§ 3.5.8 Retail Outdoor Canopy Lighting Control">§ 3.5.8 Retail Outdoor Canopy Lighting Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-18" title="§ 3.5.9 Retail Fountain Drink Ice Machine">§ 3.5.9 Retail Fountain Drink Ice Machine</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-19" title="§ 3.5.10 Retail Camera Device">§ 3.5.10 Retail Camera Device</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-20" title="§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU">§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-21" title="§ 3.6.3.1 Digital Microscopes">§ 3.6.3.1 Digital Microscopes</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-22" title="§ 3.7.1 Smart Grids">§ 3.7.1 Smart Grids</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-23" title="§ 3.10.1.2 Leaving and Coming Home">§ 3.10.1.2 Leaving and Coming Home</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-24" title="§ 4.1 Discovery">§ 4.1 Discovery</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-25" title="§ 4.2 Multi-Vendor System Integration - Out of the box interoperability">§ 4.2 Multi-Vendor System Integration - Out of the box interoperability</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-26" title="§ 4.3 Virtual Thing">§ 4.3 Virtual Thing</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-27" title="§ 4.9.1 Device Lifecycle">§ 4.9.1 Device Lifecycle</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-28" title="§ 4.10.1 AR Virtual Guide">§ 4.10.1 AR Virtual Guide</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-manufacturer-29" title="§ 4.11 Edge Computing">§ 4.11 Edge Computing</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-system-provider" aria-label="Links in this document to definition: System Provider">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-system-provider" aria-label="Permalink for definition: System Provider. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
      <li>Not referenced in this document.</li>
    </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-system-integrator" aria-label="Links in this document to definition: System Integrator">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-system-integrator" aria-label="Permalink for definition: System Integrator. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-1" title="§ 2.1.5 Mitigate WoT Protocol Binding Threat">§ 2.1.5 Mitigate WoT Protocol Binding Threat</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-2" title="§ 2.1.6 Mitigate Exposed Thing Compromise Threat">§ 2.1.6 Mitigate Exposed Thing Compromise Threat</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-3" title="§ 2.1.7 Security Access Control">§ 2.1.7 Security Access Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-4" title="§ 2.1.8 Mitigate WoT DoS Threat">§ 2.1.8 Mitigate WoT DoS Threat</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-5" title="§ 2.1.9 Mitigate WoT DDoS Threat">§ 2.1.9 Mitigate WoT DDoS Threat</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-6" title="§ 2.1.10 Mitigate Communication Threat - TD Authenticity">§ 2.1.10 Mitigate Communication Threat - TD Authenticity</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-7" title="§ 2.1.11 Mitigate Communication Threat - TD Confidentiality and Privacy">§ 2.1.11 Mitigate Communication Threat - TD Confidentiality and Privacy</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-8" title="§ 2.1.12 Mitigate Communication Threat - System User Data Authenticity">§ 2.1.12 Mitigate Communication Threat - System User Data Authenticity</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-9" title="§ 2.1.13 Mitigate Communication Threat - System User Data Confidentiality and Privacy">§ 2.1.13 Mitigate Communication Threat - System User Data Confidentiality and Privacy</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-10" title="§ 2.1.14 Mitigate Communication Threat - Side Channels">§ 2.1.14 Mitigate Communication Threat - Side Channels</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-11" title="§ 2.1.15 Discovery Network Scope">§ 2.1.15 Discovery Network Scope</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-12" title="§ 2.1.16 Discovery via Third Party Services">§ 2.1.16 Discovery via Third Party Services</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-13" title="§ 2.1.17 Discovery via Scripting API">§ 2.1.17 Discovery via Scripting API</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-14" title="§ 2.1.18 Discovery Filtering">§ 2.1.18 Discovery Filtering</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-15" title="§ 2.1.19 Discovery Spatial Queries">§ 2.1.19 Discovery Spatial Queries</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-16" title="§ 2.1.20 Discovery Subnet Spanning Queries">§ 2.1.20 Discovery Subnet Spanning Queries</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-17" title="§ 2.1.21 Discovery Scalability">§ 2.1.21 Discovery Scalability</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-18" title="§ 2.1.22 Discovery Dynamic and Static Metadata">§ 2.1.22 Discovery Dynamic and Static Metadata</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-19" title="§ 2.1.23 Discovery Deletion">§ 2.1.23 Discovery Deletion</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-20" title="§ 2.1.24 Discovery Access Control">§ 2.1.24 Discovery Access Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-21" title="§ 2.1.25 Discovery Clean Up">§ 2.1.25 Discovery Clean Up</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-22" title="§ 2.1.26 Discovery IETF CoRE Alignment">§ 2.1.26 Discovery IETF CoRE Alignment</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-23" title="§ 2.1.27 Discovery DID Alignment">§ 2.1.27 Discovery DID Alignment</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-24" title="§ 2.1.28 Discovery Extensible Introductions">§ 2.1.28 Discovery Extensible Introductions</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-25" title="§ 2.1.29 Discovery Confidentiality">§ 2.1.29 Discovery Confidentiality</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-26" title="§ 2.1.30 Discovery Authentication">§ 2.1.30 Discovery Authentication</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-27" title="§ 2.1.31 Discovery Authorization">§ 2.1.31 Discovery Authorization</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-28" title="§ 2.1.32 Discovery Anonymous Authentication">§ 2.1.32 Discovery Anonymous Authentication</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-29" title="§ 2.1.33 Discovery Lifecycle">§ 2.1.33 Discovery Lifecycle</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-30" title="§ 2.1.34 Discovery Limit Distribution">§ 2.1.34 Discovery Limit Distribution</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-31" title="§ 2.1.35 Discovery No Leaks">§ 2.1.35 Discovery No Leaks</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-32" title="§ 2.1.36 Discovery Simplicity">§ 2.1.36 Discovery Simplicity</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-33" title="§ 2.1.37 Discovery Human Authentication">§ 2.1.37 Discovery Human Authentication</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-34" title="§ 2.1.38 Discovery User Limitations">§ 2.1.38 Discovery User Limitations</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-integrator-35" title="§ 2.1.39 Discovery Alternatives">§ 2.1.39 Discovery Alternatives</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-system-installer" aria-label="Links in this document to definition: System Installer">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-system-installer" aria-label="Permalink for definition: System Installer. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
      <li>Not referenced in this document.</li>
    </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-system-user" aria-label="Links in this document to definition: System User">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-system-user" aria-label="Permalink for definition: System User. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-system-user-1" title="§ 2.1.5 Mitigate WoT Protocol Binding Threat">§ 2.1.5 Mitigate WoT Protocol Binding Threat</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-2" title="§ 2.1.6 Mitigate Exposed Thing Compromise Threat">§ 2.1.6 Mitigate Exposed Thing Compromise Threat</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-3" title="§ 2.1.7 Security Access Control">§ 2.1.7 Security Access Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-4" title="§ 2.1.8 Mitigate WoT DoS Threat">§ 2.1.8 Mitigate WoT DoS Threat</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-5" title="§ 2.1.9 Mitigate WoT DDoS Threat">§ 2.1.9 Mitigate WoT DDoS Threat</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-6" title="§ 2.1.10 Mitigate Communication Threat - TD Authenticity">§ 2.1.10 Mitigate Communication Threat - TD Authenticity</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-7" title="§ 2.1.11 Mitigate Communication Threat - TD Confidentiality and Privacy">§ 2.1.11 Mitigate Communication Threat - TD Confidentiality and Privacy</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-8" title="§ 2.1.12 Mitigate Communication Threat - System User Data Authenticity">§ 2.1.12 Mitigate Communication Threat - System User Data Authenticity</a> <a href="#ref-for-dfn-stakeholder-system-user-9" title="Reference 2">(2)</a> <a href="#ref-for-dfn-stakeholder-system-user-10" title="Reference 3">(3)</a> <a href="#ref-for-dfn-stakeholder-system-user-11" title="Reference 4">(4)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-12" title="§ 2.1.13 Mitigate Communication Threat - System User Data Confidentiality and Privacy">§ 2.1.13 Mitigate Communication Threat - System User Data Confidentiality and Privacy</a> <a href="#ref-for-dfn-stakeholder-system-user-13" title="Reference 2">(2)</a> <a href="#ref-for-dfn-stakeholder-system-user-14" title="Reference 3">(3)</a> <a href="#ref-for-dfn-stakeholder-system-user-15" title="Reference 4">(4)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-16" title="§ 2.1.14 Mitigate Communication Threat - Side Channels">§ 2.1.14 Mitigate Communication Threat - Side Channels</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-17" title="§ 2.1.15 Discovery Network Scope">§ 2.1.15 Discovery Network Scope</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-18" title="§ 2.1.16 Discovery via Third Party Services">§ 2.1.16 Discovery via Third Party Services</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-19" title="§ 2.1.17 Discovery via Scripting API">§ 2.1.17 Discovery via Scripting API</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-20" title="§ 2.1.18 Discovery Filtering">§ 2.1.18 Discovery Filtering</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-21" title="§ 2.1.19 Discovery Spatial Queries">§ 2.1.19 Discovery Spatial Queries</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-22" title="§ 2.1.20 Discovery Subnet Spanning Queries">§ 2.1.20 Discovery Subnet Spanning Queries</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-23" title="§ 2.1.21 Discovery Scalability">§ 2.1.21 Discovery Scalability</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-24" title="§ 2.1.22 Discovery Dynamic and Static Metadata">§ 2.1.22 Discovery Dynamic and Static Metadata</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-25" title="§ 2.1.23 Discovery Deletion">§ 2.1.23 Discovery Deletion</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-26" title="§ 2.1.24 Discovery Access Control">§ 2.1.24 Discovery Access Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-27" title="§ 2.1.25 Discovery Clean Up">§ 2.1.25 Discovery Clean Up</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-28" title="§ 2.1.26 Discovery IETF CoRE Alignment">§ 2.1.26 Discovery IETF CoRE Alignment</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-29" title="§ 2.1.27 Discovery DID Alignment">§ 2.1.27 Discovery DID Alignment</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-30" title="§ 2.1.28 Discovery Extensible Introductions">§ 2.1.28 Discovery Extensible Introductions</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-31" title="§ 2.1.29 Discovery Confidentiality">§ 2.1.29 Discovery Confidentiality</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-32" title="§ 2.1.30 Discovery Authentication">§ 2.1.30 Discovery Authentication</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-33" title="§ 2.1.31 Discovery Authorization">§ 2.1.31 Discovery Authorization</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-34" title="§ 2.1.32 Discovery Anonymous Authentication">§ 2.1.32 Discovery Anonymous Authentication</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-35" title="§ 2.1.33 Discovery Lifecycle">§ 2.1.33 Discovery Lifecycle</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-36" title="§ 2.1.34 Discovery Limit Distribution">§ 2.1.34 Discovery Limit Distribution</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-37" title="§ 2.1.35 Discovery No Leaks">§ 2.1.35 Discovery No Leaks</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-38" title="§ 2.1.36 Discovery Simplicity">§ 2.1.36 Discovery Simplicity</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-39" title="§ 2.1.37 Discovery Human Authentication">§ 2.1.37 Discovery Human Authentication</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-40" title="§ 2.1.38 Discovery User Limitations">§ 2.1.38 Discovery User Limitations</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-user-41" title="§ 2.1.39 Discovery Alternatives">§ 2.1.39 Discovery Alternatives</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-system-owner" aria-label="Links in this document to definition: System Owner">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-system-owner" aria-label="Permalink for definition: System Owner. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-system-owner-1" title="§ 1.3 Stakeholders and Roles">§ 1.3 Stakeholders and Roles</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-system-maintainer" aria-label="Links in this document to definition: System Maintainer">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-system-maintainer" aria-label="Permalink for definition: System Maintainer. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-system-maintainer-1" title="§ 2.1.21 Discovery Scalability">§ 2.1.21 Discovery Scalability</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-maintainer-2" title="§ 2.1.24 Discovery Access Control">§ 2.1.24 Discovery Access Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-system-maintainer-3" title="§ 2.1.25 Discovery Clean Up">§ 2.1.25 Discovery Clean Up</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-device-owner" aria-label="Links in this document to definition: Device Owner">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-device-owner" aria-label="Permalink for definition: Device Owner. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-device-owner-1" title="§ 2.1.11 Mitigate Communication Threat - TD Confidentiality and Privacy">§ 2.1.11 Mitigate Communication Threat - TD Confidentiality and Privacy</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-2" title="§ 3.1.4 Automatic milking system for dairy farm">§ 3.1.4 Automatic milking system for dairy farm</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-3" title="§ 3.1.5 Pest control in Open-field">§ 3.1.5 Pest control in Open-field</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-4" title="§ 3.2.2 Smart City Dashboard">§ 3.2.2 Smart City Dashboard</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-5" title="§ 3.2.5 Cross-Domain Discovery in a Smart Campus">§ 3.2.5 Cross-Domain Discovery in a Smart Campus</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-6" title="§ 3.2.6 Cultural Spaces (Museums)">§ 3.2.6 Cultural Spaces (Museums)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-7" title="§ 3.3.2 Connected Building Energy Efficiency">§ 3.3.2 Connected Building Energy Efficiency</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-8" title="§ 3.3.3 Automated Smart Building Management">§ 3.3.3 Automated Smart Building Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-9" title="§ 3.3.4 Portable Building Applications">§ 3.3.4 Portable Building Applications</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-10" title="§ 3.4.1 Production Monitoring">§ 3.4.1 Production Monitoring</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-11" title="§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios">§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-12" title="§ 3.5.2 Retail All Stop Button (Outdoor Emergency Stop Plunger)">§ 3.5.2 Retail All Stop Button (Outdoor Emergency Stop Plunger)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-13" title="§ 3.5.3 Retail Indoor Door Sensor">§ 3.5.3 Retail Indoor Door Sensor</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-14" title="§ 3.5.4 Retail Indoor and Outdoor Freezers">§ 3.5.4 Retail Indoor and Outdoor Freezers</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-15" title="§ 3.5.5 Retail Kitchen Refrigerator">§ 3.5.5 Retail Kitchen Refrigerator</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-16" title="§ 3.5.6 Retail Restroom Devices">§ 3.5.6 Retail Restroom Devices</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-17" title="§ 3.5.7 Retail Lighting Control">§ 3.5.7 Retail Lighting Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-18" title="§ 3.5.8 Retail Outdoor Canopy Lighting Control">§ 3.5.8 Retail Outdoor Canopy Lighting Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-19" title="§ 3.5.9 Retail Fountain Drink Ice Machine">§ 3.5.9 Retail Fountain Drink Ice Machine</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-20" title="§ 3.5.10 Retail Camera Device">§ 3.5.10 Retail Camera Device</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-21" title="§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU">§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-22" title="§ 3.6.3.1 Digital Microscopes">§ 3.6.3.1 Digital Microscopes</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-23" title="§ 3.10.2.1 Education Shared Devices">§ 3.10.2.1 Education Shared Devices</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-24" title="§ 4.1 Discovery">§ 4.1 Discovery</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-25" title="§ 4.2 Multi-Vendor System Integration - Out of the box interoperability">§ 4.2 Multi-Vendor System Integration - Out of the box interoperability</a> <a href="#ref-for-dfn-stakeholder-device-owner-26" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-27" title="§ 4.3 Virtual Thing">§ 4.3 Virtual Thing</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-28" title="§ 4.4.1 Digital Twin (1)">§ 4.4.1 Digital Twin (1)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-29" title="§ 4.4.2 Digital Twin (2)">§ 4.4.2 Digital Twin (2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-30" title="§ 4.5 Cross Protocol Interworking">§ 4.5 Cross Protocol Interworking</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-31" title="§ 4.8.1 OAuth2 Flows">§ 4.8.1 OAuth2 Flows</a> <a href="#ref-for-dfn-stakeholder-device-owner-32" title="Reference 2">(2)</a> <a href="#ref-for-dfn-stakeholder-device-owner-33" title="Reference 3">(3)</a> <a href="#ref-for-dfn-stakeholder-device-owner-34" title="Reference 4">(4)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-35" title="§ 4.9.1 Device Lifecycle">§ 4.9.1 Device Lifecycle</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-36" title="§ 4.10.1 AR Virtual Guide">§ 4.10.1 AR Virtual Guide</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-owner-37" title="§ 4.11 Edge Computing">§ 4.11 Edge Computing</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-device-user" aria-label="Links in this document to definition: Device User">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-device-user" aria-label="Permalink for definition: Device User. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-device-user-1" title="§ 3.1.3 Irrigation in Outdoor Environment">§ 3.1.3 Irrigation in Outdoor Environment</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-2" title="§ 3.1.5 Pest control in Open-field">§ 3.1.5 Pest control in Open-field</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-3" title="§ 3.1.6 Livestock Health Management">§ 3.1.6 Livestock Health Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-4" title="§ 3.2.2 Smart City Dashboard">§ 3.2.2 Smart City Dashboard</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-5" title="§ 3.2.6 Cultural Spaces (Museums)">§ 3.2.6 Cultural Spaces (Museums)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-6" title="§ 3.3.2 Connected Building Energy Efficiency">§ 3.3.2 Connected Building Energy Efficiency</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-7" title="§ 3.3.3 Automated Smart Building Management">§ 3.3.3 Automated Smart Building Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-8" title="§ 3.3.4 Portable Building Applications">§ 3.3.4 Portable Building Applications</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-9" title="§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios">§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-10" title="§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU">§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-11" title="§ 3.6.3.1 Digital Microscopes">§ 3.6.3.1 Digital Microscopes</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-12" title="§ 3.10.1.2 Leaving and Coming Home">§ 3.10.1.2 Leaving and Coming Home</a> <a href="#ref-for-dfn-stakeholder-device-user-13" title="Reference 2">(2)</a> <a href="#ref-for-dfn-stakeholder-device-user-14" title="Reference 3">(3)</a> <a href="#ref-for-dfn-stakeholder-device-user-15" title="Reference 4">(4)</a> <a href="#ref-for-dfn-stakeholder-device-user-16" title="Reference 5">(5)</a> <a href="#ref-for-dfn-stakeholder-device-user-17" title="Reference 6">(6)</a> <a href="#ref-for-dfn-stakeholder-device-user-18" title="Reference 7">(7)</a> <a href="#ref-for-dfn-stakeholder-device-user-19" title="Reference 8">(8)</a> <a href="#ref-for-dfn-stakeholder-device-user-20" title="Reference 9">(9)</a> <a href="#ref-for-dfn-stakeholder-device-user-21" title="Reference 10">(10)</a> <a href="#ref-for-dfn-stakeholder-device-user-22" title="Reference 11">(11)</a> <a href="#ref-for-dfn-stakeholder-device-user-23" title="Reference 12">(12)</a> <a href="#ref-for-dfn-stakeholder-device-user-24" title="Reference 13">(13)</a> <a href="#ref-for-dfn-stakeholder-device-user-25" title="Reference 14">(14)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-26" title="§ 3.10.2.1 Education Shared Devices">§ 3.10.2.1 Education Shared Devices</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-27" title="§ 4.1 Discovery">§ 4.1 Discovery</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-28" title="§ 4.4.2 Digital Twin (2)">§ 4.4.2 Digital Twin (2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-29" title="§ 4.8.1 OAuth2 Flows">§ 4.8.1 OAuth2 Flows</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-30" title="§ 4.10.1 AR Virtual Guide">§ 4.10.1 AR Virtual Guide</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-device-user-31" title="§ 4.11 Edge Computing">§ 4.11 Edge Computing</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-cloud-provider" aria-label="Links in this document to definition: Cloud Provider">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-cloud-provider" aria-label="Permalink for definition: Cloud Provider. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-1" title="§ 3.1.1 Greenhouse Horticulture">§ 3.1.1 Greenhouse Horticulture</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-2" title="§ 3.1.2 Open-field Agriculture">§ 3.1.2 Open-field Agriculture</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-3" title="§ 3.1.4 Automatic milking system for dairy farm">§ 3.1.4 Automatic milking system for dairy farm</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-4" title="§ 3.1.5 Pest control in Open-field">§ 3.1.5 Pest control in Open-field</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-5" title="§ 3.2.2 Smart City Dashboard">§ 3.2.2 Smart City Dashboard</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-6" title="§ 3.3.4 Portable Building Applications">§ 3.3.4 Portable Building Applications</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-7" title="§ 3.4.1 Production Monitoring">§ 3.4.1 Production Monitoring</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-8" title="§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios">§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-9" title="§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU">§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-10" title="§ 3.6.3.1 Digital Microscopes">§ 3.6.3.1 Digital Microscopes</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-11" title="§ 3.7.1 Smart Grids">§ 3.7.1 Smart Grids</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-12" title="§ 4.1 Discovery">§ 4.1 Discovery</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-13" title="§ 4.2 Multi-Vendor System Integration - Out of the box interoperability">§ 4.2 Multi-Vendor System Integration - Out of the box interoperability</a> <a href="#ref-for-dfn-stakeholder-cloud-provider-14" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-15" title="§ 4.4.1 Digital Twin (1)">§ 4.4.1 Digital Twin (1)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-16" title="§ 4.5 Cross Protocol Interworking">§ 4.5 Cross Protocol Interworking</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-17" title="§ 4.9.1 Device Lifecycle">§ 4.9.1 Device Lifecycle</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-18" title="§ 4.10.1 AR Virtual Guide">§ 4.10.1 AR Virtual Guide</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-cloud-provider-19" title="§ 4.11 Edge Computing">§ 4.11 Edge Computing</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-service-provider" aria-label="Links in this document to definition: Service Provider">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-service-provider" aria-label="Permalink for definition: Service Provider. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-service-provider-1" title="§ 1.3 Stakeholders and Roles">§ 1.3 Stakeholders and Roles</a> <a href="#ref-for-dfn-stakeholder-service-provider-2" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-3" title="§ 3.1.2 Open-field Agriculture">§ 3.1.2 Open-field Agriculture</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-4" title="§ 3.1.3 Irrigation in Outdoor Environment">§ 3.1.3 Irrigation in Outdoor Environment</a> <a href="#ref-for-dfn-stakeholder-service-provider-5" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-6" title="§ 3.1.4 Automatic milking system for dairy farm">§ 3.1.4 Automatic milking system for dairy farm</a> <a href="#ref-for-dfn-stakeholder-service-provider-7" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-8" title="§ 3.1.5 Pest control in Open-field">§ 3.1.5 Pest control in Open-field</a> <a href="#ref-for-dfn-stakeholder-service-provider-9" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-10" title="§ 3.1.6 Livestock Health Management">§ 3.1.6 Livestock Health Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-11" title="§ 3.1.7 Agricultural Machinery Management">§ 3.1.7 Agricultural Machinery Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-12" title="§ 3.2.5 Cross-Domain Discovery in a Smart Campus">§ 3.2.5 Cross-Domain Discovery in a Smart Campus</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-13" title="§ 3.2.6 Cultural Spaces (Museums)">§ 3.2.6 Cultural Spaces (Museums)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-14" title="§ 3.3.3 Automated Smart Building Management">§ 3.3.3 Automated Smart Building Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-15" title="§ 3.3.4 Portable Building Applications">§ 3.3.4 Portable Building Applications</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-16" title="§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios">§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-17" title="§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU">§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-18" title="§ 3.6.3.1 Digital Microscopes">§ 3.6.3.1 Digital Microscopes</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-19" title="§ 3.10.1.2 Leaving and Coming Home">§ 3.10.1.2 Leaving and Coming Home</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-20" title="§ 3.10.2.1 Education Shared Devices">§ 3.10.2.1 Education Shared Devices</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-21" title="§ 4.1 Discovery">§ 4.1 Discovery</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-22" title="§ 4.2 Multi-Vendor System Integration - Out of the box interoperability">§ 4.2 Multi-Vendor System Integration - Out of the box interoperability</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-23" title="§ 4.8.1 OAuth2 Flows">§ 4.8.1 OAuth2 Flows</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-24" title="§ 4.9.1 Device Lifecycle">§ 4.9.1 Device Lifecycle</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-25" title="§ 4.10.1 AR Virtual Guide">§ 4.10.1 AR Virtual Guide</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-service-provider-26" title="§ 4.11 Edge Computing">§ 4.11 Edge Computing</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-gateway-manufacturer" aria-label="Links in this document to definition: Gateway Manufacturer">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-gateway-manufacturer" aria-label="Permalink for definition: Gateway Manufacturer. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-1" title="§ 3.3.3 Automated Smart Building Management">§ 3.3.3 Automated Smart Building Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-2" title="§ 3.3.4 Portable Building Applications">§ 3.3.4 Portable Building Applications</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-3" title="§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios">§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-4" title="§ 3.5.2 Retail All Stop Button (Outdoor Emergency Stop Plunger)">§ 3.5.2 Retail All Stop Button (Outdoor Emergency Stop Plunger)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-5" title="§ 3.5.3 Retail Indoor Door Sensor">§ 3.5.3 Retail Indoor Door Sensor</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-6" title="§ 3.5.4 Retail Indoor and Outdoor Freezers">§ 3.5.4 Retail Indoor and Outdoor Freezers</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-7" title="§ 3.5.5 Retail Kitchen Refrigerator">§ 3.5.5 Retail Kitchen Refrigerator</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-8" title="§ 3.5.6 Retail Restroom Devices">§ 3.5.6 Retail Restroom Devices</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-9" title="§ 3.5.7 Retail Lighting Control">§ 3.5.7 Retail Lighting Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-10" title="§ 3.5.8 Retail Outdoor Canopy Lighting Control">§ 3.5.8 Retail Outdoor Canopy Lighting Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-11" title="§ 3.5.9 Retail Fountain Drink Ice Machine">§ 3.5.9 Retail Fountain Drink Ice Machine</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-12" title="§ 3.5.10 Retail Camera Device">§ 3.5.10 Retail Camera Device</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-13" title="§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU">§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-14" title="§ 4.1 Discovery">§ 4.1 Discovery</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-15" title="§ 4.2 Multi-Vendor System Integration - Out of the box interoperability">§ 4.2 Multi-Vendor System Integration - Out of the box interoperability</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-16" title="§ 4.3 Virtual Thing">§ 4.3 Virtual Thing</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-17" title="§ 4.9.1 Device Lifecycle">§ 4.9.1 Device Lifecycle</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-gateway-manufacturer-18" title="§ 4.11 Edge Computing">§ 4.11 Edge Computing</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-identity-provider" aria-label="Links in this document to definition: Identity Provider">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-identity-provider" aria-label="Permalink for definition: Identity Provider. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-1" title="§ 3.3.3 Automated Smart Building Management">§ 3.3.3 Automated Smart Building Management</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-2" title="§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios">§ 3.4.2 Cross-protocol Interaction in Industry 4.0 Scenarios</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-3" title="§ 3.5.2 Retail All Stop Button (Outdoor Emergency Stop Plunger)">§ 3.5.2 Retail All Stop Button (Outdoor Emergency Stop Plunger)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-4" title="§ 3.5.3 Retail Indoor Door Sensor">§ 3.5.3 Retail Indoor Door Sensor</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-5" title="§ 3.5.4 Retail Indoor and Outdoor Freezers">§ 3.5.4 Retail Indoor and Outdoor Freezers</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-6" title="§ 3.5.5 Retail Kitchen Refrigerator">§ 3.5.5 Retail Kitchen Refrigerator</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-7" title="§ 3.5.6 Retail Restroom Devices">§ 3.5.6 Retail Restroom Devices</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-8" title="§ 3.5.7 Retail Lighting Control">§ 3.5.7 Retail Lighting Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-9" title="§ 3.5.8 Retail Outdoor Canopy Lighting Control">§ 3.5.8 Retail Outdoor Canopy Lighting Control</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-10" title="§ 3.5.9 Retail Fountain Drink Ice Machine">§ 3.5.9 Retail Fountain Drink Ice Machine</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-11" title="§ 3.5.10 Retail Camera Device">§ 3.5.10 Retail Camera Device</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-12" title="§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU">§ 3.6.1.2 Interconnected Medical Devices in a Hospital ICU</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-13" title="§ 3.6.3.1 Digital Microscopes">§ 3.6.3.1 Digital Microscopes</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-14" title="§ 4.1 Discovery">§ 4.1 Discovery</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-15" title="§ 4.8.1 OAuth2 Flows">§ 4.8.1 OAuth2 Flows</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-identity-provider-16" title="§ 4.10.1 AR Virtual Guide">§ 4.10.1 AR Virtual Guide</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-directory-service-provider" aria-label="Links in this document to definition: Directory Service Provider">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-directory-service-provider" aria-label="Permalink for definition: Directory Service Provider. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-directory-service-provider-1" title="§ 1.3 Stakeholders and Roles">§ 1.3 Stakeholders and Roles</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-td-consumer" aria-label="Links in this document to definition: TD Consumer">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-td-consumer" aria-label="Permalink for definition: TD Consumer. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-td-consumer-1" title="§ 2.1.3 Byte Ordering for Binary Data Formats">§ 2.1.3 Byte Ordering for Binary Data Formats</a> <a href="#ref-for-dfn-stakeholder-td-consumer-2" title="Reference 2">(2)</a> 
    </li><li>
      <a href="#ref-for-dfn-stakeholder-td-consumer-3" title="§ 2.1.4 Polling Rate Limit">§ 2.1.4 Polling Rate Limit</a> <a href="#ref-for-dfn-stakeholder-td-consumer-4" title="Reference 2">(2)</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-td-server" aria-label="Links in this document to definition: TD Server">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-td-server" aria-label="Permalink for definition: TD Server. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
    <li>
      <a href="#ref-for-dfn-stakeholder-td-server-1" title="§ 1.3 Stakeholders and Roles">§ 1.3 Stakeholders and Roles</a> 
    </li>
  </ul>
    </div><div class="dfn-panel" hidden="" role="dialog" aria-modal="true" id="dfn-panel-for-dfn-stakeholder-td-directory" aria-label="Links in this document to definition: TD Directory">
      <span class="caret"></span>
      <div>
        <a class="self-link" href="#dfn-stakeholder-td-directory" aria-label="Permalink for definition: TD Directory. Activate to close this dialog.">Permalink</a>
         
      </div>
      <p><b>Referenced in:</b></p>
      <ul>
      <li>Not referenced in this document.</li>
    </ul>
    </div><script id="respec-highlight-vars">(() => {
// @ts-check

if (document.respec) {
  document.respec.ready.then(setupVarHighlighter);
} else {
  setupVarHighlighter();
}

function setupVarHighlighter() {
  document
    .querySelectorAll("var")
    .forEach(varElem => varElem.addEventListener("click", highlightListener));
}

function highlightListener(ev) {
  ev.stopPropagation();
  const { target: varElem } = ev;
  const hightligtedElems = highlightVars(varElem);
  const resetListener = () => {
    const hlColor = getHighlightColor(varElem);
    hightligtedElems.forEach(el => removeHighlight(el, hlColor));
    [...HL_COLORS.keys()].forEach(key => HL_COLORS.set(key, true));
  };
  if (hightligtedElems.length) {
    document.body.addEventListener("click", resetListener, { once: true });
  }
}

// availability of highlight colors. colors from var.css
const HL_COLORS = new Map([
  ["respec-hl-c1", true],
  ["respec-hl-c2", true],
  ["respec-hl-c3", true],
  ["respec-hl-c4", true],
  ["respec-hl-c5", true],
  ["respec-hl-c6", true],
  ["respec-hl-c7", true],
]);

function getHighlightColor(target) {
  // return current colors if applicable
  const { value } = target.classList;
  const re = /respec-hl-\w+/;
  const activeClass = re.test(value) && value.match(re);
  if (activeClass) return activeClass[0];

  // first color preference
  if (HL_COLORS.get("respec-hl-c1") === true) return "respec-hl-c1";

  // otherwise get some other available color
  return [...HL_COLORS.keys()].find(c => HL_COLORS.get(c)) || "respec-hl-c1";
}

function highlightVars(varElem) {
  const textContent = norm(varElem.textContent);
  const parent = varElem.closest(".algorithm, section");
  const highlightColor = getHighlightColor(varElem);

  const varsToHighlight = [...parent.querySelectorAll("var")].filter(
    el =>
      norm(el.textContent) === textContent &&
      el.closest(".algorithm, section") === parent
  );

  // update availability of highlight color
  const colorStatus = varsToHighlight[0].classList.contains("respec-hl");
  HL_COLORS.set(highlightColor, colorStatus);

  // highlight vars
  if (colorStatus) {
    varsToHighlight.forEach(el => removeHighlight(el, highlightColor));
    return [];
  } else {
    varsToHighlight.forEach(el => addHighlight(el, highlightColor));
  }
  return varsToHighlight;
}

function removeHighlight(el, highlightColor) {
  el.classList.remove("respec-hl", highlightColor);
  // clean up empty class attributes so they don't come in export
  if (!el.classList.length) el.removeAttribute("class");
}

function addHighlight(elem, highlightColor) {
  elem.classList.add("respec-hl", highlightColor);
}

/**
 * Same as `norm` from src/core/utils, but our build process doesn't allow
 * imports in runtime scripts, so duplicated here.
 * @param {string} str
 */
function norm(str) {
  return str.trim().replace(/\s+/g, " ");
}
})()</script><script id="respec-dfn-panel">(() => {
// @ts-check
if (document.respec) {
  document.respec.ready.then(setupPanel);
} else {
  setupPanel();
}

function setupPanel() {
  const listener = panelListener();
  document.body.addEventListener("keydown", listener);
  document.body.addEventListener("click", listener);
}

function panelListener() {
  /** @type {HTMLElement} */
  let panel = null;
  return event => {
    const { target, type } = event;

    if (!(target instanceof HTMLElement)) return;

    // For keys, we only care about Enter key to activate the panel
    // otherwise it's activated via a click.
    if (type === "keydown" && event.key !== "Enter") return;

    const action = deriveAction(event);

    switch (action) {
      case "show": {
        hidePanel(panel);
        /** @type {HTMLElement} */
        const dfn = target.closest("dfn, .index-term");
        panel = document.getElementById(`dfn-panel-for-${dfn.id}`);
        const coords = deriveCoordinates(event);
        displayPanel(dfn, panel, coords);
        break;
      }
      case "dock": {
        panel.style.left = null;
        panel.style.top = null;
        panel.classList.add("docked");
        break;
      }
      case "hide": {
        hidePanel(panel);
        panel = null;
        break;
      }
    }
  };
}

/**
 * @param {MouseEvent|KeyboardEvent} event
 */
function deriveCoordinates(event) {
  const target = /** @type HTMLElement */ (event.target);

  // We prevent synthetic AT clicks from putting
  // the dialog in a weird place. The AT events sometimes
  // lack coordinates, so they have clientX/Y = 0
  const rect = target.getBoundingClientRect();
  if (
    event instanceof MouseEvent &&
    event.clientX >= rect.left &&
    event.clientY >= rect.top
  ) {
    // The event probably happened inside the bounding rect...
    return { x: event.clientX, y: event.clientY };
  }

  // Offset to the middle of the element
  const x = rect.x + rect.width / 2;
  // Placed at the bottom of the element
  const y = rect.y + rect.height;
  return { x, y };
}

/**
 * @param {Event} event
 */
function deriveAction(event) {
  const target = /** @type {HTMLElement} */ (event.target);
  const hitALink = !!target.closest("a");
  if (target.closest("dfn:not([data-cite]), .index-term")) {
    return hitALink ? "none" : "show";
  }
  if (target.closest(".dfn-panel")) {
    if (hitALink) {
      return target.classList.contains("self-link") ? "hide" : "dock";
    }
    const panel = target.closest(".dfn-panel");
    return panel.classList.contains("docked") ? "hide" : "none";
  }
  if (document.querySelector(".dfn-panel:not([hidden])")) {
    return "hide";
  }
  return "none";
}

/**
 * @param {HTMLElement} dfn
 * @param {HTMLElement} panel
 * @param {{ x: number, y: number }} clickPosition
 */
function displayPanel(dfn, panel, { x, y }) {
  panel.hidden = false;
  // distance (px) between edge of panel and the pointing triangle (caret)
  const MARGIN = 20;

  const dfnRects = dfn.getClientRects();
  // Find the `top` offset when the `dfn` can be spread across multiple lines
  let closestTop = 0;
  let minDiff = Infinity;
  for (const rect of dfnRects) {
    const { top, bottom } = rect;
    const diffFromClickY = Math.abs((top + bottom) / 2 - y);
    if (diffFromClickY < minDiff) {
      minDiff = diffFromClickY;
      closestTop = top;
    }
  }

  const top = window.scrollY + closestTop + dfnRects[0].height;
  const left = x - MARGIN;
  panel.style.left = `${left}px`;
  panel.style.top = `${top}px`;

  // Find if the panel is flowing out of the window
  const panelRect = panel.getBoundingClientRect();
  const SCREEN_WIDTH = Math.min(window.innerWidth, window.screen.width);
  if (panelRect.right > SCREEN_WIDTH) {
    const newLeft = Math.max(MARGIN, x + MARGIN - panelRect.width);
    const newCaretOffset = left - newLeft;
    panel.style.left = `${newLeft}px`;
    /** @type {HTMLElement} */
    const caret = panel.querySelector(".caret");
    caret.style.left = `${newCaretOffset}px`;
  }

  // As it's a dialog, we trap focus.
  // TODO: when <dialog> becomes a implemented, we should really
  // use that.
  trapFocus(panel, dfn);
}

/**
 * @param {HTMLElement} panel
 * @param {HTMLElement} dfn
 * @returns
 */
function trapFocus(panel, dfn) {
  /** @type NodeListOf<HTMLAnchorElement> elements */
  const anchors = panel.querySelectorAll("a[href]");
  // No need to trap focus
  if (!anchors.length) return;

  // Move focus to first anchor element
  const first = anchors.item(0);
  first.focus();

  const trapListener = createTrapListener(anchors, panel, dfn);
  panel.addEventListener("keydown", trapListener);

  // Hiding the panel releases the trap
  const mo = new MutationObserver(records => {
    const [record] = records;
    const target = /** @type HTMLElement */ (record.target);
    if (target.hidden) {
      panel.removeEventListener("keydown", trapListener);
      mo.disconnect();
    }
  });
  mo.observe(panel, { attributes: true, attributeFilter: ["hidden"] });
}

/**
 *
 * @param {NodeListOf<HTMLAnchorElement>} anchors
 * @param {HTMLElement} panel
 * @param {HTMLElement} dfn
 * @returns
 */
function createTrapListener(anchors, panel, dfn) {
  const lastIndex = anchors.length - 1;
  let currentIndex = 0;
  return event => {
    switch (event.key) {
      // Hitting "Tab" traps us in a nice loop around elements.
      case "Tab": {
        event.preventDefault();
        currentIndex += event.shiftKey ? -1 : +1;
        if (currentIndex < 0) {
          currentIndex = lastIndex;
        } else if (currentIndex > lastIndex) {
          currentIndex = 0;
        }
        anchors.item(currentIndex).focus();
        break;
      }

      // Hitting "Enter" on an anchor releases the trap.
      case "Enter":
        hidePanel(panel);
        break;

      // Hitting "Escape" returns focus to dfn.
      case "Escape":
        hidePanel(panel);
        dfn.focus();
        return;
    }
  };
}

/** @param {HTMLElement} panel */
function hidePanel(panel) {
  if (!panel) return;
  panel.hidden = true;
  panel.classList.remove("docked");
}
})()</script><script src="https://www.w3.org/scripts/TR/2021/fixup.js"></script></body></html>